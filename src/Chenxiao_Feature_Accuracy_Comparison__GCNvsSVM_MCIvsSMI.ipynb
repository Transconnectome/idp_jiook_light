{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn import linear_model, svm\n",
    "import re\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os          \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "import sklearn.linear_model as lm\n",
    "\n",
    "\n",
    "\n",
    "print(\"finished this block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished this block\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, '..')\n",
    "from lib import models, graph, coarsening, utils\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "print(\"finished this block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished this block\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir('../braindata')\n",
    "dd =pd.read_csv(\"data_3_all.csv\",header=0)\n",
    "import csv\n",
    "with open('data_3_all.csv', 'r') as f:\n",
    "    d_reader = csv.DictReader(f)\n",
    "    headers = d_reader.fieldnames\n",
    "print(\"finished this block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished this block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:2248: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    }
   ],
   "source": [
    "data=np.array(dd)\n",
    "\n",
    "\n",
    "\n",
    "idx_IN_columns = np.append(np.array([3,4]),np.array(range(11,data.shape[1])))\n",
    "X=data[:,idx_IN_columns]\n",
    "\n",
    "\n",
    "\n",
    "X = stats.zscore(X)\n",
    "y=data[:,6]\n",
    "\n",
    "ind_num=np.isnan(y)\n",
    "# print(ind_num.shape)\n",
    "y_no_nan = y[~ind_num]\n",
    "X_no_nan = X[~ind_num,:]\n",
    "\n",
    "y=y_no_nan\n",
    "X=X_no_nan\n",
    "\n",
    "np.isnan(X).any()\n",
    "X[np.isnan(X)] = np.median(X[~np.isnan(X)])\n",
    "print(\"finished this block\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Chenxiao: the several blocks of codes are for generating the accuracies, f1 scores, and so on for various feauatres.\n",
    "If there is an existing number of feature, the statistics can be calculated using the simpler code behind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished this block\n"
     ]
    }
   ],
   "source": [
    "feature_num_all=[]\n",
    "GCN_all_feature=[]\n",
    "GCN_f1s_feature=[]\n",
    "base_labels= []\n",
    "\n",
    "###########################\n",
    "#From Yun's code, selecting the import features\n",
    "clf = ExtraTreesClassifier(n_estimators=50,random_state=0)\n",
    "clf = clf.fit(X, y)\n",
    "importances = clf.feature_importances_\n",
    "importances\n",
    "indices = np.argsort(importances)[::-1]\n",
    "############################\n",
    "n_features = [100,1000]\n",
    "n_features.sort()\n",
    "\n",
    "\n",
    "print(\"Finished this block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished this block\n"
     ]
    }
   ],
   "source": [
    "C = max(y) + 1  # number of classes    \n",
    "\n",
    "common = {}\n",
    "common['dir_name']       = 'Chenxiao_Testing'\n",
    "common['num_epochs']     = 35\n",
    "common['batch_size']     = 10\n",
    "common['eval_frequency'] = common['num_epochs']\n",
    "common['brelu']          = 'b1relu'\n",
    "common['pool']           = 'mpool1'\n",
    "common['filter']         = 'chebyshev5'\n",
    "\n",
    "# Architecture.\n",
    "common['F']              = [64, 32]  # Number of graph convolutional filters.\n",
    "common['K']              = [10, 10]  # Polynomial orders.\n",
    "common['p']              = [4, 2]    # Pooling sizes.\n",
    "common['M']              = [256, 512, C]  # Output dimensionality of fully connected layers.\n",
    "\n",
    "# Optimization.\n",
    "common['regularization'] = 5e-4\n",
    "common['dropout']        = 0.9\n",
    "common['learning_rate']  = 5e-4\n",
    "common['decay_rate']     = 0.95\n",
    "common['momentum']       = 0.9\n",
    "#params['decay_steps']    = n_train / params['batch_size']\n",
    "\n",
    "model_perf = utils.model_perf()    \n",
    "\n",
    "sep = '*' * 100\n",
    "print(\"finished this block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "\n",
    "for i in n_features:\n",
    "    print('\\nWorking on number of feature selected as {} {}\\n'.format(i, sep))\n",
    "    index=indices[0:i]\n",
    "    features=X[:,index]\n",
    "    feature_num=features.shape[1]\n",
    "\n",
    "    GCN_all_accs = []\n",
    "    GCN_all_scores = []\n",
    "    GCN_f1s = []\n",
    "    base_labels=[]\n",
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "#This part is from the NIPS code, generating training, validation and traing set\n",
    "\n",
    "        \n",
    "    for runs in range(10):        \n",
    "        print(\"\\n RUN: {} {} \\n\".format(runs, sep))\n",
    "\n",
    "        GCN_accuracies = []\n",
    "        GCN_scores = []\n",
    "        strat_labels = []\n",
    "        \n",
    "        for j in range(skf.get_n_splits(features, y)):   \n",
    "            print(\"\\n Fold: {} {} \\n\".format(i, sep))\n",
    "            \n",
    "            train_data = np.empty([0,features.shape[1]])\n",
    "            train_labels = [] \n",
    "            val_ix = j\n",
    "            if val_ix == max(bins):\n",
    "                test_ix = 0\n",
    "                bins.remove(val_ix)\n",
    "                bins.remove(test_ix)\n",
    "\n",
    "            else:\n",
    "                test_ix = val_ix + 1\n",
    "                bins.remove(test_ix)\n",
    "                bins.remove(val_ix)\n",
    "\n",
    "            val_data, val_labels = features[bin_ixs[val_ix]], y[bin_ixs[val_ix]]\n",
    "            test_data, test_labels = features[bin_ixs[test_ix]], y[bin_ixs[test_ix]]\n",
    "        \n",
    "            for b in bins:\n",
    "                train_data = np.concatenate((train_data, features[bin_ixs[b]]))\n",
    "                train_labels = np.concatenate((train_labels, y[bin_ixs[b]]))\n",
    "\n",
    "###################################################\n",
    "#Chenxiao: generating permuational matrix\n",
    "            dist, idx = graph.distance_scipy_spatial(train_data.transpose(), k=10, metric='euclidean')\n",
    "            A = graph.adjacency(dist, idx).astype(np.float32)\n",
    "\n",
    "            assert A.shape == (d, d)\n",
    "            print('d = |V| = {}, k|V| < |E| = {}'.format(d, A.nnz))\n",
    "            plt.spy(A, markersize=2, color='black')     \n",
    "        \n",
    "            graphs, perm = coarsening.coarsen(A, levels=8, self_connections=False)\n",
    "        \n",
    "            train_data = coarsening.perm_data(train_data, perm)\n",
    "            val_data = coarsening.perm_data(val_data, perm)\n",
    "            test_data = coarsening.perm_data(test_data, perm)\n",
    "\n",
    "            L = [graph.laplacian(A, normalized=True) for A in graphs]\n",
    " #       graph.plot_spectrum(L)    \n",
    " ###################################################        \n",
    "            name = 'CGCNN'\n",
    "            params = common.copy()\n",
    "            params['dir_name'] += name             \n",
    "            params['decay_steps'] = len(train_labels) / common['batch_size']\n",
    "        \n",
    "            print('begin working!!!!!!!!')\n",
    "            model_perf.test(models.cgcnn(L, **params), name, params, \n",
    "                            train_data, train_labels, val_data, val_labels, test_data, test_labels, val_ix)\n",
    "        \n",
    "            scores, y_labels, test_accuracy = model_perf.show()   \n",
    "            \n",
    "            strat_labels=np.append(strat_labels, test_labels)\n",
    "            \n",
    "            #f1 calculation\n",
    "            log_f1=f1_score(test_labels, y_labels)            \n",
    "\n",
    "            GCN_accuracies = np.append(GCN_accuracies, test_accuracy)\n",
    "            GCN_scores=np.append(GCN_scores, scores)\n",
    "            GCN_f1s=np.append(GCN_f1s, log_f1)\n",
    "            \n",
    "            GCN_all_scores=np.append(GCN_all_scores, GCN_scores) \n",
    "            GCN_fold_avg=np.mean(GCN_accuracies)\n",
    "            GCN_all_accs=np.append(GCN_all_accs, GCN_fold_avg)\n",
    "            \n",
    "        feature_num_all=np.append(feature_num_all, feature_num)\n",
    "        GCN_all_feature=np.append(GCN_all_feature, np.mean(GCN_all_accs))\n",
    "        GCN_f1s_feature=np.append(GCN_f1s_feature, np.mean(GCN_f1s)\n",
    "        base_labels=np.append(base_labels, np.mean(strat_labels))\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Chenxiao: the code is for a particular number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RUN: 0 **************************************************************************************************** \n",
      "\n",
      "\n",
      " Fold: 0 **************************************************************************************************** \n",
      "\n",
      "d = |V| = 500, k|V| < |E| = 8376\n",
      "Layer 0: M_0 = |V| = 576 nodes (76 added),|E| = 4188 edges\n",
      "Layer 1: M_1 = |V| = 288 nodes (30 added),|E| = 2791 edges\n",
      "Layer 2: M_2 = |V| = 144 nodes (14 added),|E| = 1704 edges\n",
      "Layer 3: M_3 = |V| = 72 nodes (6 added),|E| = 867 edges\n",
      "Layer 4: M_4 = |V| = 36 nodes (2 added),|E| = 357 edges\n",
      "Layer 5: M_5 = |V| = 18 nodes (1 added),|E| = 118 edges\n",
      "Layer 6: M_6 = |V| = 9 nodes (0 added),|E| = 35 edges\n",
      "begin working!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "##################################\n",
    "#This is from Yun's framework of K-fold cross validation\n",
    "##################################\n",
    "##################################\n",
    "\n",
    "\n",
    "###########################\n",
    "#From Yun's code, selecting the import features\n",
    "clf = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "clf = clf.fit(X, y)\n",
    "importances = clf.feature_importances_\n",
    "importances\n",
    "indices = np.argsort(importances)[::-1]\n",
    "############################\n",
    "\n",
    "\n",
    "number_of_features=500\n",
    "index=indices[0:number_of_features]\n",
    "features=X[:,index]\n",
    "feature_num=features.shape[1]\n",
    "\n",
    "GCN_all_accs_one_fetur  = []\n",
    "GCN_all_scores_one_fetur = []\n",
    "GCN_all_f1s_one_fetur = []\n",
    "\n",
    "LR_all_accs_one_fetur  = []\n",
    "LR_all_f1s_one_fetur = []\n",
    "\n",
    "SVM_all_accs_one_fetur  = []\n",
    "SVM_all_f1s_one_fetur = []\n",
    "base_labels=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "#This part is from the NIPS code, generating training, validation and traing set\n",
    "\n",
    "for runs in range(5):        \n",
    "    counter=0\n",
    "    print(\"\\n RUN: {} {} \\n\".format(runs, sep))\n",
    "    strat_labels = []\n",
    "\n",
    "    GCN_accuracies = []\n",
    "    GCN_scores = []\n",
    "    GCN_f1s=[]\n",
    "\n",
    "    LR_accuracies = []\n",
    "    LR_f1s=[]    \n",
    "    \n",
    "    SVM_accuracies = []\n",
    "    SVM_f1s=[]    \n",
    "    \n",
    "    t=time.process_time()\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=int(t))\n",
    "#    skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    for train_index, test_index in skf.split(features, y):\n",
    "        print(\"\\n Fold: {} {} \\n\".format(counter, sep))        \n",
    "        train_data, test_data = features[train_index], features[test_index]\n",
    "        train_labels, test_labels = y[train_index], y[test_index]\n",
    "        val_data=test_data\n",
    "        val_labels=test_labels\n",
    "\n",
    "###################################################\n",
    "#Chenxiao: generating permuational matrix\n",
    "        dist, idx = graph.distance_scipy_spatial(train_data.transpose(), k=10, metric='euclidean')\n",
    "        A = graph.adjacency(dist, idx).astype(np.float32)\n",
    "\n",
    "        assert A.shape == (features.shape[1], features.shape[1])\n",
    "        print('d = |V| = {}, k|V| < |E| = {}'.format(features.shape[1], A.nnz))\n",
    "        plt.spy(A, markersize=2, color='black')     \n",
    "        \n",
    "        graphs, perm = coarsening.coarsen(A, levels=6, self_connections=False)\n",
    "        \n",
    "        train_data = coarsening.perm_data(train_data, perm)\n",
    "        val_data = coarsening.perm_data(val_data, perm)\n",
    "        test_data = coarsening.perm_data(test_data, perm)\n",
    "\n",
    "        L = [graph.laplacian(A, normalized=True) for A in graphs]\n",
    " #       graph.plot_spectrum(L)    \n",
    " ###################################################        \n",
    "    \n",
    "        name = 'CGCNN'\n",
    "        params = common.copy()\n",
    "        params['dir_name'] = params['dir_name'] + name + '_Run' + str(runs) + '_Skf' + str(counter)             \n",
    "        params['decay_steps'] = len(train_labels) / common['batch_size']\n",
    "        \n",
    "        print('begin working!!!!!!!!')\n",
    "        model_perf.test(models.cgcnn(L, **params), name, params, \n",
    "                        train_data, train_labels, val_data, val_labels, test_data, test_labels, test_index)\n",
    "        \n",
    "        scores, f1, y_labels, test_accuracy = model_perf.show()   \n",
    "            \n",
    "        strat_labels=np.append(strat_labels, test_labels)\n",
    "            \n",
    "####################################################   \n",
    "#Chenxiao: add Yun's code for logistric regression and SVM, for comparision with GCN case by case\n",
    "        logistic = linear_model.LogisticRegression(C=1e5)\n",
    "        rbf = svm.SVC(C=10,kernel='linear',gamma=0.01)\n",
    "#######################\n",
    "#logistic regression:\n",
    "\n",
    "        log=logistic.fit(train_data, train_labels)\n",
    "    \n",
    "        #log_prob_val=log.decision_function(val_data)\n",
    "        #log_prob_test=log.decision_funtion(test_data)\n",
    "        \n",
    "        log_acc_val=log.score(val_data, val_labels)\n",
    "        log_acc_test=log.score(test_data, test_labels)    \n",
    "        \n",
    "        ##f1 calculation\n",
    "        y_pred_val=logistic.predict(val_data)\n",
    "        y_pred_test=logistic.predict(test_data)\n",
    "        \n",
    "        log_f1_val=f1_score(val_labels, y_pred_val)\n",
    "        log_f1_test=f1_score(test_labels, y_pred_test)\n",
    "        \n",
    "        \n",
    "        print('Logistic Regression Accuracy for Validation: %f' % log_acc_val)\n",
    "        print('Logistic Regression Accuracy for Test: %f' % log_acc_test)\n",
    "        print('Logistic Regression F1 for Validation: %f' % log_f1_val)\n",
    "        print('Logistic Regression F1 for Test: %f' % log_f1_test)\n",
    "        \n",
    "        \n",
    "#SVM:\n",
    "        rbf=rbf.fit(train_data, train_labels)\n",
    "    \n",
    "        #svm_prob_val=rbf.decision_function(val_data)\n",
    "        #svm_prob_test=rbf.decision_funtion(test_data)\n",
    "        \n",
    "        svm_acc_val=rbf.score(val_data, val_labels)\n",
    "        svm_acc_test=rbf.score(test_data, test_labels)    \n",
    "        \n",
    "        #f1 calculation\n",
    "        y_pred_val=rbf.predict(val_data)\n",
    "        y_pred_test=rbf.predict(test_data)\n",
    "        \n",
    "        svm_f1_val=f1_score(val_labels, y_pred_val)\n",
    "        svm_f1_test=f1_score(test_labels, y_pred_test)\n",
    "               \n",
    "        print('SVM Accuracy for Validation: %f' % svm_acc_val)\n",
    "        print('SVM Accuracy for Test: %f' % svm_acc_test)\n",
    "        print('SVM F1 for Validation: %f' % svm_f1_val)\n",
    "        print('SVM F1 for Test: %f' % svm_f1_test)        \n",
    "                \n",
    "####################################################        \n",
    "        \n",
    "        \n",
    "        ##f1 calculation\n",
    "        #log_f1=f1_score(test_labels, y_labels)            \n",
    "\n",
    "        GCN_accuracies = np.append(GCN_accuracies, test_accuracy)\n",
    "        GCN_scores=np.append(GCN_scores, scores)\n",
    "        GCN_f1s=np.append(GCN_f1s, f1)\n",
    "        \n",
    "        LR_accuracies = np.append(LR_accuracies, log_acc_test)\n",
    "        LR_f1s=np.append(LR_f1s, log_f1_test)        \n",
    "        \n",
    "        SVM_accuracies = np.append(SVM_accuracies, svm_acc_test)\n",
    "        SVM_f1s=np.append(SVM_f1s, svm_f1_test) \n",
    "        \n",
    "        counter=counter+1\n",
    "   \n",
    "    base_labels=np.append(base_labels, strat_labels)        \n",
    "    GCN_all_scores_one_fetur=np.append(GCN_all_scores_one_fetur, GCN_scores) \n",
    "    GCN_all_accs_one_fetur=np.append(GCN_all_accs_one_fetur, np.mean(GCN_accuracies))\n",
    "    GCN_all_f1s_one_fetur =np.append(GCN_all_f1s_one_fetur, np.mean(GCN_f1s))\n",
    "    \n",
    "    LR_all_accs_one_fetur=np.append(LR_all_accs_one_fetur, np.mean(LR_accuracies))\n",
    "    LR_all_f1s_one_fetur =np.append(LR_all_f1s_one_fetur, np.mean(LR_f1s))    \n",
    "    \n",
    "    SVM_all_accs_one_fetur=np.append(SVM_all_accs_one_fetur, np.mean(SVM_accuracies))\n",
    "    SVM_all_f1s_one_fetur =np.append(SVM_all_f1s_one_fetur, np.mean(SVM_f1s))       \n",
    "    \n",
    "    print(\"GCN###############################################################\")\n",
    "    print(\"Runs Avg Accuracies: {}\".format(np.mean(GCN_accuracies)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(GCN_accuracies)))\n",
    "    print(\"Runs Avg F1: {}\".format(np.mean(GCN_f1s)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(GCN_f1s)))\n",
    "\n",
    "    print(\"LR###############################################################\")\n",
    "    print(\"Runs Avg Accuracies: {}\".format(np.mean(LR_accuracies)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(LR_accuracies)))\n",
    "    print(\"Runs Avg F1: {}\".format(np.mean(LR_f1s)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(LR_f1s)))\n",
    "\n",
    "    print(\"SVM###############################################################\")\n",
    "    print(\"Runs Avg Accuracies: {}\".format(np.mean(SVM_accuracies)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(SVM_accuracies)))\n",
    "    print(\"Runs Avg F1: {}\".format(np.mean(SVM_f1s)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(SVM_f1s)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"GCN###############################################################\")\n",
    "print(\"Runs Avg Accuracies: {}\".format(np.mean(GCN_all_accs_one_fetur)))\n",
    "print(\"Standard Deviation: {}\".format(np.std(GCN_all_accs_one_fetur)))\n",
    "print(\"Runs Avg F1: {}\".format(np.mean(GCN_all_f1s_one_fetur)))\n",
    "print(\"Standard Deviation: {}\".format(np.std(GCN_all_f1s_one_fetur)))\n",
    "\n",
    "print(\"LR###############################################################\")\n",
    "print(\"Runs Avg Accuracies: {}\".format(np.mean(LR_all_accs_one_fetur)))\n",
    "print(\"Standard Deviation: {}\".format(np.std(LR_all_accs_one_fetur)))\n",
    "print(\"Runs Avg F1: {}\".format(np.mean(LR_all_f1s_one_fetur)))\n",
    "print(\"Standard Deviation: {}\".format(np.std(LR_all_f1s_one_fetur)))\n",
    "\n",
    "print(\"SVM###############################################################\")\n",
    "print(\"Runs Avg Accuracies: {}\".format(np.mean(SVM_all_accs_one_fetur)))\n",
    "print(\"Standard Deviation: {}\".format(np.std(SVM_all_accs_one_fetur)))\n",
    "print(\"Runs Avg F1: {}\".format(np.mean(SVM_all_f1s_one_fetur)))\n",
    "print(\"Standard Deviation: {}\".format(np.std(SVM_all_f1s_one_fetur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fpr['GCN'], tpr['GCN'], _ = roc_curve(base_labels, GCN_all_scores_one_fetur)\n",
    "roc_auc['GCN'] = auc(fpr['GCN'], tpr['GCN'])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr['GCN'], tpr['GCN'], lw=5, label='GCN (area = %0.2f)' % roc_auc['GCN'] )\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=5, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('MCIvsSMI')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('10x_Combined_ROC.eps')\n",
    "#plt.savefig('ROC_MCIVsNormal_connectome.eps')\n",
    "#plt.savefig('/Users/yunwang/Dropbox (NYSPI)/00 AD ML/papers/ISMRM/Figures/ROC_MCIvsSMI_connectome.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/posnerlab/Library/Python/3.5/lib/python/site-packages/scipy/stats/stats.py:2247: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn import linear_model, svm\n",
    "import re\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#s = \"../braindata/data_1_mor_select_100.csv\"\n",
    "import os          \n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('../braindata')\n",
    "#dd =pd.read_csv(\"data_3_all.csv\",header=0)\n",
    "dd =pd.read_csv(\"NBS_connectome_3M_count2_vector.csv\",header=0)\n",
    "data=np.array(dd)\n",
    "#print(data.shape)\n",
    "idx_IN_columns = np.append(np.array([1]),np.array(range(2,data.shape[1])))\n",
    "X=data[:,idx_IN_columns]\n",
    "#features=data[:,11:data.shape[1]]\n",
    "#features = features.transpose()\n",
    "X = stats.zscore(X)\n",
    "#print(features.shape)\n",
    "y=data[:,0]\n",
    "#5: ad-smi / 6:mci-smi / 7:adonly-smi / 8:ad-mci / 9:adonly-mci / 10:adonly - adwithsmallvv\n",
    "\n",
    "ind_num=np.isnan(y)\n",
    "# print(ind_num.shape)\n",
    "\n",
    "\n",
    "y_no_nan = y[~ind_num]\n",
    "\n",
    "X_no_nan = X[~ind_num,:]\n",
    "\n",
    "       # print(y.shape)\n",
    "\n",
    "y=y_no_nan\n",
    "X=X_no_nan\n",
    "feature_num_all=[]\n",
    "lr_all_feature=[]\n",
    "svm_all_feature=[]\n",
    "lr_fls_feature=[]\n",
    "svm_fls_feature=[]\n",
    "base_labels= []\n",
    "\n",
    "#X=X.reshape(X.size,1)\n",
    "#X=X.astype(np.float64,copy=False)\n",
    "np.isnan(X).any()\n",
    "#feature_num=features.shape[1]\n",
    "X[np.isnan(X)] = np.median(X[~np.isnan(X)])\n",
    "clf = ExtraTreesClassifier(n_estimators=50,\n",
    "                              random_state=0)\n",
    "clf = clf.fit(X, y)\n",
    "importances = clf.feature_importances_\n",
    "importances\n",
    "indices = np.argsort(importances)[::-1]\n",
    "#print(\"Feature ranking:\")\n",
    "\n",
    "#for f in range(X.shape[1]):\n",
    "#    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "#n_features = [2,5,10,20,40,50,70,80,100,1000,10000,3000,4000,500,5000,6000,7000,8000,9000,10000,20000]\n",
    "n_features = [40]\n",
    "\n",
    "#n_features = [6000]\n",
    "n_features.sort()\n",
    "lr_all_accs = []\n",
    "lr_all_scores = []\n",
    "lr_f1s = []\n",
    "svm_all_accs = []\n",
    "svm_all_scores = []\n",
    "svm_f1s = []\n",
    "base_labels = []\n",
    "\n",
    "for i in n_features:\n",
    "#     #print(i)\n",
    "    \n",
    "#     #lsvc = LinearSVC(C=J[i],penalty=\"l1\", dual=True).fit(X, y)\n",
    "#     #model = SelectFromModel(lsvc, prefit=True)\n",
    "#     #features = model.transform(X)\n",
    "#     clf = ExtraTreesClassifier(n_estimators=250,\n",
    "#                               random_state=0)\n",
    "#     clf = clf.fit(X, y)\n",
    "#     importances = forest.feature_importances_\n",
    "       \n",
    "    index=indices[0:i]\n",
    "    features=X[:,index]\n",
    "#     clf.feature_importances_ \n",
    "\n",
    "#     model = SelectFromModel(clf, threshold=0.6,prefit=True)\n",
    "#     features = model.transform(X)\n",
    "#     features.shape               \n",
    "#     #features=features.reshape(features.size,1)\n",
    "#     #features=features.astype(np.float64,copy=false)\n",
    "#     np.isnan(features).any()\n",
    "    feature_num=features.shape[1]\n",
    "    print(feature_num)\n",
    "    \n",
    "#    lr_all_accs = []\n",
    "#     lr_all_scores = []\n",
    "#     lr_f1s = []\n",
    "#     svm_all_accs = []\n",
    "#     svm_all_scores = []\n",
    "#     svm_f1s = []\n",
    "    #base_labels = []\n",
    "    for runs in range(10):\n",
    "        lr_accuracies = []\n",
    "        lr_scores = []\n",
    "        svm_accuracies = []\n",
    "        svm_scores = []\n",
    "        strat_labels = []\n",
    "        \n",
    "        logistic = linear_model.LogisticRegression(C=1e5)\n",
    "        rbf = svm.SVC(C=10,kernel='linear',gamma=0.01)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=3)\n",
    "        for train_index, test_index in skf.split(features, y):\n",
    "                    train_data, test_data = features[train_index], features[test_index]\n",
    "                    train_labels, test_labels = y[train_index], y[test_index]\n",
    "\n",
    "                    strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    "                    log = logistic.fit(train_data, train_labels)\n",
    "                    log_prob = log.decision_function(test_data)\n",
    "                    log_acc = log.score(test_data, test_labels)\n",
    "\n",
    "                    #f1 calculation\n",
    "                    y_pred = logistic.predict(test_data)\n",
    "                    log_f1 = f1_score(test_labels, y_pred)\n",
    "\n",
    "                    lr_accuracies = np.append(lr_accuracies, log_acc)\n",
    "                    lr_scores = np.append(lr_scores, log_prob)\n",
    "                    lr_f1s = np.append(lr_f1s, log_f1)\n",
    "                    #print('Logistic Regression Accuracy: %f' % log_acc)\n",
    "\n",
    "                    rbf = rbf.fit(train_data, train_labels)\n",
    "                    svm_acc = rbf.score(test_data, test_labels)\n",
    "                    svm_prob = rbf.decision_function(test_data)\n",
    "\n",
    "                    #f1 calculation\n",
    "                    y_pred = rbf.predict(test_data)\n",
    "                    svm_f1 = f1_score(test_labels, y_pred)\n",
    "                    #print('SVM Accuracy: %f' % svm_acc)\n",
    "                    svm_accuracies = np.append(svm_accuracies, svm_acc)\n",
    "                    svm_scores = np.append(svm_scores, svm_prob)\n",
    "                    svm_f1s = np.append(svm_f1s, svm_f1)\n",
    "                    \n",
    "        base_labels = np.append(base_labels, strat_labels)\n",
    "        lr_all_scores = np.append(lr_all_scores, lr_scores)\n",
    "        lr_fold_avg = np.mean(lr_accuracies)\n",
    "        lr_all_accs = np.append(lr_all_accs, lr_fold_avg)\n",
    "        svm_all_scores = np.append(svm_all_scores, svm_scores)\n",
    "        svm_fold_avg = np.mean(svm_accuracies)\n",
    "        svm_all_accs = np.append(svm_all_accs, svm_fold_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d726cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.85714286  0.5         0.66666667  0.85714286  0.5         0.66666667\n",
      "  0.85714286  0.5         0.66666667  0.85714286  0.5         0.66666667\n",
      "  0.85714286  0.5         0.66666667  0.85714286  0.5         0.66666667\n",
      "  0.85714286  0.5         0.66666667  0.85714286  0.5         0.66666667\n",
      "  0.85714286  0.5         0.66666667  0.85714286  0.5         0.66666667\n",
      "  0.5         0.5         0.66666667  0.8         0.5         0.5\n",
      "  0.66666667  0.8         0.5         0.5         0.66666667  0.8         0.5\n",
      "  0.5         0.66666667  0.8         0.5         0.5         0.66666667\n",
      "  0.8         0.5         0.5         0.66666667  0.8         0.5         0.5\n",
      "  0.66666667  0.8         0.5         0.5         0.66666667  0.8         0.5\n",
      "  0.5         0.66666667  0.8         0.5         0.5         0.66666667\n",
      "  0.8         0.5         0.5         0.66666667  0.5         0.5\n",
      "  0.66666667  0.5         0.5         0.66666667  0.5         0.5\n",
      "  0.66666667  0.5         0.5         0.66666667  0.5         0.5\n",
      "  0.66666667  0.5         0.5         0.66666667  0.5         0.5\n",
      "  0.66666667  0.5         0.5         0.66666667  0.5         0.5\n",
      "  0.66666667  0.4         0.4         0.4         0.4         0.4         0.4\n",
      "  0.4         0.4         0.4         0.4       ]\n",
      "[ 0.88998968  0.88998968  0.88998968  0.88998968  0.88998968  0.88998968\n",
      "  0.88998968  0.88998968  0.88998968  0.88998968  0.88998968  0.88998968\n",
      "  0.88998968  0.88998968  0.88998968  0.88998968  0.88998968  0.88998968\n",
      "  0.88998968  0.88998968  0.85665635  0.85665635  0.85665635  0.85665635\n",
      "  0.85665635  0.85665635  0.85665635  0.85665635  0.85665635  0.85665635\n",
      "  0.82201582  0.82201582  0.82201582  0.82201582  0.82201582  0.82201582\n",
      "  0.82201582  0.82201582  0.82201582  0.82201582  0.83378053  0.83378053\n",
      "  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053\n",
      "  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053\n",
      "  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053\n",
      "  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053\n",
      "  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053\n",
      "  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053\n",
      "  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053\n",
      "  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053  0.83378053]\n",
      "LR accuracy Avg: nan\n",
      "LR accuracy Standard Deviation: nan\n",
      "LR f1s Avg : nan\n",
      "LR f1s Standard Deviation: 0.14206645064871604\n",
      "SVM Avg: nan\n",
      "SVM Standard Deviation: 0.024233004900190563\n",
      "SVM f1s Avg : nan\n",
      "SVM f1s Standard Deviation: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "#plt.plot( (feature_num_all), lr_all_feature*100, lw=3, label='Logistic Regression')\n",
    "plt.plot( (feature_num_all), svm_all_feature*100, lw=3, label='SVM')\n",
    "plt.xlim([0, 10000])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Number of Features vs Accuracy')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('AD_SMI_ALL.eps')\n",
    "plt.show()\n",
    "\n",
    "svm_f1s=svm_f1s[np.nonzero(svm_f1s)]\n",
    "print(svm_f1s)\n",
    "print(svm_all_accs)\n",
    "\n",
    "print(\"LR accuracy Avg: {}\".format(np.mean(lr_all_feature)))\n",
    "print(\"LR accuracy Standard Deviation: {}\".format(np.std(lr_all_feature)))\n",
    "\n",
    "print(\"LR f1s Avg : {}\".format(np.mean( lr_fls_feature)))\n",
    "print(\"LR f1s Standard Deviation: {}\".format(np.std(lr_f1s)))\n",
    "\n",
    "print(\"SVM Avg: {}\".format(np.mean(svm_all_feature)))\n",
    "print(\"SVM Standard Deviation: {}\".format(np.std(svm_all_accs)))\n",
    "\n",
    "print(\"SVM f1s Avg : {}\".format(np.mean( svm_fls_feature )))\n",
    "print(\"SVM f1s Standard Deviation: {}\".format(np.std(svm_fls_feature)))\n",
    "#print(lr_all_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "clf = clf.fit(X, y)\n",
    "importances = clf.feature_importances_\n",
    "importances\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-618d75e777fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_all_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'svm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'svm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_all_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'svm'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'svm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'svm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    712\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    713\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "fpr['lr'], tpr['lr'], _ = roc_curve(base_labels, lr_all_scores)\n",
    "roc_auc['lr'] = auc(fpr['lr'], tpr['lr'])\n",
    "#f1['lr']=f1_score(fpr['lr'], tpr['lr'])\n",
    "fpr['svm'], tpr['svm'], _ = roc_curve(base_labels, svm_all_scores)\n",
    "roc_auc['svm'] = auc(fpr['svm'], tpr['svm'])\n",
    "#f1['svm']=f1_score(fpr['svm'], tpr['svm'])\n",
    "#fpr['gcn'], tpr['gcn'], _ = roc_curve(all_labels, all_scores)\n",
    "#roc_auc['gcn'] = auc(fpr['gcn'], tpr['gcn'])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr['lr'], tpr['lr'], lw=3, label='Logistic Regression (area = %0.2f)' % roc_auc['lr'] )\n",
    "#plt.plot(fpr['lr'], tpr['lr'], lw=3, label='Logistic Regression (f1 = %0.2f)' % f1['lr'] )\n",
    "plt.plot(fpr['svm'], tpr['svm'], lw=3, label='SVM (area = %0.2f)' % roc_auc['svm'] )\n",
    "#plt.plot(fpr['svm'], tpr['svm'], lw=3, label='SVM (f1 = %0.2f)' % f1['svm'] )\n",
    "#plt.plot(fpr['gcn'], tpr['gcn'], lw=3, label='GCN (area = %0.2f)' % roc_auc['gcn'])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic-MCI vs Normal')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('10x_Combined_ROC.eps')\n",
    "#plt.savefig('ROC_MCIVsNormal_connectome.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1111ad3acfb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    712\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    713\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "f1['lr']=f1_score(fpr['lr'], tpr['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_all_scores .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('../idp_jiook_local/braindata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " lr_fls_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.isnan(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.log(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

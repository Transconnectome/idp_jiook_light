{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn import linear_model, svm\n",
    "import re\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#s = \"../braindata/data_1_mor_select_100.csv\"\n",
    "import os          \n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 34728)\n",
      "[    9    17    18 ..., 34725 34726 34727]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:2247: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "10\n",
      "(30,)\n",
      "30\n",
      "(50,)\n",
      "50\n",
      "(70,)\n",
      "70\n",
      "(80,)\n",
      "80\n",
      "(100,)\n",
      "100\n",
      "(500,)\n",
      "500\n",
      "(1000,)\n",
      "1000\n",
      "(2000,)\n",
      "2000\n",
      "(3000,)\n",
      "3000\n",
      "(4000,)\n",
      "4000\n",
      "(5000,)\n",
      "5000\n",
      "(6000,)\n",
      "6000\n",
      "(7000,)\n",
      "7000\n",
      "(8000,)\n",
      "8000\n",
      "(9000,)\n",
      "9000\n",
      "(10000,)\n",
      "10000\n",
      "(13000,)\n",
      "13000\n",
      "(15000,)\n",
      "15000\n",
      "(18000,)\n",
      "18000\n",
      "(20000,)\n",
      "20000\n",
      "(25000,)\n",
      "25000\n",
      "(30000,)\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir('/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/idp_jiook/data/adni')\n",
    "dd =pd.read_csv(\"combine_new.csv\",header=0)\n",
    "print(dd.shape)\n",
    "import csv\n",
    "\n",
    "with open('combine_new.csv', 'r') as f:\n",
    "    d_reader = csv.DictReader(f)\n",
    "\n",
    "    #get fieldnames from DictReader object and store in list\n",
    "    headers = d_reader.fieldnames\n",
    "data=np.array(dd)\n",
    "#print(data.shape)\n",
    "idx_IN_columns = np.append(np.array([9,17]),np.array(range(18,data.shape[1])))\n",
    "print(idx_IN_columns)\n",
    "X=data[:,idx_IN_columns]\n",
    "#features=data[:,11:data.shape[1]]\n",
    "#features = features.transpose()\n",
    "X = stats.zscore(X)\n",
    "#print(features.shape)\n",
    "y=data[:,6]\n",
    "#/ 6:AD-normal / 7:AD-MCI / 8:MCI-normal \n",
    "\n",
    "ind_num=np.isnan(y)\n",
    "# print(ind_num.shape)\n",
    "\n",
    "\n",
    "y_no_nan = y[~ind_num]\n",
    "\n",
    "X_no_nan = X[~ind_num,:]\n",
    "\n",
    "       # print(y.shape)\n",
    "\n",
    "y=y_no_nan\n",
    "X=X_no_nan\n",
    "feature_num_all=[]\n",
    "lr_all_feature=[]\n",
    "svm_all_feature=[]\n",
    "lr_fls_feature=[]\n",
    "svm_fls_feature=[]\n",
    "base_labels= []\n",
    "\n",
    "#X=X.reshape(X.size,1)\n",
    "#X=X.astype(np.float64,copy=False)\n",
    "np.isnan(X).any()\n",
    "#feature_num=features.shape[1]\n",
    "\n",
    "X[np.isnan(X)] = np.median(X[~np.isnan(X)])\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "clf = clf.fit(X, y)\n",
    "importances = clf.feature_importances_\n",
    "importances\n",
    "indices = np.argsort(importances)[::-1]\n",
    "#print(\"Feature ranking:\")\n",
    "\n",
    "#for f in range(X.shape[1]):\n",
    "#    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "n_features = [10,30,50,70,80,100,1000,2000,13000,18000,10000,20000,3000,30000,4000,500,5000,6000,7000,8000,9000,15000,25000]\n",
    "#n_features = [1000]\n",
    "n_features.sort()\n",
    "\n",
    "for i in n_features:\n",
    "#     #print(i)\n",
    "    \n",
    "#     #lsvc = LinearSVC(C=J[i],penalty=\"l1\", dual=True).fit(X, y)\n",
    "#     #model = SelectFromModel(lsvc, prefit=True)\n",
    "#     #features = model.transform(X)\n",
    "#     clf = ExtraTreesClassifier(n_estimators=250,\n",
    "#                               random_state=0)\n",
    "#     clf = clf.fit(X, y)\n",
    "#     importances = forest.feature_importances_\n",
    "       \n",
    "    index=indices[0:i]\n",
    "    print(index.shape)\n",
    "    features=X[:,index]\n",
    "#     clf.feature_importances_ \n",
    "\n",
    "#     model = SelectFromModel(clf, threshold=0.6,prefit=True)\n",
    "#     features = model.transform(X)\n",
    "#     features.shape               \n",
    "#     #features=features.reshape(features.size,1)\n",
    "#     #features=features.astype(np.float64,copy=false)\n",
    "#     np.isnan(features).any()\n",
    "    feature_num=features.shape[1]\n",
    "    print(feature_num)\n",
    "    \n",
    "  \n",
    "    lr_all_accs = []\n",
    "    lr_all_scores = []\n",
    "    lr_f1s = []\n",
    "    svm_all_accs = []\n",
    "    svm_all_scores = []\n",
    "    svm_f1s = []\n",
    "    #base_labels = []\n",
    "    for runs in range(1):\n",
    "        lr_accuracies = []\n",
    "        lr_scores = []\n",
    "        svm_accuracies = []\n",
    "        svm_scores = []\n",
    "        strat_labels = []\n",
    "        \n",
    "        logistic = linear_model.LogisticRegression(C=1e5)\n",
    "        rbf = svm.SVC(C=10,kernel='linear',gamma=0.01)\n",
    "\n",
    "        skf=RepeatedStratifiedKFold(n_splits=10, n_repeats=2)\n",
    "        for train_index, test_index in skf.split(features, y):\n",
    "                    train_data, test_data = features[train_index], features[test_index]\n",
    "                    train_labels, test_labels = y[train_index], y[test_index]\n",
    "\n",
    "                    strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    "                    log = logistic.fit(train_data, train_labels)\n",
    "                    log_prob = log.decision_function(test_data)\n",
    "                    log_acc = log.score(test_data, test_labels)\n",
    "\n",
    "                    #f1 calculation\n",
    "                    y_pred = logistic.predict(test_data)\n",
    "                    log_f1 = f1_score(test_labels, y_pred)\n",
    "\n",
    "                    lr_accuracies = np.append(lr_accuracies, log_acc)\n",
    "                    lr_scores = np.append(lr_scores, log_prob)\n",
    "                    lr_f1s = np.append(lr_f1s, log_f1)\n",
    "                    #print('Logistic Regression Accuracy: %f' % log_acc)\n",
    "\n",
    "                    rbf = rbf.fit(train_data, train_labels)\n",
    "                    svm_acc = rbf.score(test_data, test_labels)\n",
    "                    svm_prob = rbf.decision_function(test_data)\n",
    "\n",
    "                    #f1 calculation\n",
    "                    y_pred = rbf.predict(test_data)\n",
    "                    svm_f1 = f1_score(test_labels, y_pred)\n",
    "                    #print('SVM Accuracy: %f' % svm_acc)\n",
    "                    svm_accuracies = np.append(svm_accuracies, svm_acc)\n",
    "                    svm_scores = np.append(svm_scores, svm_prob)\n",
    "                    svm_f1s = np.append(svm_f1s, svm_f1)\n",
    "                    #print('SVM f1: %f' % svm_f1)\n",
    "\n",
    "\n",
    "                    lr_all_scores = np.append(lr_all_scores, lr_scores)\n",
    "                    lr_fold_avg = np.mean(lr_accuracies)\n",
    "                    lr_all_accs = np.append(lr_all_accs, lr_fold_avg)\n",
    "                    svm_all_scores = np.append(svm_all_scores, svm_scores)\n",
    "                    svm_fold_avg = np.mean(svm_accuracies)\n",
    "                    svm_all_accs = np.append(svm_all_accs, svm_fold_avg)\n",
    "                    #print('Logistic Regression Accuracy: %f' % log_acc_avg)\n",
    "                            #print('SVM Regression Accuracy: %f' % svm_acc_avg)\n",
    "        feature_num_all=np.append(feature_num_all,feature_num)\n",
    "# print(np.mean(lr_all_accs))\n",
    "# print(np.mean(svm_all_accs))      \n",
    "        lr_all_feature=np.append(lr_all_feature,np.mean(lr_all_accs))\n",
    "        svm_all_feature=np.append(svm_all_feature,np.mean(svm_all_accs))\n",
    "        lr_fls_feature=np.append(lr_fls_feature,np.mean(lr_f1s))\n",
    "        svm_fls_feature=np.append(svm_fls_feature,np.mean(svm_f1s))\n",
    "        #base_labels_all = np.append(base_labels_all,strat)\n",
    "        base_labels = np.append(base_labels, np.mean(strat_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9650825243477138"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n",
    "np.max(lr_all_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wNnqYPzOtNc/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1106db470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot( (feature_num_all), lr_all_feature*100, lw=5, label='Logistic Regression')\n",
    "plt.plot( (feature_num_all), svm_all_feature*100, lw=5, label='SVM')\n",
    "plt.xlim([50, 30000])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('ADvsNormal')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/idp_jiook/data/ADvsNormal_combine.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy: 0.9473684210526315\n",
      "svm f1: 0.8695652173913044\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"svm accuracy: {}\".format(np.mean(svm_acc)))\n",
    "print(\"svm f1: {}\".format(np.mean(svm_f1s)))\n",
    "print(svm_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-da8518b9331f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# print(\"SVM f1s Avg : {}\".format(np.mean( svm_fls_feature )),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# print(\"SVM f1s Standard Deviation: {}\".format(np.std(svm_fls_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlrindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_all_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# print(\"LR Maximum feature number is: {}\".format(feature_num_all[lrindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msvmindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_all_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#print(svm_f1s)\n",
    "\n",
    "# print(\"LR accuracy Avg: {}\".format(np.mean(lr_all_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"LR accuracy Standard Deviation: {}\".format(np.std(lr_all_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "# print(\"LR f1s Avg : {}\".format(np.mean( lr_fls_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"LR f1s Standard Deviation: {}\".format(np.std(lr_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "# print(\"SVM Avg: {}\".format(np.mean(svm_all_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"SVM Standard Deviation: {}\".format(np.std(svm_all_accs)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "# print(\"SVM f1s Avg : {}\".format(np.mean( svm_fls_feature )),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"SVM f1s Standard Deviation: {}\".format(np.std(svm_fls_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "lrindex=np.argmax(lr_all_feature)\n",
    "# print(\"LR Maximum feature number is: {}\".format(feature_num_all[lrindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "svmindex=np.argmax(svm_all_feature)\n",
    "# print(\"SVM Maximum feature is number : {}\".format(feature_num_all[svmindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "\n",
    "# clf = ExtraTreesClassifier(n_estimators=250,\n",
    "#                               random_state=0)\n",
    "# clf = clf.fit(X, y)\n",
    "# importances = clf.feature_importances_\n",
    "# #importances\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(100):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f],headers[indices[f]],importances[indices[f]]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMI_rank.txt\", \"a\"))\n",
    "\n",
    "    \n",
    "#################################################################################################################    \n",
    "from sklearn import metrics\n",
    "\n",
    "max_features = feature_num_all[svmindex]\n",
    "print(max_features)\n",
    "lr_all_accs = []\n",
    "lr_all_scores = []\n",
    "lr_f1s = []\n",
    "svm_all_accs = []\n",
    "svm_all_scores = []\n",
    "svm_f1s = []\n",
    "base_labels = []\n",
    "lr_sensitivity= []\n",
    "svm_sensitivity=[]\n",
    "lr_specificity=[]\n",
    "svm_specificity=[]\n",
    "\n",
    "index=indices[0:int(max_features)]\n",
    "features=X[:,index]\n",
    "feature_num=features.shape[1]\n",
    "for runs in range(1):\n",
    "    lr_accuracies = []\n",
    "    lr_scores = []\n",
    "    svm_accuracies = []\n",
    "    svm_scores = []\n",
    "    strat_labels = []\n",
    "\n",
    "    logistic = linear_model.LogisticRegression(C=1e5)\n",
    "    rbf = svm.SVC(C=10,kernel='linear',gamma=0.01)\n",
    "    \n",
    "    skf=RepeatedStratifiedKFold(n_splits=10, n_repeats=10)\n",
    "    for train_index, test_index in skf.split(features, y):\n",
    "                train_data, test_data = features[train_index], features[test_index]\n",
    "                train_labels, test_labels = y[train_index], y[test_index]\n",
    "                #print(train_data.shape)\n",
    "                strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    "                log = logistic.fit(train_data, train_labels)\n",
    "                log_prob = log.decision_function(test_data)\n",
    "                log_acc = log.score(test_data, test_labels)\n",
    "\n",
    "                #f1 calculation\n",
    "                y_pred = logistic.predict(test_data)\n",
    "                log_f1 = f1_score(test_labels, y_pred)\n",
    "                log_confuse= metrics.confusion_matrix(test_labels, y_pred)\n",
    "                TP = log_confuse[1, 1]\n",
    "                TN = log_confuse[0, 0]\n",
    "                FP = log_confuse[0, 1]\n",
    "                FN = log_confuse[1, 0]\n",
    "                log_sen=metrics.recall_score(test_labels, y_pred)\n",
    "    #             print(TN)\n",
    "    #             print(FP)\n",
    "                log_spec=TN / (TN + FP)\n",
    "    #             print(log_confuse)\n",
    "    #             print(log_sen)\n",
    "    #             print(log_spec)\n",
    "\n",
    "                lr_accuracies = np.append(lr_accuracies, log_acc)\n",
    "                lr_sensitivity=np.append(lr_sensitivity, log_sen)\n",
    "                lr_specificity=np.append(lr_specificity, log_spec)\n",
    "\n",
    "                lr_scores = np.append(lr_scores, log_prob)\n",
    "                lr_f1s = np.append(lr_f1s, log_f1)\n",
    "\n",
    "                #print('Logistic Regression Accuracy: %f' % log_acc)\n",
    "\n",
    "                rbf = rbf.fit(train_data, train_labels)\n",
    "                svm_acc = rbf.score(test_data, test_labels)\n",
    "                svm_prob = rbf.decision_function(test_data)\n",
    "\n",
    "                #f1 calculation\n",
    "                y_pred = rbf.predict(test_data)\n",
    "                svm_f1 = f1_score(test_labels, y_pred)\n",
    "                svm_confuse= metrics.confusion_matrix(test_labels, y_pred)\n",
    "                TP = log_confuse[1, 1]\n",
    "                TN = log_confuse[0, 0]\n",
    "                FP = log_confuse[0, 1]\n",
    "                FN = log_confuse[1, 0]\n",
    "                svm_sen=metrics.recall_score(test_labels, y_pred)\n",
    "                svm_spec=TN / (TN + FP)\n",
    "\n",
    "\n",
    "\n",
    "                svm_accuracies = np.append(svm_accuracies, log_acc)\n",
    "                svm_sensitivity=np.append(svm_sensitivity, log_sen)\n",
    "                svm_specificity=np.append(svm_specificity, log_spec)\n",
    "\n",
    "                #print('SVM Accuracy: %f' % svm_acc)\n",
    "                svm_accuracies = np.append(svm_accuracies, svm_acc)\n",
    "                svm_scores = np.append(svm_scores, svm_prob)\n",
    "                svm_f1s = np.append(svm_f1s, svm_f1)\n",
    "\n",
    "    base_labels = np.append(base_labels, strat_labels)\n",
    "    lr_all_scores = np.append(lr_all_scores, lr_scores)\n",
    "    lr_fold_avg = np.mean(lr_accuracies)\n",
    "    lr_all_accs = np.append(lr_all_accs, lr_fold_avg)\n",
    "    svm_all_scores = np.append(svm_all_scores, svm_scores)\n",
    "    svm_fold_avg = np.mean(svm_accuracies)\n",
    "    svm_all_accs = np.append(svm_all_accs, svm_fold_avg)\n",
    "\n",
    "# feature_num_all=np.append(feature_num_all,feature_num)\n",
    "# # print(np.mean(lr_all_accs))\n",
    "print(np.mean(svm_all_accs))      \n",
    "# lr_all_feature=np.append(lr_all_feature,np.mean(lr_all_accs))\n",
    "# print(lr_all_feature)\n",
    "# svm_all_feature=np.append(svm_all_feature,np.mean(svm_all_accs))\n",
    "# print(np.mean(svm_accuracies))\n",
    "# lr_fls_feature=np.append(lr_fls_feature,np.mean(lr_f1s))\n",
    "# svm_fls_feature=np.append(svm_fls_feature,np.mean(svm_f1s))\n",
    "#base_labels_all = np.append(base_labels_all,strat)\n",
    "#base_labels = np.append(base_labels, np.mean(strat_labels))\n",
    "\n",
    "print(\"LR accuracy Avg: {}\".format(np.mean(lr_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR accuracy Standard Deviation: {}\".format(np.std(lr_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR sensitivity Avg: {}\".format(np.mean(lr_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR sensitivity Standard Deviation: {}\".format(np.std(lr_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR specificity Avg: {}\".format(np.mean(lr_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR specificity Standard Deviation: {}\".format(np.std(lr_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR f1s Avg : {}\".format(np.mean(lr_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR f1s Standard Deviation: {}\".format(np.std(lr_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "print(\"SVM Avg: {}\".format(np.mean(svm_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM Standard Deviation: {}\".format(np.std(svm_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM sensitivity Avg: {}\".format(np.mean(svm_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM sensitivity Standard Deviation: {}\".format(np.std(svm_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM specificity Avg: {}\".format(np.mean(svm_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM specificity Standard Deviation: {}\".format(np.std(svm_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM f1s Avg : {}\".format(np.mean(svm_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM f1s Standard Deviation: {}\".format(np.std(svm_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "#lrindex=np.argmax(lr_all_feature)\n",
    "print(\"LR Maximum feature number is: {}\".format(feature_num_all[lrindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "#svmindex=np.argmax(svm_all_feature)\n",
    "print(\"SVM Maximum feature is number : {}\".format(feature_num_all[svmindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "fpr['lr'], tpr['lr'], _ = roc_curve(base_labels, lr_all_scores)\n",
    "roc_auc['lr'] = auc(fpr['lr'], tpr['lr'])\n",
    "#f1['lr']=f1_score(fpr['lr'], tpr['lr'])\n",
    "fpr['svm'], tpr['svm'], _ = roc_curve(base_labels, svm_all_scores)\n",
    "roc_auc['svm'] = auc(fpr['svm'], tpr['svm'])\n",
    "#f1['svm']=f1_score(fpr['svm'], tpr['svm'])\n",
    "#fpr['gcn'], tpr['gcn'], _ = roc_curve(all_labels, all_scores)\n",
    "#roc_auc['gcn'] = auc(fpr['gcn'], tpr['gcn'])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr['lr'], tpr['lr'], lw=5, label='Logistic Regression (area = %0.2f)' % roc_auc['lr'] )\n",
    "#plt.plot(fpr['lr'], tpr['lr'], lw=3, label='Logistic Regression (f1 = %0.2f)' % f1['lr'] )\n",
    "plt.plot(fpr['svm'], tpr['svm'], lw=5, label='SVM (area = %0.2f)' % roc_auc['svm'] )\n",
    "#plt.plot(fpr['svm'], tpr['svm'f], lw=3, label='SVM (f1 = %0.2f)' % f1['svm'] )\n",
    "#plt.plot(fpr['gcn'], tpr['gcn'], lw=3, label='GCN (area = %0.2f)' % roc_auc['gcn'])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=5, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('MCIvsSMI')\n",
    "plt.legend(loc=\"lower right\") \n",
    "#plt.savefig('10x_Combined_ROC.eps')\n",
    "#plt.savefig('ROC_MCIVsNormal_connectome.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig('/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/ROC_MCIvsSMI_connectome.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

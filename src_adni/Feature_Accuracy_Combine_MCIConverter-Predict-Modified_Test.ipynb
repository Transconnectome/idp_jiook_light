{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold,GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel,VarianceThreshold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn import linear_model, svm\n",
    "import re\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#s = \"../braindata/data_1_mor_select_100.csv\"\n",
    "import os          \n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 34728)\n",
      "[    9    17    18 ..., 34725 34726 34727]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:2247: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 34712)\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........................ n_estimators=50, score=0.571429 -   0.5s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........................ n_estimators=50, score=0.692308 -   0.5s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........................ n_estimators=50, score=0.692308 -   0.5s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........................ n_estimators=50, score=0.615385 -   0.5s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........................ n_estimators=50, score=0.615385 -   0.5s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........................ n_estimators=50, score=0.615385 -   0.5s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........................ n_estimators=50, score=0.538462 -   0.5s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ........................ n_estimators=50, score=0.615385 -   0.5s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ........................ n_estimators=50, score=0.769231 -   0.4s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ........................ n_estimators=50, score=0.538462 -   0.4s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... n_estimators=100, score=0.571429 -   0.7s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.461538 -   0.7s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.538462 -   0.7s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.692308 -   0.7s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.538462 -   0.7s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.461538 -   0.7s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.538462 -   0.7s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.692308 -   0.7s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.692308 -   0.7s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.692308 -   0.7s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.571429 -   1.5s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.692308 -   1.5s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.538462 -   1.6s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.769231 -   1.6s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.461538 -   1.7s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.538462 -   1.6s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.615385 -   1.7s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.384615 -   1.8s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.615385 -   1.6s\n",
      "[CV] ....................... n_estimators=250, score=0.769231 -   1.6s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.571429 -   2.9s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.615385 -   2.9s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.461538 -   2.8s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.692308 -   2.9s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.461538 -   2.6s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.538462 -   2.6s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.538462 -   2.5s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ....................... n_estimators=500, score=0.692308 -   2.6s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ....................... n_estimators=500, score=0.615385 -   2.7s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ....................... n_estimators=500, score=0.615385 -   2.7s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.571429 -   6.0s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.692308 -   6.0s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.692308 -   6.4s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.692308 -   6.4s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.692308 -   6.1s\n",
      "[CV] ...................... n_estimators=1000, score=0.461538 -   6.3s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.538462 -   5.9s\n",
      "[CV] ...................... n_estimators=1000, score=0.615385 -   5.8s\n",
      "[CV] n_estimators=5000 ...............................................\n",
      "[CV] n_estimators=5000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.692308 -   5.2s\n",
      "[CV] n_estimators=5000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.769231 -   5.2s\n",
      "[CV] n_estimators=5000 ...............................................\n",
      "[CV] ...................... n_estimators=5000, score=0.571429 -  28.7s\n",
      "[CV] n_estimators=5000 ...............................................\n",
      "[CV] ...................... n_estimators=5000, score=0.692308 -  29.0s\n",
      "[CV] n_estimators=5000 ...............................................\n",
      "[CV] ...................... n_estimators=5000, score=0.615385 -  29.1s\n",
      "[CV] n_estimators=5000 ...............................................\n",
      "[CV] ...................... n_estimators=5000, score=0.692308 -  29.3s\n",
      "[CV] n_estimators=5000 ...............................................\n",
      "[CV] ...................... n_estimators=5000, score=0.461538 -  28.1s\n",
      "[CV] n_estimators=5000 ...............................................\n",
      "[CV] ...................... n_estimators=5000, score=0.461538 -  27.9s\n",
      "[CV] n_estimators=5000 ...............................................\n",
      "[CV] ...................... n_estimators=5000, score=0.538462 -  28.0s\n",
      "[CV] ...................... n_estimators=5000, score=0.769231 -  28.1s\n",
      "[CV] ...................... n_estimators=5000, score=0.692308 -  25.3s\n",
      "[CV] ...................... n_estimators=5000, score=0.769231 -  25.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"{'n_estimators': 1000}\",\n",
       " 0.6412213740458015,\n",
       " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/idp_jiook/data/adni')\n",
    "dd =pd.read_csv(\"combine_new.csv\",header=0)\n",
    "print(dd.shape)\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "with open('combine_new.csv', 'r') as f:\n",
    "    d_reader = csv.DictReader(f)\n",
    "\n",
    "    #get fieldnames from DictReader object and store in list\n",
    "    headers = d_reader.fieldnames\n",
    "data=np.array(dd)\n",
    "#print(data.shape)\n",
    "idx_IN_columns = np.append(np.array([9,17]),np.array(range(18,data.shape[1])))\n",
    "print(idx_IN_columns)\n",
    "X=data[:,idx_IN_columns]\n",
    "#features=data[:,11:data.shape[1]]\n",
    "#features = features.transpose()\n",
    "X = stats.zscore(X)\n",
    "#print(features.shape)\n",
    "y=data[:,8]\n",
    "#/ 6:AD-normal / 7:AD-MCI / 8:MCI-normal \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ind_num=np.isnan(y)\n",
    "# print(ind_num.shape)\n",
    "\n",
    "\n",
    "y_no_nan = y[~ind_num]\n",
    "\n",
    "X_no_nan = X[~ind_num,:]\n",
    "\n",
    "       # print(y.shape)\n",
    "\n",
    "y=y_no_nan\n",
    "X=X_no_nan\n",
    "feature_num_all=[]\n",
    "lr_all_feature=[]\n",
    "svm_all_feature=[]\n",
    "lr_fls_feature=[]\n",
    "svm_fls_feature=[]\n",
    "base_labels= []\n",
    "\n",
    "np.isnan(X).any()\n",
    "\n",
    "X[np.isnan(X)] = np.median(X[~np.isnan(X)])\n",
    "\n",
    "selector = VarianceThreshold()\n",
    "selector.fit_transform(X)\n",
    "print(X.shape)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "parameters = [{\"n_estimators\": [50,100,250, 500, 1000,5000]}]\n",
    " \n",
    "# Returns the best configuration for a model using crosvalidation\n",
    "# and grid search\n",
    "def best_config(model, parameters, train_instances, judgements):\n",
    "    clf = GridSearchCV(model, parameters, cv=10,\n",
    "                       scoring=\"accuracy\", verbose=5, n_jobs=4)\n",
    "    clf.fit(train_instances, judgements)\n",
    "    best_estimator = clf.best_estimator_\n",
    "    #log_info('Best hyperparameters: ' + str(clf.best_params_))\n",
    "    return [str(clf.best_params_), clf.best_score_, best_estimator]\n",
    "\n",
    "\n",
    "best_config(model,parameters,X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] degree=1, kernel=poly ...........................................\n",
      "[CV] degree=1, kernel=poly ...........................................\n",
      "[CV] degree=1, kernel=poly ...........................................\n",
      "[CV] degree=1, kernel=poly ...........................................\n",
      "[CV] .................. degree=1, kernel=poly, score=0.920000 -   0.7s\n",
      "[CV] degree=1, kernel=poly ...........................................\n",
      "[CV] .................. degree=1, kernel=poly, score=0.708333 -   0.7s\n",
      "[CV] degree=2, kernel=poly ...........................................\n",
      "[CV] .................. degree=1, kernel=poly, score=0.791667 -   0.7s\n",
      "[CV] degree=2, kernel=poly ...........................................\n",
      "[CV] .................. degree=1, kernel=poly, score=0.782609 -   0.7s\n",
      "[CV] degree=2, kernel=poly ...........................................\n",
      "[CV] .................. degree=1, kernel=poly, score=0.869565 -   0.7s\n",
      "[CV] degree=2, kernel=poly ...........................................\n",
      "[CV] .................. degree=2, kernel=poly, score=0.680000 -   0.7s\n",
      "[CV] degree=2, kernel=poly ...........................................\n",
      "[CV] .................. degree=2, kernel=poly, score=0.625000 -   0.7s\n",
      "[CV] degree=3, kernel=poly ...........................................\n",
      "[CV] .................. degree=2, kernel=poly, score=0.625000 -   0.7s\n",
      "[CV] degree=3, kernel=poly ...........................................\n",
      "[CV] .................. degree=2, kernel=poly, score=0.652174 -   0.7s\n",
      "[CV] degree=3, kernel=poly ...........................................\n",
      "[CV] .................. degree=2, kernel=poly, score=0.652174 -   0.7s\n",
      "[CV] degree=3, kernel=poly ...........................................\n",
      "[CV] .................. degree=3, kernel=poly, score=0.640000 -   0.7s\n",
      "[CV] degree=3, kernel=poly ...........................................\n",
      "[CV] .................. degree=3, kernel=poly, score=0.625000 -   0.7s\n",
      "[CV] degree=4, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. degree=3, kernel=poly, score=0.583333 -   0.7s\n",
      "[CV] degree=4, kernel=poly ...........................................\n",
      "[CV] .................. degree=3, kernel=poly, score=0.652174 -   0.7s\n",
      "[CV] degree=4, kernel=poly ...........................................\n",
      "[CV] .................. degree=3, kernel=poly, score=0.608696 -   0.7s\n",
      "[CV] degree=4, kernel=poly ...........................................\n",
      "[CV] .................. degree=4, kernel=poly, score=0.640000 -   0.7s\n",
      "[CV] degree=4, kernel=poly ...........................................\n",
      "[CV] .................. degree=4, kernel=poly, score=0.583333 -   0.7s\n",
      "[CV] .................. degree=4, kernel=poly, score=0.583333 -   0.7s\n",
      "[CV] .................. degree=4, kernel=poly, score=0.652174 -   0.7s\n",
      "[CV] .................. degree=4, kernel=poly, score=0.608696 -   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  18 out of  20 | elapsed:    3.7s remaining:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........................ n_estimators=50, score=0.880000 -   0.4s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........................ n_estimators=50, score=0.708333 -   0.4s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ........................ n_estimators=50, score=0.875000 -   0.4s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ........................ n_estimators=50, score=0.826087 -   0.4s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ........................ n_estimators=50, score=0.913043 -   0.4s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.920000 -   0.5s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.666667 -   0.5s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.826087 -   0.5s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.875000 -   0.6s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.913043 -   0.5s\n",
      "[CV] n_estimators=250 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... n_estimators=250, score=0.920000 -   0.8s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.958333 -   0.9s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.666667 -   1.0s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.782609 -   1.1s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.913043 -   0.9s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.880000 -   1.7s\n",
      "[CV] ....................... n_estimators=500, score=0.708333 -   1.7s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ....................... n_estimators=500, score=0.916667 -   1.6s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ....................... n_estimators=500, score=0.782609 -   2.0s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ....................... n_estimators=500, score=0.913043 -   1.5s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.920000 -   2.9s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.666667 -   2.7s\n",
      "[CV] ...................... n_estimators=1000, score=0.916667 -   3.5s\n",
      "[CV] ...................... n_estimators=1000, score=0.782609 -   3.4s\n",
      "[CV] ...................... n_estimators=1000, score=0.956522 -   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:    9.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.880000 -   0.3s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.666667 -   0.3s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.541667 -   0.3s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.695652 -   0.3s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.782609 -   0.3s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......................... n_neighbors=3, score=0.720000 -   0.3s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......................... n_neighbors=3, score=0.708333 -   0.3s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=3, score=0.625000 -   0.3s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=3, score=0.608696 -   0.3s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=3, score=0.782609 -   0.3s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.680000 -   0.3s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.750000 -   0.3s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.500000 -   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.608696 -   0.3s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.652174 -   0.3s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ......................... n_neighbors=10, score=0.680000 -   0.3s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ......................... n_neighbors=10, score=0.541667 -   0.3s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ......................... n_neighbors=10, score=0.625000 -   0.3s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ......................... n_neighbors=10, score=0.652174 -   0.3s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ......................... n_neighbors=10, score=0.739130 -   0.3s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ......................... n_neighbors=20, score=0.720000 -   0.3s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ......................... n_neighbors=20, score=0.583333 -   0.3s\n",
      "[CV] ......................... n_neighbors=20, score=0.666667 -   0.3s\n",
      "[CV] ......................... n_neighbors=20, score=0.695652 -   0.3s\n",
      "[CV] ......................... n_neighbors=20, score=0.739130 -   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"{'n_estimators': 250}\",\n",
       " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=-1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the best model from a set of model families given\n",
    "# training data using cross-validation.\n",
    "def best_model(classifier_families, train_instances, judgements):\n",
    "    best_quality = 0.6\n",
    "    best_classifier = None\n",
    "    classifiers = []\n",
    "    for name, model, parameters in classifier_families:\n",
    "        classifiers.append(best_config(model, parameters,\n",
    "                                       train_instances,\n",
    "                                       judgements))\n",
    " \n",
    "    for name, quality, classifier in classifiers:\n",
    "        if (quality > best_quality):\n",
    "            \n",
    "            best_quality = quality\n",
    "            best_classifier = [name, classifier]\n",
    " \n",
    "    return best_classifier\n",
    "\n",
    "\n",
    "# List of candidate family classifiers with parameters for grid\n",
    "# search [name, classifier object, parameters].\n",
    "def candidate_families():\n",
    "    candidates = []\n",
    "    svm_tuned_parameters = [{'kernel': ['poly'],\n",
    "                             'degree': [1, 2, 3, 4]}]\n",
    "    candidates.append([\"SVM\", SVC(C=10), svm_tuned_parameters])\n",
    "    \n",
    "    rf_tuned_parameters = [{\"n_estimators\": [50, 100,250, 500, 1000]}]\n",
    "    candidates.append([\"RandomForest\",\n",
    "                       RandomForestClassifier(n_jobs=-1),\n",
    "                       rf_tuned_parameters])\n",
    " \n",
    "    knn_tuned_parameters = [{\"n_neighbors\": [1, 3, 5, 10, 20]}]\n",
    "    candidates.append([\"kNN\", KNeighborsClassifier(),\n",
    "                       knn_tuned_parameters])\n",
    " \n",
    "    return candidates\n",
    "\n",
    "\n",
    "candidates=candidate_families()\n",
    "best_model(candidates,X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 34727)\n",
      "[    9    17    18 ..., 34724 34725 34726]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:2247: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n",
      "(10,)\n",
      "(30, 10)\n",
      "Logistic Regression Accuracy: 0.500000\n",
      "SVM Accuracy: 0.500000\n",
      "(30,)\n",
      "(30, 30)\n",
      "Logistic Regression Accuracy: 0.600000\n",
      "SVM Accuracy: 0.633333\n",
      "(50,)\n",
      "(30, 50)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.633333\n",
      "(70,)\n",
      "(30, 70)\n",
      "Logistic Regression Accuracy: 0.500000\n",
      "SVM Accuracy: 0.633333\n",
      "(80,)\n",
      "(30, 80)\n",
      "Logistic Regression Accuracy: 0.600000\n",
      "SVM Accuracy: 0.633333\n",
      "(100,)\n",
      "(30, 100)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.666667\n",
      "(500,)\n",
      "(30, 500)\n",
      "Logistic Regression Accuracy: 0.300000\n",
      "SVM Accuracy: 0.633333\n",
      "(1000,)\n",
      "(30, 1000)\n",
      "Logistic Regression Accuracy: 0.400000\n",
      "SVM Accuracy: 0.633333\n",
      "(2000,)\n",
      "(30, 2000)\n",
      "Logistic Regression Accuracy: 0.333333\n",
      "SVM Accuracy: 0.633333\n",
      "(3000,)\n",
      "(30, 3000)\n",
      "Logistic Regression Accuracy: 0.233333\n",
      "SVM Accuracy: 0.633333\n",
      "(4000,)\n",
      "(30, 4000)\n",
      "Logistic Regression Accuracy: 0.300000\n",
      "SVM Accuracy: 0.633333\n",
      "(5000,)\n",
      "(30, 5000)\n",
      "Logistic Regression Accuracy: 0.266667\n",
      "SVM Accuracy: 0.633333\n",
      "(6000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 6000)\n",
      "Logistic Regression Accuracy: 0.266667\n",
      "SVM Accuracy: 0.633333\n",
      "(7000,)\n",
      "(30, 7000)\n",
      "Logistic Regression Accuracy: 0.266667\n",
      "SVM Accuracy: 0.633333\n",
      "(8000,)\n",
      "(30, 8000)\n",
      "Logistic Regression Accuracy: 0.266667\n",
      "SVM Accuracy: 0.633333\n",
      "(9000,)\n",
      "(30, 9000)\n",
      "Logistic Regression Accuracy: 0.266667\n",
      "SVM Accuracy: 0.633333\n",
      "(10000,)\n",
      "(30, 10000)\n",
      "Logistic Regression Accuracy: 0.266667\n",
      "SVM Accuracy: 0.633333\n",
      "(13000,)\n",
      "(30, 13000)\n",
      "Logistic Regression Accuracy: 0.300000\n",
      "SVM Accuracy: 0.633333\n",
      "(15000,)\n",
      "(30, 15000)\n",
      "Logistic Regression Accuracy: 0.333333\n",
      "SVM Accuracy: 0.633333\n",
      "(18000,)\n",
      "(30, 18000)\n",
      "Logistic Regression Accuracy: 0.333333\n",
      "SVM Accuracy: 0.633333\n",
      "(20000,)\n",
      "(30, 20000)\n",
      "Logistic Regression Accuracy: 0.333333\n",
      "SVM Accuracy: 0.633333\n",
      "(25000,)\n",
      "(30, 25000)\n",
      "Logistic Regression Accuracy: 0.366667\n",
      "SVM Accuracy: 0.633333\n",
      "(30000,)\n",
      "(30, 30000)\n",
      "Logistic Regression Accuracy: 0.333333\n",
      "SVM Accuracy: 0.633333\n",
      "0.628985507246\n",
      "(30,)\n",
      "(10,)\n",
      "(30, 10)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.566667\n",
      "(30,)\n",
      "(30, 30)\n",
      "Logistic Regression Accuracy: 0.400000\n",
      "SVM Accuracy: 0.366667\n",
      "(50,)\n",
      "(30, 50)\n",
      "Logistic Regression Accuracy: 0.266667\n",
      "SVM Accuracy: 0.500000\n",
      "(70,)\n",
      "(30, 70)\n",
      "Logistic Regression Accuracy: 0.400000\n",
      "SVM Accuracy: 0.500000\n",
      "(80,)\n",
      "(30, 80)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.566667\n",
      "(100,)\n",
      "(30, 100)\n",
      "Logistic Regression Accuracy: 0.366667\n",
      "SVM Accuracy: 0.466667\n",
      "(500,)\n",
      "(30, 500)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.466667\n",
      "(1000,)\n",
      "(30, 1000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.466667\n",
      "(2000,)\n",
      "(30, 2000)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.466667\n",
      "(3000,)\n",
      "(30, 3000)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.433333\n",
      "(4000,)\n",
      "(30, 4000)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.466667\n",
      "(5000,)\n",
      "(30, 5000)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.466667\n",
      "(6000,)\n",
      "(30, 6000)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.433333\n",
      "(7000,)\n",
      "(30, 7000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.466667\n",
      "(8000,)\n",
      "(30, 8000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.466667\n",
      "(9000,)\n",
      "(30, 9000)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.433333\n",
      "(10000,)\n",
      "(30, 10000)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.500000\n",
      "(13000,)\n",
      "(30, 13000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.500000\n",
      "(15000,)\n",
      "(30, 15000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.466667\n",
      "(18000,)\n",
      "(30, 18000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.533333\n",
      "(20000,)\n",
      "(30, 20000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.500000\n",
      "(25000,)\n",
      "(30, 25000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.500000\n",
      "(30000,)\n",
      "(30, 30000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.500000\n",
      "0.591666666667\n"
     ]
    }
   ],
   "source": [
    "# clf = ExtraTreesClassifier(n_estimators=250,\n",
    "#                               random_state=0)\n",
    "# clf = clf.fit(X, y)\n",
    "# importances = clf.feature_importances_\n",
    "# importances\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# #print(\"Feature ranking:\")\n",
    "\n",
    "# #for f in range(X.shape[1]):\n",
    "# #    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "# n_features = [10,30,50,70,80,100,1000,2000,13000,18000,10000,20000,3000,30000,4000,500,5000,6000,7000,8000,9000,15000,25000]\n",
    "# #n_features = [1000]\n",
    "# n_features.sort()\n",
    "\n",
    "# for i in n_features:\n",
    "    \n",
    "       \n",
    "#     index=indices[0:i]\n",
    "#     print(index.shape)\n",
    "#     features=X[:,index]\n",
    "\n",
    "#     feature_num=features.shape[1]\n",
    "#     print(feature_num)\n",
    "#     lr_all_scores = []\n",
    "#     lr_f1s = []\n",
    "#     svm_all_accs = []\n",
    "#     svm_all_scores = []\n",
    "#     svm_f1s = []\n",
    "#     #base_labels = []\n",
    "#     #for runs in range(1):\n",
    "#         lr_accuracies = []\n",
    "#         lr_scores = []\n",
    "#         svm_accuracies = []\n",
    "#         svm_scores = []\n",
    "#         strat_labels = []\n",
    "        \n",
    "logistic = linear_model.LogisticRegression(C=1e5)\n",
    "rbf = svm.SVC(C=10,kernel='linear',gamma=0.01)\n",
    "\n",
    "skf=RepeatedStratifiedKFold(n_splits=2, n_repeats=1)\n",
    "lr_all_accs = []\n",
    "lr_all_scores = []\n",
    "lr_f1s = []\n",
    "svm_all_accs = []\n",
    "svm_all_scores = []\n",
    "svm_f1s = []\n",
    "\n",
    "lr_accuracies = []\n",
    "lr_scores = []\n",
    "svm_accuracies = []\n",
    "svm_scores = []\n",
    "strat_labels = []\n",
    "\n",
    "        \n",
    "for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "        train_data, test_data = X[train_index], X[test_index]\n",
    "        train_labels, test_labels = y[train_index], y[test_index]\n",
    "        strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    "        clf = ExtraTreesClassifier(n_estimators=10000, random_state=0)\n",
    "        clf = clf.fit(train_data, train_labels)\n",
    "        importances = clf.feature_importances_\n",
    "        importances\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        #print(\"Feature ranking:\")\n",
    "        print(train_labels.shape)\n",
    "        #for f in range(X.shape[1]):\n",
    "        #    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "        n_features = [10,30,50,70,80,100,1000,2000,13000,18000,10000,20000,3000,30000,4000,500,5000,6000,7000,8000,9000,15000,25000]\n",
    "        #n_features = [1000]\n",
    "        n_features.sort()\n",
    "\n",
    "\n",
    "\n",
    "        for i in n_features:\n",
    "\n",
    "\n",
    "            index=indices[0:i]\n",
    "            print(index.shape)\n",
    "            features=train_data[:,index]\n",
    "\n",
    "            feature_num=features.shape[1]\n",
    "            #print(feature_num)\n",
    "\n",
    "\n",
    "            #train_data, test_data = features[train_index], features[test_index]\n",
    "            #train_labels, test_labels = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            log = logistic.fit(train_data[:,index], train_labels)\n",
    "            print(train_data[:,index].shape)\n",
    "            log_prob = log.decision_function(test_data[:,index])\n",
    "            log_acc = log.score(test_data[:,index], test_labels)\n",
    "\n",
    "            #f1 calculation\n",
    "            y_pred = logistic.predict(test_data[:,index])\n",
    "            log_f1 = f1_score(test_labels, y_pred)\n",
    "\n",
    "            lr_accuracies = np.append(lr_accuracies, log_acc)\n",
    "            lr_scores = np.append(lr_scores, log_prob)\n",
    "            lr_f1s = np.append(lr_f1s, log_f1)\n",
    "            print('Logistic Regression Accuracy: %f' % log_acc)\n",
    "\n",
    "            rbf = rbf.fit(train_data[:,index], train_labels)\n",
    "            svm_acc = rbf.score(test_data[:,index], test_labels)\n",
    "            svm_prob = rbf.decision_function(test_data[:,index])\n",
    "\n",
    "            #f1 calculation\n",
    "            y_pred = rbf.predict(test_data[:,index])\n",
    "            svm_f1 = f1_score(test_labels, y_pred)\n",
    "            print('SVM Accuracy: %f' % svm_acc)\n",
    "            svm_accuracies = np.append(svm_accuracies, svm_acc)\n",
    "            svm_scores = np.append(svm_scores, svm_prob)\n",
    "            svm_f1s = np.append(svm_f1s, svm_f1)\n",
    "            #print('SVM f1: %f' % svm_f1)\n",
    "\n",
    "\n",
    "        lr_all_scores = np.append(lr_all_scores, lr_scores)\n",
    "        lr_fold_avg = np.mean(lr_accuracies)\n",
    "        lr_all_accs = np.append(lr_all_accs, lr_fold_avg)\n",
    "        svm_all_scores = np.append(svm_all_scores, svm_scores)\n",
    "        svm_fold_avg = np.mean(svm_accuracies)\n",
    "        svm_all_accs = np.append(svm_all_accs, svm_fold_avg)\n",
    "            #print('Logistic Regression Accuracy: %f' % log_acc_avg)\n",
    "                    #print('SVM Regression Accuracy: %f' % svm_acc_avg)\n",
    "        feature_num_all=np.append(feature_num_all,feature_num)\n",
    "        #print(feature_num_all)\n",
    "# print(np.mean(lr_all_accs))\n",
    "        print(np.mean(svm_all_accs))      \n",
    "        lr_all_feature=np.append(lr_all_feature,np.mean(lr_all_accs))\n",
    "        svm_all_feature=np.append(svm_all_feature,np.mean(svm_all_accs))\n",
    "        lr_fls_feature=np.append(lr_fls_feature,np.mean(lr_f1s))\n",
    "        svm_fls_feature=np.append(svm_fls_feature,np.mean(svm_f1s))\n",
    "            #base_labels_all = np.append(base_labels_all,strat)\n",
    "        base_labels = np.append(base_labels, np.mean(strat_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.62898551  0.59166667]\n"
     ]
    }
   ],
   "source": [
    "print(svm_all_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot( (feature_num_all), lr_all_feature*100, lw=5, label='Logistic Regression')\n",
    "plt.plot( (feature_num_all), svm_all_feature*100, lw=5, label='SVM')\n",
    "plt.xlim([50, 30000])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('MC converter vs non-converter')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/idp_jiook/data/MCIconvert_combine.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy: 0.9473684210526315\n",
      "svm f1: 0.8695652173913044\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"svm accuracy: {}\".format(np.mean(svm_acc)))\n",
    "print(\"svm f1: {}\".format(np.mean(svm_f1s)))\n",
    "print(svm_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-da8518b9331f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# print(\"SVM f1s Avg : {}\".format(np.mean( svm_fls_feature )),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# print(\"SVM f1s Standard Deviation: {}\".format(np.std(svm_fls_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlrindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_all_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# print(\"LR Maximum feature number is: {}\".format(feature_num_all[lrindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msvmindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_all_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#print(svm_f1s)\n",
    "\n",
    "# print(\"LR accuracy Avg: {}\".format(np.mean(lr_all_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"LR accuracy Standard Deviation: {}\".format(np.std(lr_all_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "# print(\"LR f1s Avg : {}\".format(np.mean( lr_fls_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"LR f1s Standard Deviation: {}\".format(np.std(lr_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "# print(\"SVM Avg: {}\".format(np.mean(svm_all_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"SVM Standard Deviation: {}\".format(np.std(svm_all_accs)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "# print(\"SVM f1s Avg : {}\".format(np.mean( svm_fls_feature )),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"SVM f1s Standard Deviation: {}\".format(np.std(svm_fls_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "lrindex=np.argmax(lr_all_feature)\n",
    "# print(\"LR Maximum feature number is: {}\".format(feature_num_all[lrindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "svmindex=np.argmax(svm_all_feature)\n",
    "# print(\"SVM Maximum feature is number : {}\".format(feature_num_all[svmindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "\n",
    "# clf = ExtraTreesClassifier(n_estimators=250,\n",
    "#                               random_state=0)\n",
    "# clf = clf.fit(X, y)\n",
    "# importances = clf.feature_importances_\n",
    "# #importances\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(100):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f],headers[indices[f]],importances[indices[f]]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMI_rank.txt\", \"a\"))\n",
    "\n",
    "    \n",
    "#################################################################################################################    \n",
    "from sklearn import metrics\n",
    "\n",
    "max_features = feature_num_all[svmindex]\n",
    "print(max_features)\n",
    "lr_all_accs = []\n",
    "lr_all_scores = []\n",
    "lr_f1s = []\n",
    "svm_all_accs = []\n",
    "svm_all_scores = []\n",
    "svm_f1s = []\n",
    "base_labels = []\n",
    "lr_sensitivity= []\n",
    "svm_sensitivity=[]\n",
    "lr_specificity=[]\n",
    "svm_specificity=[]\n",
    "\n",
    "index=indices[0:int(max_features)]\n",
    "features=X[:,index]\n",
    "feature_num=features.shape[1]\n",
    "for runs in range(1):\n",
    "    lr_accuracies = []\n",
    "    lr_scores = []\n",
    "    svm_accuracies = []\n",
    "    svm_scores = []\n",
    "    strat_labels = []\n",
    "\n",
    "    logistic = linear_model.LogisticRegression(C=1e5)\n",
    "    rbf = svm.SVC(C=10,kernel='linear',gamma=0.01)\n",
    "    \n",
    "    skf=RepeatedStratifiedKFold(n_splits=10, n_repeats=10)\n",
    "    for train_index, test_index in skf.split(features, y):\n",
    "                train_data, test_data = features[train_index], features[test_index]\n",
    "                train_labels, test_labels = y[train_index], y[test_index]\n",
    "                #print(train_data.shape)\n",
    "                strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    "                log = logistic.fit(train_data, train_labels)\n",
    "                log_prob = log.decision_function(test_data)\n",
    "                log_acc = log.score(test_data, test_labels)\n",
    "\n",
    "                #f1 calculation\n",
    "                y_pred = logistic.predict(test_data)\n",
    "                log_f1 = f1_score(test_labels, y_pred)\n",
    "                log_confuse= metrics.confusion_matrix(test_labels, y_pred)\n",
    "                TP = log_confuse[1, 1]\n",
    "                TN = log_confuse[0, 0]\n",
    "                FP = log_confuse[0, 1]\n",
    "                FN = log_confuse[1, 0]\n",
    "                log_sen=metrics.recall_score(test_labels, y_pred)\n",
    "    #             print(TN)\n",
    "    #             print(FP)\n",
    "                log_spec=TN / (TN + FP)\n",
    "    #             print(log_confuse)\n",
    "    #             print(log_sen)\n",
    "    #             print(log_spec)\n",
    "\n",
    "                lr_accuracies = np.append(lr_accuracies, log_acc)\n",
    "                lr_sensitivity=np.append(lr_sensitivity, log_sen)\n",
    "                lr_specificity=np.append(lr_specificity, log_spec)\n",
    "\n",
    "                lr_scores = np.append(lr_scores, log_prob)\n",
    "                lr_f1s = np.append(lr_f1s, log_f1)\n",
    "\n",
    "                #print('Logistic Regression Accuracy: %f' % log_acc)\n",
    "\n",
    "                rbf = rbf.fit(train_data, train_labels)\n",
    "                svm_acc = rbf.score(test_data, test_labels)\n",
    "                svm_prob = rbf.decision_function(test_data)\n",
    "\n",
    "                #f1 calculation\n",
    "                y_pred = rbf.predict(test_data)\n",
    "                svm_f1 = f1_score(test_labels, y_pred)\n",
    "                svm_confuse= metrics.confusion_matrix(test_labels, y_pred)\n",
    "                TP = log_confuse[1, 1]\n",
    "                TN = log_confuse[0, 0]\n",
    "                FP = log_confuse[0, 1]\n",
    "                FN = log_confuse[1, 0]\n",
    "                svm_sen=metrics.recall_score(test_labels, y_pred)\n",
    "                svm_spec=TN / (TN + FP)\n",
    "\n",
    "\n",
    "\n",
    "                svm_accuracies = np.append(svm_accuracies, log_acc)\n",
    "                svm_sensitivity=np.append(svm_sensitivity, log_sen)\n",
    "                svm_specificity=np.append(svm_specificity, log_spec)\n",
    "\n",
    "                #print('SVM Accuracy: %f' % svm_acc)\n",
    "                svm_accuracies = np.append(svm_accuracies, svm_acc)\n",
    "                svm_scores = np.append(svm_scores, svm_prob)\n",
    "                svm_f1s = np.append(svm_f1s, svm_f1)\n",
    "\n",
    "    base_labels = np.append(base_labels, strat_labels)\n",
    "    lr_all_scores = np.append(lr_all_scores, lr_scores)\n",
    "    lr_fold_avg = np.mean(lr_accuracies)\n",
    "    lr_all_accs = np.append(lr_all_accs, lr_fold_avg)\n",
    "    svm_all_scores = np.append(svm_all_scores, svm_scores)\n",
    "    svm_fold_avg = np.mean(svm_accuracies)\n",
    "    svm_all_accs = np.append(svm_all_accs, svm_fold_avg)\n",
    "\n",
    "# feature_num_all=np.append(feature_num_all,feature_num)\n",
    "# # print(np.mean(lr_all_accs))\n",
    "print(np.mean(svm_all_accs))      \n",
    "# lr_all_feature=np.append(lr_all_feature,np.mean(lr_all_accs))\n",
    "# print(lr_all_feature)\n",
    "# svm_all_feature=np.append(svm_all_feature,np.mean(svm_all_accs))\n",
    "# print(np.mean(svm_accuracies))\n",
    "# lr_fls_feature=np.append(lr_fls_feature,np.mean(lr_f1s))\n",
    "# svm_fls_feature=np.append(svm_fls_feature,np.mean(svm_f1s))\n",
    "#base_labels_all = np.append(base_labels_all,strat)\n",
    "#base_labels = np.append(base_labels, np.mean(strat_labels))\n",
    "\n",
    "print(\"LR accuracy Avg: {}\".format(np.mean(lr_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR accuracy Standard Deviation: {}\".format(np.std(lr_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR sensitivity Avg: {}\".format(np.mean(lr_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR sensitivity Standard Deviation: {}\".format(np.std(lr_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR specificity Avg: {}\".format(np.mean(lr_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR specificity Standard Deviation: {}\".format(np.std(lr_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR f1s Avg : {}\".format(np.mean(lr_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR f1s Standard Deviation: {}\".format(np.std(lr_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "print(\"SVM Avg: {}\".format(np.mean(svm_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM Standard Deviation: {}\".format(np.std(svm_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM sensitivity Avg: {}\".format(np.mean(svm_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM sensitivity Standard Deviation: {}\".format(np.std(svm_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM specificity Avg: {}\".format(np.mean(svm_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM specificity Standard Deviation: {}\".format(np.std(svm_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM f1s Avg : {}\".format(np.mean(svm_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM f1s Standard Deviation: {}\".format(np.std(svm_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "#lrindex=np.argmax(lr_all_feature)\n",
    "print(\"LR Maximum feature number is: {}\".format(feature_num_all[lrindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "#svmindex=np.argmax(svm_all_feature)\n",
    "print(\"SVM Maximum feature is number : {}\".format(feature_num_all[svmindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "fpr['lr'], tpr['lr'], _ = roc_curve(base_labels, lr_all_scores)\n",
    "roc_auc['lr'] = auc(fpr['lr'], tpr['lr'])\n",
    "#f1['lr']=f1_score(fpr['lr'], tpr['lr'])\n",
    "fpr['svm'], tpr['svm'], _ = roc_curve(base_labels, svm_all_scores)\n",
    "roc_auc['svm'] = auc(fpr['svm'], tpr['svm'])\n",
    "#f1['svm']=f1_score(fpr['svm'], tpr['svm'])\n",
    "#fpr['gcn'], tpr['gcn'], _ = roc_curve(all_labels, all_scores)\n",
    "#roc_auc['gcn'] = auc(fpr['gcn'], tpr['gcn'])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr['lr'], tpr['lr'], lw=5, label='Logistic Regression (area = %0.2f)' % roc_auc['lr'] )\n",
    "#plt.plot(fpr['lr'], tpr['lr'], lw=3, label='Logistic Regression (f1 = %0.2f)' % f1['lr'] )\n",
    "plt.plot(fpr['svm'], tpr['svm'], lw=5, label='SVM (area = %0.2f)' % roc_auc['svm'] )\n",
    "#plt.plot(fpr['svm'], tpr['svm'f], lw=3, label='SVM (f1 = %0.2f)' % f1['svm'] )\n",
    "#plt.plot(fpr['gcn'], tpr['gcn'], lw=3, label='GCN (area = %0.2f)' % roc_auc['gcn'])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=5, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('MCIvsSMI')\n",
    "plt.legend(loc=\"lower right\") \n",
    "#plt.savefig('10x_Combined_ROC.eps')\n",
    "#plt.savefig('ROC_MCIVsNormal_connectome.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig('/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/ROC_MCIvsSMI_connectome.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

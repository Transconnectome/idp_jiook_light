{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 179 entries, 0 to 178\n",
      "Columns: 16384 entries, RID to T16360\n",
      "dtypes: float64(3496), int64(12888)\n",
      "memory usage: 22.4 MB\n",
      "(179, 16384)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold,GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel,VarianceThreshold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn import linear_model, svm\n",
    "import re\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#s = \"../braindata/data_1_mor_select_100.csv\"\n",
    "import os          \n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/idp_jiook/data/adni')\n",
    "dd =pd.read_csv(\"combine_new_biomarker.csv\",header=0)\n",
    "dd.info()\n",
    "print(dd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 16384)\n",
      "[  4.08100000e+03   1.00000000e+00              nan ...,   1.50000000e+01\n",
      "   5.00000000e+00   3.00000000e+00]\n",
      "[19 20 21 22 23]\n",
      "[ nan  nan  nan  nan  nan  nan  nan   0.  nan  nan   0.  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan   0.   0.  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan   0.  nan   1.  nan   0.   0.\n",
      "  nan  nan   1.  nan  nan   0.   1.  nan  nan  nan   1.  nan  nan   0.  nan\n",
      "   1.  nan   1.   1.  nan  nan   0.   0.   0.   1.  nan   1.  nan   0.  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan   0.  nan  nan  nan  nan\n",
      "   0.  nan  nan  nan   0.   1.   0.   0.   1.  nan  nan   1.   0.   0.  nan\n",
      "  nan  nan  nan   1.  nan  nan   1.  nan  nan   0.  nan  nan  nan  nan   0.\n",
      "  nan  nan  nan  nan  nan  nan   0.   0.   0.   0.  nan   0.   0.   1.  nan\n",
      "   1.   0.   1.  nan   1.   0.   0.   0.  nan  nan  nan   0.  nan   0.   1.\n",
      "   0.  nan  nan   0.  nan  nan   1.  nan   1.   1.  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan   0.   0.  nan  nan  nan  nan]\n",
      "(60, 5)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# corr_matrix=dd.corr()\n",
    "# from pandas.tools.plotting import scatter_matrix\n",
    "# att=[\"finaldx\",\"dxbl\",\"Agebl\",\"ABETA\",\"TAU\",\"PTAU\",\"ratio1\",\"ratio2\",\"PTGENDER\"]\n",
    "# scatter_matrix(dd[att],figsize=(20,15))\n",
    "# #dd.hist(bins=3,figsize=(20,15))\n",
    "# dd.plot(kind='scatter',x='dxbl',y='ratio2')\n",
    "# dd.corr\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "with open('combine_new_biomarker.csv', 'r') as f:\n",
    "    d_reader = csv.DictReader(f)\n",
    "\n",
    "    #get fieldnames from DictReader object and store in list\n",
    "    headers = d_reader.fieldnames\n",
    "\n",
    "data=np.array(dd)\n",
    "print(data.shape)\n",
    "print(data[0])\n",
    "\n",
    "#idx_IN_columns = np.append(np.array([10,18]),np.array(range(22,data.shape[1])))\n",
    "idx_IN_columns = np.array([19,20,21,22,23])\n",
    "\n",
    "print(idx_IN_columns)\n",
    "X=data[:,idx_IN_columns]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()\n",
    "#features=data[:,11:data.shape[1]]\n",
    "#features = features.transpose()\n",
    "#X = stats.zscore(X)\n",
    "#print(features.shape)\n",
    "y=data[:,2]\n",
    "print(y)\n",
    "#/ 6:AD-normal / 7:AD-MCI / 8:MCI-normal \n",
    "\n",
    "ind_num=np.isnan(y)\n",
    "# print(ind_num.shape)\n",
    "\n",
    "\n",
    "y_no_nan = y[~ind_num]\n",
    "\n",
    "X_no_nan = X[~ind_num,:]\n",
    "\n",
    "       # print(y.shape)\n",
    "\n",
    "y=y_no_nan\n",
    "X=X_no_nan\n",
    "feature_num_all=[]\n",
    "lr_all_feature=[]\n",
    "svm_all_feature=[]\n",
    "lr_fls_feature=[]\n",
    "svm_fls_feature=[]\n",
    "base_labels= []\n",
    "\n",
    "np.isnan(X).any()\n",
    "\n",
    "X[np.isnan(X)] = np.median(X[~np.isnan(X)])\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70891640867\n",
      "0.660667007535\n",
      "0.630253825615\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold()\n",
    "selector.fit_transform(X)\n",
    "print(X.shape)\n",
    "features=X\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "# parameters = [{\"n_estimators\": [50,100,250, 500, 1000,5000]}]\n",
    " \n",
    "# Returns the best configuration for a model using crosvalidation\n",
    "# and grid search\n",
    "# def best_config(model, parameters, train_instances, judgements):\n",
    "#     clf = GridSearchCV(model, parameters, cv=5,\n",
    "#                        scoring=\"accuracy\", verbose=5, n_jobs=4)\n",
    "#     clf.fit(train_instances, judgements)\n",
    "#     best_estimator = clf.best_estimator_\n",
    "#     #log_info('Best hyperparameters: ' + str(clf.best_params_))\n",
    "#     return [str(clf.best_params_), clf.best_score_, best_estimator]\n",
    "\n",
    "\n",
    "# best_config(model,parameters,X,y)\n",
    "lr_all_accs = []\n",
    "lr_all_scores = []\n",
    "lr_f1s = []\n",
    "svm_all_accs = []\n",
    "svm_all_scores = []\n",
    "svm_f1s = []\n",
    "\n",
    "lr_accuracies = []\n",
    "lr_scores = []\n",
    "svm_accuracies = []\n",
    "svm_scores = []\n",
    "strat_labels = []\n",
    "rf_all_accs = []\n",
    "rf_all_scores = []\n",
    "rf_f1s = []\n",
    "\n",
    "rf_accuracies = []\n",
    "rf_scores = []\n",
    "logistic = linear_model.LogisticRegression(C=1e5)\n",
    "rbf = svm.SVC(C=10,kernel='linear',gamma=0.001)\n",
    "rf = ExtraTreesClassifier(n_estimators=500, random_state=0)\n",
    "\n",
    "\n",
    "skf=RepeatedStratifiedKFold(n_splits=10, n_repeats=2)\n",
    "for train_index, test_index in skf.split(features, y):\n",
    "        train_data, test_data = features[train_index], features[test_index]\n",
    "        train_labels, test_labels = y[train_index], y[test_index]\n",
    "\n",
    "        strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    "        log = logistic.fit(train_data, train_labels)\n",
    "        log_prob = log.decision_function(test_data)\n",
    "        log_acc = log.score(test_data, test_labels)\n",
    "\n",
    "        #f1 calculation\n",
    "        y_pred = logistic.predict(test_data)\n",
    "        log_f1 = f1_score(test_labels, y_pred)\n",
    "\n",
    "        lr_accuracies = np.append(lr_accuracies, log_acc)\n",
    "        lr_scores = np.append(lr_scores, log_prob)\n",
    "        lr_f1s = np.append(lr_f1s, log_f1)\n",
    "        #print('Logistic Regression Accuracy: %f' % log_acc)\n",
    "\n",
    "        rbf = rbf.fit(train_data, train_labels)\n",
    "        svm_acc = rbf.score(test_data, test_labels)\n",
    "        svm_prob = rbf.decision_function(test_data)\n",
    "\n",
    "        #f1 calculation\n",
    "        y_pred = rbf.predict(test_data)\n",
    "        svm_f1 = f1_score(test_labels, y_pred)\n",
    "        #print('SVM Accuracy: %f' % svm_acc)\n",
    "        svm_accuracies = np.append(svm_accuracies, svm_acc)\n",
    "        svm_scores = np.append(svm_scores, svm_prob)\n",
    "        svm_f1s = np.append(svm_f1s, svm_f1)\n",
    "        #print('SVM f1: %f' % svm_f1)\n",
    "\n",
    "        rf = rf.fit(train_data, train_labels)\n",
    "        rf_acc = rf.score(test_data, test_labels)\n",
    "       # rf_prob = rf.decision_function(test_data)\n",
    "\n",
    "#         #f1 calculation\n",
    "        y_pred = rf.predict(test_data)\n",
    "        rf_f1 = f1_score(test_labels, y_pred)\n",
    "       # print('Tree Accuracy: %f' % rf_acc)\n",
    "        rf_accuracies = np.append(rf_accuracies, rf_acc)\n",
    "        #rf_scores = np.append(rf_scores, rf_prob)\n",
    "        rf_f1s = np.append(rf_f1s, rf_f1)\n",
    "        #print('SVM f1: %f' % svm_f1)\n",
    "\n",
    "        lr_all_scores = np.append(lr_all_scores, lr_scores)\n",
    "        lr_fold_avg = np.mean(lr_accuracies)\n",
    "        lr_all_accs = np.append(lr_all_accs, lr_fold_avg)\n",
    "        svm_all_scores = np.append(svm_all_scores, svm_scores)\n",
    "        svm_fold_avg = np.mean(svm_accuracies)\n",
    "        svm_all_accs = np.append(svm_all_accs, svm_fold_avg)\n",
    "        svm_all_accs = np.append(svm_all_accs, svm_fold_avg)\n",
    "\n",
    "        #rf_all_scores = np.append(rf_all_scores, rf_scores)\n",
    "        rf_fold_avg = np.mean(rf_accuracies)\n",
    "        rf_all_accs = np.append(rf_all_accs, rf_fold_avg)\n",
    "        #print('Logistic Regression Accuracy: %f' % lr_acc_avg)\n",
    "        #print('SVM Regression Accuracy: %f' % svm_acc_avg)\n",
    "#  feature_num_all=np.append(feature_num_all,feature_num)\n",
    "print(np.mean(lr_all_accs))\n",
    "print(np.mean(svm_all_accs))     \n",
    "print(np.mean(rf_all_accs))      \n",
    "\n",
    "#         lr_all_feature=np.append(lr_all_feature,np.mean(lr_all_accs))\n",
    "#         svm_all_feature=np.append(svm_all_feature,np.mean(svm_all_accs))\n",
    "#         lr_fls_feature=np.append(lr_fls_feature,np.mean(lr_f1s))\n",
    "#         svm_fls_feature=np.append(svm_fls_feature,np.mean(svm_f1s))\n",
    "#         #base_labels_all = np.append(base_labels_all,strat)\n",
    "#         base_labels = np.append(base_labels, np.mean(strat_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........................ n_estimators=50, score=0.473684 -   0.1s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........................ n_estimators=50, score=0.611111 -   0.1s\n",
      "[CV] ........................ n_estimators=50, score=0.444444 -   0.1s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........................ n_estimators=50, score=0.111111 -   0.1s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........................ n_estimators=50, score=0.388889 -   0.1s\n",
      "[CV] ........................ n_estimators=50, score=0.722222 -   0.1s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ........................ n_estimators=50, score=0.388889 -   0.1s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ........................ n_estimators=50, score=0.611111 -   0.1s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ........................ n_estimators=50, score=0.411765 -   0.1s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ....................... n_estimators=100, score=0.166667 -   0.2s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.421053 -   0.2s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.444444 -   0.2s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ........................ n_estimators=50, score=0.352941 -   0.1s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.666667 -   0.1s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.388889 -   0.1s\n",
      "[CV] ....................... n_estimators=100, score=0.722222 -   0.1s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.333333 -   0.1s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.294118 -   0.1s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....................... n_estimators=100, score=0.666667 -   0.1s\n",
      "[CV] n_estimators=250 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... n_estimators=100, score=0.411765 -   0.2s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.222222 -   0.4s\n",
      "[CV] ....................... n_estimators=250, score=0.473684 -   0.4s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.444444 -   0.4s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.722222 -   0.4s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.666667 -   0.3s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.500000 -   0.4s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.333333 -   0.3s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.555556 -   0.3s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.411765 -   0.3s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....................... n_estimators=250, score=0.411765 -   0.3s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.473684 -   0.6s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.222222 -   0.6s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.444444 -   0.7s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.722222 -   0.6s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.611111 -   0.6s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.444444 -   0.6s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ....................... n_estimators=500, score=0.333333 -   0.6s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ....................... n_estimators=500, score=0.500000 -   0.6s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ....................... n_estimators=500, score=0.411765 -   0.6s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....................... n_estimators=500, score=0.470588 -   0.5s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.421053 -   1.1s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.222222 -   1.1s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.444444 -   1.1s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.722222 -   1.1s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.666667 -   1.1s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.444444 -   1.1s\n",
      "[CV] ...................... n_estimators=1000, score=0.333333 -   1.1s\n",
      "[CV] ...................... n_estimators=1000, score=0.555556 -   1.0s\n",
      "[CV] ...................... n_estimators=1000, score=0.411765 -   1.0s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ...................... n_estimators=1000, score=0.470588 -   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    6.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"{'n_estimators': 250}\",\n",
       " 0.4748603351955307,\n",
       " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "parameters = [{\"n_estimators\": [50,100,250, 500, 1000]}]\n",
    " \n",
    "def best_config(model, parameters, train_instances, judgements):\n",
    "    #log_info('Grid search for... ' + name)\n",
    "    clf = GridSearchCV(model, parameters, cv=10,\n",
    "                       scoring=\"accuracy\", verbose=5, n_jobs=4)\n",
    "    clf.fit(train_instances, judgements)\n",
    "    best_estimator = clf.best_estimator_\n",
    "    #log_info('Best hyperparameters: ' + str(clf.best_params_))\n",
    " \n",
    "    return [str(clf.best_params_), clf.best_score_,\n",
    "            best_estimator]\n",
    "best_config(model,parameters,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.001}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, grid_search\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "\n",
    "svc_param_selection(X,y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] degree=1, kernel=poly ...........................................\n",
      "[CV] degree=1, kernel=poly ...........................................\n",
      "[CV] degree=1, kernel=poly ...........................................\n",
      "[CV] degree=1, kernel=poly ...........................................\n",
      "[CV] .................. degree=1, kernel=poly, score=0.666667 -   0.2s\n",
      "[CV] degree=1, kernel=poly ...........................................\n",
      "[CV] .................. degree=1, kernel=poly, score=0.653846 -   0.2s\n",
      "[CV] degree=2, kernel=poly ...........................................\n",
      "[CV] .................. degree=1, kernel=poly, score=0.500000 -   0.4s\n",
      "[CV] degree=2, kernel=poly ...........................................\n",
      "[CV] .................. degree=1, kernel=poly, score=0.730769 -   0.4s\n",
      "[CV] degree=2, kernel=poly ...........................................\n",
      "[CV] .................. degree=1, kernel=poly, score=0.653846 -   0.4s\n",
      "[CV] degree=2, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   3 out of  10 | elapsed:    0.4s remaining:    0.9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-f19c03e68861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcandidate_families\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-98-f19c03e68861>\u001b[0m in \u001b[0;36mbest_model\u001b[0;34m(classifier_families, train_instances, judgements)\u001b[0m\n\u001b[1;32m     20\u001b[0m         classifiers.append(best_config(model, parameters,\n\u001b[1;32m     21\u001b[0m                                        \u001b[0mtrain_instances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                        judgements))\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-f19c03e68861>\u001b[0m in \u001b[0;36mbest_config\u001b[0;34m(model, parameters, train_instances, judgements)\u001b[0m\n\u001b[1;32m      5\u001b[0m     clf = GridSearchCV(model, parameters, cv=5,\n\u001b[1;32m      6\u001b[0m                        scoring=\"accuracy\", verbose=5, n_jobs=4)\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_instances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjudgements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mbest_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#log_info('Best hyperparameters: ' + str(clf.best_params_))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[0;32m--> 838\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 for train, test in cv)\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Returns the best model from a set of model families given\n",
    "# training data using cross-validation.\n",
    "def best_config(model, parameters, train_instances, judgements):\n",
    "    #log_info('Grid search for... ' + name)\n",
    "    clf = GridSearchCV(model, parameters, cv=5,\n",
    "                       scoring=\"accuracy\", verbose=5, n_jobs=4)\n",
    "    clf.fit(train_instances, judgements)\n",
    "    best_estimator = clf.best_estimator_\n",
    "    #log_info('Best hyperparameters: ' + str(clf.best_params_))\n",
    " \n",
    "    return [str(clf.best_params_), clf.best_score_,\n",
    "            best_estimator]\n",
    "\n",
    "\n",
    "def best_model(classifier_families, train_instances, judgements):\n",
    "    best_quality = 0.9\n",
    "    best_classifier = None\n",
    "    classifiers = []\n",
    "    for name, model, parameters in classifier_families:\n",
    "        classifiers.append(best_config(model, parameters,\n",
    "                                       train_instances,\n",
    "                                       judgements))\n",
    " \n",
    "    for name, quality, classifier in classifiers:\n",
    "        if (quality > best_quality):\n",
    "            \n",
    "            best_quality = quality\n",
    "            best_classifier = [name, classifier]\n",
    " \n",
    "    return best_classifier\n",
    "\n",
    "\n",
    "# List of candidate family classifiers with parameters for grid\n",
    "# search [name, classifier object, parameters].\n",
    "def candidate_families():\n",
    "    candidates = []\n",
    "    svm_tuned_parameters = [{'kernel': ['poly'],\n",
    "                             'degree': [1, 2]}]\n",
    "    candidates.append([\"SVM\", SVC(C=10), svm_tuned_parameters])\n",
    "    \n",
    "    rf_tuned_parameters = [{\"n_estimators\": [50, 100,250, 500, 1000]}]\n",
    "    candidates.append([\"RandomForest\",\n",
    "                       RandomForestClassifier(n_jobs=-1),\n",
    "                       rf_tuned_parameters])\n",
    " #     knn_tuned_parameters = [{\"n_neighbors\": [1, 3, 5, 10, 20]}]\n",
    "#     candidates.append([\"kNN\", KNeighborsClassifier(),\n",
    "#                        knn_tuned_parameters])\n",
    " \n",
    "    return candidates\n",
    "\n",
    "\n",
    "candidates=candidate_families()\n",
    "best_model(candidates,X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 34727)\n",
      "[    9    17    18 ..., 34724 34725 34726]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:2247: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n",
      "(10,)\n",
      "(30, 10)\n",
      "Logistic Regression Accuracy: 0.500000\n",
      "SVM Accuracy: 0.500000\n",
      "(30,)\n",
      "(30, 30)\n",
      "Logistic Regression Accuracy: 0.600000\n",
      "SVM Accuracy: 0.633333\n",
      "(50,)\n",
      "(30, 50)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.633333\n",
      "(70,)\n",
      "(30, 70)\n",
      "Logistic Regression Accuracy: 0.500000\n",
      "SVM Accuracy: 0.633333\n",
      "(80,)\n",
      "(30, 80)\n",
      "Logistic Regression Accuracy: 0.600000\n",
      "SVM Accuracy: 0.633333\n",
      "(100,)\n",
      "(30, 100)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.666667\n",
      "(500,)\n",
      "(30, 500)\n",
      "Logistic Regression Accuracy: 0.300000\n",
      "SVM Accuracy: 0.633333\n",
      "(1000,)\n",
      "(30, 1000)\n",
      "Logistic Regression Accuracy: 0.400000\n",
      "SVM Accuracy: 0.633333\n",
      "(2000,)\n",
      "(30, 2000)\n",
      "Logistic Regression Accuracy: 0.333333\n",
      "SVM Accuracy: 0.633333\n",
      "(3000,)\n",
      "(30, 3000)\n",
      "Logistic Regression Accuracy: 0.233333\n",
      "SVM Accuracy: 0.633333\n",
      "(4000,)\n",
      "(30, 4000)\n",
      "Logistic Regression Accuracy: 0.300000\n",
      "SVM Accuracy: 0.633333\n",
      "(5000,)\n",
      "(30, 5000)\n",
      "Logistic Regression Accuracy: 0.266667\n",
      "SVM Accuracy: 0.633333\n",
      "(6000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 6000)\n",
      "Logistic Regression Accuracy: 0.266667\n",
      "SVM Accuracy: 0.633333\n",
      "(7000,)\n",
      "(30, 7000)\n",
      "Logistic Regression Accuracy: 0.266667\n",
      "SVM Accuracy: 0.633333\n",
      "(8000,)\n",
      "(30, 8000)\n",
      "Logistic Regression Accuracy: 0.266667\n",
      "SVM Accuracy: 0.633333\n",
      "(9000,)\n",
      "(30, 9000)\n",
      "Logistic Regression Accuracy: 0.266667\n",
      "SVM Accuracy: 0.633333\n",
      "(10000,)\n",
      "(30, 10000)\n",
      "Logistic Regression Accuracy: 0.266667\n",
      "SVM Accuracy: 0.633333\n",
      "(13000,)\n",
      "(30, 13000)\n",
      "Logistic Regression Accuracy: 0.300000\n",
      "SVM Accuracy: 0.633333\n",
      "(15000,)\n",
      "(30, 15000)\n",
      "Logistic Regression Accuracy: 0.333333\n",
      "SVM Accuracy: 0.633333\n",
      "(18000,)\n",
      "(30, 18000)\n",
      "Logistic Regression Accuracy: 0.333333\n",
      "SVM Accuracy: 0.633333\n",
      "(20000,)\n",
      "(30, 20000)\n",
      "Logistic Regression Accuracy: 0.333333\n",
      "SVM Accuracy: 0.633333\n",
      "(25000,)\n",
      "(30, 25000)\n",
      "Logistic Regression Accuracy: 0.366667\n",
      "SVM Accuracy: 0.633333\n",
      "(30000,)\n",
      "(30, 30000)\n",
      "Logistic Regression Accuracy: 0.333333\n",
      "SVM Accuracy: 0.633333\n",
      "0.628985507246\n",
      "(30,)\n",
      "(10,)\n",
      "(30, 10)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.566667\n",
      "(30,)\n",
      "(30, 30)\n",
      "Logistic Regression Accuracy: 0.400000\n",
      "SVM Accuracy: 0.366667\n",
      "(50,)\n",
      "(30, 50)\n",
      "Logistic Regression Accuracy: 0.266667\n",
      "SVM Accuracy: 0.500000\n",
      "(70,)\n",
      "(30, 70)\n",
      "Logistic Regression Accuracy: 0.400000\n",
      "SVM Accuracy: 0.500000\n",
      "(80,)\n",
      "(30, 80)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.566667\n",
      "(100,)\n",
      "(30, 100)\n",
      "Logistic Regression Accuracy: 0.366667\n",
      "SVM Accuracy: 0.466667\n",
      "(500,)\n",
      "(30, 500)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.466667\n",
      "(1000,)\n",
      "(30, 1000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.466667\n",
      "(2000,)\n",
      "(30, 2000)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.466667\n",
      "(3000,)\n",
      "(30, 3000)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.433333\n",
      "(4000,)\n",
      "(30, 4000)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.466667\n",
      "(5000,)\n",
      "(30, 5000)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.466667\n",
      "(6000,)\n",
      "(30, 6000)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.433333\n",
      "(7000,)\n",
      "(30, 7000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.466667\n",
      "(8000,)\n",
      "(30, 8000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.466667\n",
      "(9000,)\n",
      "(30, 9000)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.433333\n",
      "(10000,)\n",
      "(30, 10000)\n",
      "Logistic Regression Accuracy: 0.433333\n",
      "SVM Accuracy: 0.500000\n",
      "(13000,)\n",
      "(30, 13000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.500000\n",
      "(15000,)\n",
      "(30, 15000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.466667\n",
      "(18000,)\n",
      "(30, 18000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.533333\n",
      "(20000,)\n",
      "(30, 20000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.500000\n",
      "(25000,)\n",
      "(30, 25000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.500000\n",
      "(30000,)\n",
      "(30, 30000)\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "SVM Accuracy: 0.500000\n",
      "0.591666666667\n"
     ]
    }
   ],
   "source": [
    "# clf = ExtraTreesClassifier(n_estimators=250,\n",
    "#                               random_state=0)\n",
    "# clf = clf.fit(X, y)\n",
    "# importances = clf.feature_importances_\n",
    "# importances\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# #print(\"Feature ranking:\")\n",
    "\n",
    "# #for f in range(X.shape[1]):\n",
    "# #    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "# n_features = [10,30,50,70,80,100,1000,2000,13000,18000,10000,20000,3000,30000,4000,500,5000,6000,7000,8000,9000,15000,25000]\n",
    "# #n_features = [1000]\n",
    "# n_features.sort()\n",
    "\n",
    "# for i in n_features:\n",
    "    \n",
    "       \n",
    "#     index=indices[0:i]\n",
    "#     print(index.shape)\n",
    "#     features=X[:,index]\n",
    "\n",
    "#     feature_num=features.shape[1]\n",
    "#     print(feature_num)\n",
    "#     lr_all_scores = []\n",
    "#     lr_f1s = []\n",
    "#     svm_all_accs = []\n",
    "#     svm_all_scores = []\n",
    "#     svm_f1s = []\n",
    "#     #base_labels = []\n",
    "#     #for runs in range(1):\n",
    "#         lr_accuracies = []\n",
    "#         lr_scores = []\n",
    "#         svm_accuracies = []\n",
    "#         svm_scores = []\n",
    "#         strat_labels = []\n",
    "        \n",
    "logistic = linear_model.LogisticRegression(C=1e5)\n",
    "rbf = svm.SVC(C=10,kernel='linear',gamma=0.01)\n",
    "\n",
    "skf=RepeatedStratifiedKFold(n_splits=2, n_repeats=1)\n",
    "lr_all_accs = []\n",
    "lr_all_scores = []\n",
    "lr_f1s = []\n",
    "svm_all_accs = []\n",
    "svm_all_scores = []\n",
    "svm_f1s = []\n",
    "\n",
    "lr_accuracies = []\n",
    "lr_scores = []\n",
    "svm_accuracies = []\n",
    "svm_scores = []\n",
    "strat_labels = []\n",
    "\n",
    "        \n",
    "for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "        train_data, test_data = X[train_index], X[test_index]\n",
    "        train_labels, test_labels = y[train_index], y[test_index]\n",
    "        strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    "        clf = ExtraTreesClassifier(n_estimators=10000, random_state=0)\n",
    "        clf = clf.fit(train_data, train_labels)\n",
    "        importances = clf.feature_importances_\n",
    "        importances\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        #print(\"Feature ranking:\")\n",
    "        print(train_labels.shape)\n",
    "        #for f in range(X.shape[1]):\n",
    "        #    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "        n_features = [10,30,50,70,80,100,1000,2000,13000,18000,10000,20000,3000,30000,4000,500,5000,6000,7000,8000,9000,15000,25000]\n",
    "        #n_features = [1000]\n",
    "        n_features.sort()\n",
    "\n",
    "\n",
    "\n",
    "        for i in n_features:\n",
    "\n",
    "\n",
    "            index=indices[0:i]\n",
    "            print(index.shape)\n",
    "            features=train_data[:,index]\n",
    "\n",
    "            feature_num=features.shape[1]\n",
    "            #print(feature_num)\n",
    "\n",
    "\n",
    "            #train_data, test_data = features[train_index], features[test_index]\n",
    "            #train_labels, test_labels = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            log = logistic.fit(train_data[:,index], train_labels)\n",
    "            print(train_data[:,index].shape)\n",
    "            log_prob = log.decision_function(test_data[:,index])\n",
    "            log_acc = log.score(test_data[:,index], test_labels)\n",
    "\n",
    "            #f1 calculation\n",
    "            y_pred = logistic.predict(test_data[:,index])\n",
    "            log_f1 = f1_score(test_labels, y_pred)\n",
    "\n",
    "            lr_accuracies = np.append(lr_accuracies, log_acc)\n",
    "            lr_scores = np.append(lr_scores, log_prob)\n",
    "            lr_f1s = np.append(lr_f1s, log_f1)\n",
    "            print('Logistic Regression Accuracy: %f' % log_acc)\n",
    "\n",
    "            rbf = rbf.fit(train_data[:,index], train_labels)\n",
    "            svm_acc = rbf.score(test_data[:,index], test_labels)\n",
    "            svm_prob = rbf.decision_function(test_data[:,index])\n",
    "\n",
    "            #f1 calculation\n",
    "            y_pred = rbf.predict(test_data[:,index])\n",
    "            svm_f1 = f1_score(test_labels, y_pred)\n",
    "            print('SVM Accuracy: %f' % svm_acc)\n",
    "            svm_accuracies = np.append(svm_accuracies, svm_acc)\n",
    "            svm_scores = np.append(svm_scores, svm_prob)\n",
    "            svm_f1s = np.append(svm_f1s, svm_f1)\n",
    "            #print('SVM f1: %f' % svm_f1)\n",
    "\n",
    "\n",
    "        lr_all_scores = np.append(lr_all_scores, lr_scores)\n",
    "        lr_fold_avg = np.mean(lr_accuracies)\n",
    "        lr_all_accs = np.append(lr_all_accs, lr_fold_avg)\n",
    "        svm_all_scores = np.append(svm_all_scores, svm_scores)\n",
    "        svm_fold_avg = np.mean(svm_accuracies)\n",
    "        svm_all_accs = np.append(svm_all_accs, svm_fold_avg)\n",
    "            #print('Logistic Regression Accuracy: %f' % log_acc_avg)\n",
    "                    #print('SVM Regression Accuracy: %f' % svm_acc_avg)\n",
    "        feature_num_all=np.append(feature_num_all,feature_num)\n",
    "        #print(feature_num_all)\n",
    "# print(np.mean(lr_all_accs))\n",
    "        print(np.mean(svm_all_accs))      \n",
    "        lr_all_feature=np.append(lr_all_feature,np.mean(lr_all_accs))\n",
    "        svm_all_feature=np.append(svm_all_feature,np.mean(svm_all_accs))\n",
    "        lr_fls_feature=np.append(lr_fls_feature,np.mean(lr_f1s))\n",
    "        svm_fls_feature=np.append(svm_fls_feature,np.mean(svm_f1s))\n",
    "            #base_labels_all = np.append(base_labels_all,strat)\n",
    "        base_labels = np.append(base_labels, np.mean(strat_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.62898551  0.59166667]\n"
     ]
    }
   ],
   "source": [
    "print(svm_all_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot( (feature_num_all), lr_all_feature*100, lw=5, label='Logistic Regression')\n",
    "plt.plot( (feature_num_all), svm_all_feature*100, lw=5, label='SVM')\n",
    "plt.xlim([50, 30000])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('MC converter vs non-converter')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/idp_jiook/data/MCIconvert_combine.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy: 0.9473684210526315\n",
      "svm f1: 0.8695652173913044\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"svm accuracy: {}\".format(np.mean(svm_acc)))\n",
    "print(\"svm f1: {}\".format(np.mean(svm_f1s)))\n",
    "print(svm_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-da8518b9331f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# print(\"SVM f1s Avg : {}\".format(np.mean( svm_fls_feature )),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# print(\"SVM f1s Standard Deviation: {}\".format(np.std(svm_fls_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlrindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_all_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# print(\"LR Maximum feature number is: {}\".format(feature_num_all[lrindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msvmindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_all_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#print(svm_f1s)\n",
    "\n",
    "# print(\"LR accuracy Avg: {}\".format(np.mean(lr_all_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"LR accuracy Standard Deviation: {}\".format(np.std(lr_all_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "# print(\"LR f1s Avg : {}\".format(np.mean( lr_fls_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"LR f1s Standard Deviation: {}\".format(np.std(lr_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "# print(\"SVM Avg: {}\".format(np.mean(svm_all_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"SVM Standard Deviation: {}\".format(np.std(svm_all_accs)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "# print(\"SVM f1s Avg : {}\".format(np.mean( svm_fls_feature )),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"SVM f1s Standard Deviation: {}\".format(np.std(svm_fls_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "lrindex=np.argmax(lr_all_feature)\n",
    "# print(\"LR Maximum feature number is: {}\".format(feature_num_all[lrindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "svmindex=np.argmax(svm_all_feature)\n",
    "# print(\"SVM Maximum feature is number : {}\".format(feature_num_all[svmindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "\n",
    "# clf = ExtraTreesClassifier(n_estimators=250,\n",
    "#                               random_state=0)\n",
    "# clf = clf.fit(X, y)\n",
    "# importances = clf.feature_importances_\n",
    "# #importances\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(100):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f],headers[indices[f]],importances[indices[f]]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMI_rank.txt\", \"a\"))\n",
    "\n",
    "    \n",
    "#################################################################################################################    \n",
    "from sklearn import metrics\n",
    "\n",
    "max_features = feature_num_all[svmindex]\n",
    "print(max_features)\n",
    "lr_all_accs = []\n",
    "lr_all_scores = []\n",
    "lr_f1s = []\n",
    "svm_all_accs = []\n",
    "svm_all_scores = []\n",
    "svm_f1s = []\n",
    "base_labels = []\n",
    "lr_sensitivity= []\n",
    "svm_sensitivity=[]\n",
    "lr_specificity=[]\n",
    "svm_specificity=[]\n",
    "\n",
    "index=indices[0:int(max_features)]\n",
    "features=X[:,index]\n",
    "feature_num=features.shape[1]\n",
    "for runs in range(1):\n",
    "    lr_accuracies = []\n",
    "    lr_scores = []\n",
    "    svm_accuracies = []\n",
    "    svm_scores = []\n",
    "    strat_labels = []\n",
    "\n",
    "    logistic = linear_model.LogisticRegression(C=1e5)\n",
    "    rbf = svm.SVC(C=10,kernel='linear',gamma=0.01)\n",
    "    \n",
    "    skf=RepeatedStratifiedKFold(n_splits=10, n_repeats=10)\n",
    "    for train_index, test_index in skf.split(features, y):\n",
    "                train_data, test_data = features[train_index], features[test_index]\n",
    "                train_labels, test_labels = y[train_index], y[test_index]\n",
    "                #print(train_data.shape)\n",
    "                strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    "                log = logistic.fit(train_data, train_labels)\n",
    "                log_prob = log.decision_function(test_data)\n",
    "                log_acc = log.score(test_data, test_labels)\n",
    "\n",
    "                #f1 calculation\n",
    "                y_pred = logistic.predict(test_data)\n",
    "                log_f1 = f1_score(test_labels, y_pred)\n",
    "                log_confuse= metrics.confusion_matrix(test_labels, y_pred)\n",
    "                TP = log_confuse[1, 1]\n",
    "                TN = log_confuse[0, 0]\n",
    "                FP = log_confuse[0, 1]\n",
    "                FN = log_confuse[1, 0]\n",
    "                log_sen=metrics.recall_score(test_labels, y_pred)\n",
    "    #             print(TN)\n",
    "    #             print(FP)\n",
    "                log_spec=TN / (TN + FP)\n",
    "    #             print(log_confuse)\n",
    "    #             print(log_sen)\n",
    "    #             print(log_spec)\n",
    "\n",
    "                lr_accuracies = np.append(lr_accuracies, log_acc)\n",
    "                lr_sensitivity=np.append(lr_sensitivity, log_sen)\n",
    "                lr_specificity=np.append(lr_specificity, log_spec)\n",
    "\n",
    "                lr_scores = np.append(lr_scores, log_prob)\n",
    "                lr_f1s = np.append(lr_f1s, log_f1)\n",
    "\n",
    "                #print('Logistic Regression Accuracy: %f' % log_acc)\n",
    "\n",
    "                rbf = rbf.fit(train_data, train_labels)\n",
    "                svm_acc = rbf.score(test_data, test_labels)\n",
    "                svm_prob = rbf.decision_function(test_data)\n",
    "\n",
    "                #f1 calculation\n",
    "                y_pred = rbf.predict(test_data)\n",
    "                svm_f1 = f1_score(test_labels, y_pred)\n",
    "                svm_confuse= metrics.confusion_matrix(test_labels, y_pred)\n",
    "                TP = log_confuse[1, 1]\n",
    "                TN = log_confuse[0, 0]\n",
    "                FP = log_confuse[0, 1]\n",
    "                FN = log_confuse[1, 0]\n",
    "                svm_sen=metrics.recall_score(test_labels, y_pred)\n",
    "                svm_spec=TN / (TN + FP)\n",
    "\n",
    "\n",
    "\n",
    "                svm_accuracies = np.append(svm_accuracies, log_acc)\n",
    "                svm_sensitivity=np.append(svm_sensitivity, log_sen)\n",
    "                svm_specificity=np.append(svm_specificity, log_spec)\n",
    "\n",
    "                #print('SVM Accuracy: %f' % svm_acc)\n",
    "                svm_accuracies = np.append(svm_accuracies, svm_acc)\n",
    "                svm_scores = np.append(svm_scores, svm_prob)\n",
    "                svm_f1s = np.append(svm_f1s, svm_f1)\n",
    "\n",
    "    base_labels = np.append(base_labels, strat_labels)\n",
    "    lr_all_scores = np.append(lr_all_scores, lr_scores)\n",
    "    lr_fold_avg = np.mean(lr_accuracies)\n",
    "    lr_all_accs = np.append(lr_all_accs, lr_fold_avg)\n",
    "    svm_all_scores = np.append(svm_all_scores, svm_scores)\n",
    "    svm_fold_avg = np.mean(svm_accuracies)\n",
    "    svm_all_accs = np.append(svm_all_accs, svm_fold_avg)\n",
    "\n",
    "# feature_num_all=np.append(feature_num_all,feature_num)\n",
    "# # print(np.mean(lr_all_accs))\n",
    "print(np.mean(svm_all_accs))      \n",
    "# lr_all_feature=np.append(lr_all_feature,np.mean(lr_all_accs))\n",
    "# print(lr_all_feature)\n",
    "# svm_all_feature=np.append(svm_all_feature,np.mean(svm_all_accs))\n",
    "# print(np.mean(svm_accuracies))\n",
    "# lr_fls_feature=np.append(lr_fls_feature,np.mean(lr_f1s))\n",
    "# svm_fls_feature=np.append(svm_fls_feature,np.mean(svm_f1s))\n",
    "#base_labels_all = np.append(base_labels_all,strat)\n",
    "#base_labels = np.append(base_labels, np.mean(strat_labels))\n",
    "\n",
    "print(\"LR accuracy Avg: {}\".format(np.mean(lr_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR accuracy Standard Deviation: {}\".format(np.std(lr_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR sensitivity Avg: {}\".format(np.mean(lr_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR sensitivity Standard Deviation: {}\".format(np.std(lr_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR specificity Avg: {}\".format(np.mean(lr_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR specificity Standard Deviation: {}\".format(np.std(lr_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR f1s Avg : {}\".format(np.mean(lr_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR f1s Standard Deviation: {}\".format(np.std(lr_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "print(\"SVM Avg: {}\".format(np.mean(svm_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM Standard Deviation: {}\".format(np.std(svm_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM sensitivity Avg: {}\".format(np.mean(svm_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM sensitivity Standard Deviation: {}\".format(np.std(svm_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM specificity Avg: {}\".format(np.mean(svm_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM specificity Standard Deviation: {}\".format(np.std(svm_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM f1s Avg : {}\".format(np.mean(svm_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM f1s Standard Deviation: {}\".format(np.std(svm_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "#lrindex=np.argmax(lr_all_feature)\n",
    "print(\"LR Maximum feature number is: {}\".format(feature_num_all[lrindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "#svmindex=np.argmax(svm_all_feature)\n",
    "print(\"SVM Maximum feature is number : {}\".format(feature_num_all[svmindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "fpr['lr'], tpr['lr'], _ = roc_curve(base_labels, lr_all_scores)\n",
    "roc_auc['lr'] = auc(fpr['lr'], tpr['lr'])\n",
    "#f1['lr']=f1_score(fpr['lr'], tpr['lr'])\n",
    "fpr['svm'], tpr['svm'], _ = roc_curve(base_labels, svm_all_scores)\n",
    "roc_auc['svm'] = auc(fpr['svm'], tpr['svm'])\n",
    "#f1['svm']=f1_score(fpr['svm'], tpr['svm'])\n",
    "#fpr['gcn'], tpr['gcn'], _ = roc_curve(all_labels, all_scores)\n",
    "#roc_auc['gcn'] = auc(fpr['gcn'], tpr['gcn'])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr['lr'], tpr['lr'], lw=5, label='Logistic Regression (area = %0.2f)' % roc_auc['lr'] )\n",
    "#plt.plot(fpr['lr'], tpr['lr'], lw=3, label='Logistic Regression (f1 = %0.2f)' % f1['lr'] )\n",
    "plt.plot(fpr['svm'], tpr['svm'], lw=5, label='SVM (area = %0.2f)' % roc_auc['svm'] )\n",
    "#plt.plot(fpr['svm'], tpr['svm'f], lw=3, label='SVM (f1 = %0.2f)' % f1['svm'] )\n",
    "#plt.plot(fpr['gcn'], tpr['gcn'], lw=3, label='GCN (area = %0.2f)' % roc_auc['gcn'])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=5, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('MCIvsSMI')\n",
    "plt.legend(loc=\"lower right\") \n",
    "#plt.savefig('10x_Combined_ROC.eps')\n",
    "#plt.savefig('ROC_MCIVsNormal_connectome.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig('/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/ROC_MCIvsSMI_connectome.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

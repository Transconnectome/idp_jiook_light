{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished this block\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn import linear_model, svm\n",
    "import re\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#s = \"../braindata/data_1_mor_select_100.csv\"\n",
    "import os          \n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "print('finished this block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished this block\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir('../data/adni')\n",
    "print('finished this block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the original training data dimension is\n",
      "(179, 34733)\n"
     ]
    }
   ],
   "source": [
    "dd =pd.read_csv(\"combine_new_biomarker_correct.csv\",header=0)\n",
    "print('the original training data dimension is')\n",
    "print(dd.shape)\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:2248: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after the precoessing, the X.shape is \n",
      "(179, 34712)\n",
      "the y.shape is\n",
      "(179,)\n",
      "the number of MCI case is\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "with open('combine_new_biomarker_correct.csv', 'r') as f:\n",
    "    d_reader = csv.DictReader(f)\n",
    "    #get fieldnames from DictReader object and store in list\n",
    "    headers = d_reader.fieldnames\n",
    "    \n",
    "data=np.array(dd)\n",
    "\n",
    "idx_IN_columns = np.append(np.array([14,22]), np.array(range(23,data.shape[1])))\n",
    "\n",
    "X=data[:,idx_IN_columns]\n",
    "#X_biomarker=X[:,0:5]\n",
    "\n",
    "y=data[:, 9]  \n",
    "y_dxbl=data[:,10]\n",
    "\n",
    "#ind_num_matrix=np.isnan(X_biomarker)\n",
    "#ind_num_vector=np.any(ind_num_matrix,axis=1)\n",
    "\n",
    "#X_no_nan=X[~ind_num_vector,:]\n",
    "#y_no_nan=y[~ind_num_vector]\n",
    "#y_dxbl_no_nan = y_dxbl[~ind_num_vector]\n",
    "\n",
    "#X=X_no_nan\n",
    "#y=y_no_nan\n",
    "#y_dxbl=y_dxbl_no_nan\n",
    "\n",
    "MCI = (y_dxbl==2)\n",
    "MCI_index =[ i for i in range(0, MCI.shape[0]) if MCI[i]]\n",
    "\n",
    "\n",
    "X = stats.zscore(X)\n",
    "\n",
    "feature_num_all=[]\n",
    "\n",
    "lr_all_feature=[]\n",
    "svm_all_feature=[]\n",
    "XGreg_all_feature=[]\n",
    "\n",
    "\n",
    "lr_fls_feature=[]\n",
    "svm_fls_feature=[]\n",
    "XGB_f1s_feature=[]\n",
    "\n",
    "base_labels= []\n",
    "\n",
    "\n",
    "np.isnan(X).any()\n",
    "X[np.isnan(X)] = np.median(X[~np.isnan(X)])\n",
    "\n",
    "print(\"after the precoessing, the X.shape is \")\n",
    "print(X.shape)\n",
    "print(\"the y.shape is\")\n",
    "print(y.shape)\n",
    "print(\"the number of MCI case is\")\n",
    "print(len(MCI_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin SVM\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin GCN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning selection best number of features\n",
      "\n",
      "\n",
      " Number of Feature: 10 **************************************************************************************************** \n",
      "\n",
      "\n",
      " RUN: 0 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.733333\n",
      "SVM F1 score: 0.714286\n",
      "[ 0.  1.  1.  1.  1.]\n",
      "[ 0.  0.  0.  1.  1.]\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.800000\n",
      "SVM F1 score: 0.769231\n",
      "[ 1.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.  1.]\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.733333\n",
      "SVM F1 score: 0.714286\n",
      "[ 1.  1.  1.  0.  1.  0.  0.]\n",
      "[ 1.  1.  1.  0.  1.  0.  1.]\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.800000\n",
      "SVM F1 score: 0.769231\n",
      "[ 0.  0.  1.  1.  0.]\n",
      "[ 0.  0.  1.  0.  0.]\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.857143\n",
      "SVM F1 score: 0.800000\n",
      "[ 0.]\n",
      "[ 1.]\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.642857\n",
      "SVM F1 score: 0.444444\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  1.  1.  1.  0.]\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.769231\n",
      "SVM F1 score: 0.666667\n",
      "[ 1.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.  0.]\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.846154\n",
      "SVM F1 score: 0.750000\n",
      "[ 1.  0.  0.  1.]\n",
      "[ 1.  1.  0.  1.]\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.769231\n",
      "SVM F1 score: 0.727273\n",
      "[ 0.  1.  1.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.  0.]\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.692308\n",
      "SVM F1 score: 0.500000\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "[ 1.  0.  0.  0.  0.]\n",
      "the mean accr_CV is\n",
      "0.764358974359\n",
      "the mean f1s_CV is\n",
      "0.685541680542\n",
      "the accr_MCI_CV is\n",
      "0.686274509804\n",
      "the f1_score_MCI is\n",
      "0.578947368421\n",
      "\n",
      " RUN: 1 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.666667\n",
      "SVM F1 score: 0.615385\n",
      "[ 0.  1.  1.  1.  0.]\n",
      "[ 0.  0.  1.  0.  1.]\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.733333\n",
      "SVM F1 score: 0.600000\n",
      "[ 0.  0.  1.  1.  0.]\n",
      "[ 0.  0.  0.  1.  0.]\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.666667\n",
      "SVM F1 score: 0.444444\n",
      "[ 0.  0.  1.  0.  0.  0.]\n",
      "[ 1.  1.  0.  1.  0.  1.]\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.933333\n",
      "SVM F1 score: 0.923077\n",
      "[ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.]\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.714286\n",
      "SVM F1 score: 0.600000\n",
      "[ 0.  0.  0.  0.  1.  0.  0.]\n",
      "[ 0.  1.  0.  1.  0.  0.  0.]\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.785714\n",
      "SVM F1 score: 0.769231\n",
      "[ 0.  1.  1.  0.  1.  1.  1.  0.]\n",
      "[ 0.  0.  1.  1.  1.  1.  0.  0.]\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.846154\n",
      "SVM F1 score: 0.750000\n",
      "[ 0.  0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  1.  0.  0.  1.]\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.615385\n",
      "SVM F1 score: 0.444444\n",
      "[ 0.  0.  0.  0.]\n",
      "[ 1.  1.  0.  1.]\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.846154\n",
      "SVM F1 score: 0.833333\n",
      "[ 0.  1.  1.]\n",
      "[ 0.  0.  0.]\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.692308\n",
      "SVM F1 score: 0.666667\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "the mean accr_CV is\n",
      "0.75\n",
      "the mean f1s_CV is\n",
      "0.664658119658\n",
      "the accr_MCI_CV is\n",
      "0.588235294118\n",
      "the f1_score_MCI is\n",
      "0.432432432432\n",
      "\n",
      " RUN: 2 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.933333\n",
      "SVM F1 score: 0.909091\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.800000\n",
      "SVM F1 score: 0.727273\n",
      "[ 0.  0.  0.  1.  0.]\n",
      "[ 0.  0.  1.  1.  0.]\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.600000\n",
      "SVM F1 score: 0.400000\n",
      "[ 0.  1.  1.  0.  0.]\n",
      "[ 1.  0.  0.  0.  0.]\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.666667\n",
      "SVM F1 score: 0.545455\n",
      "[ 0.  0.  1.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.  1.]\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.714286\n",
      "SVM F1 score: 0.666667\n",
      "[ 1.  0.  0.  1.  1.]\n",
      "[ 0.  1.  0.  1.  1.]\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.714286\n",
      "SVM F1 score: 0.600000\n",
      "[ 0.  0.  0.  0.  0.  1.]\n",
      "[ 0.  1.  1.  0.  0.  1.]\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.846154\n",
      "SVM F1 score: 0.800000\n",
      "[ 0.  0.  0.  1.  1.  1.]\n",
      "[ 1.  0.  0.  1.  0.  1.]\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.769231\n",
      "SVM F1 score: 0.727273\n",
      "[ 1.  1.  1.  0.]\n",
      "[ 0.  1.  0.  0.]\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.615385\n",
      "SVM F1 score: 0.545455\n",
      "[ 0.  0.  0.  1.  1.  0.]\n",
      "[ 1.  0.  0.  0.  0.  0.]\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.692308\n",
      "SVM F1 score: 0.714286\n",
      "[ 1.  1.  1.  1.  1.]\n",
      "[ 0.  0.  1.  1.  1.]\n",
      "the mean accr_CV is\n",
      "0.735164835165\n",
      "the mean f1s_CV is\n",
      "0.66354978355\n",
      "the accr_MCI_CV is\n",
      "0.647058823529\n",
      "the f1_score_MCI is\n",
      "0.571428571429\n",
      "\n",
      " RUN: 3 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.666667\n",
      "SVM F1 score: 0.545455\n",
      "[ 0.]\n",
      "[ 0.]\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.666667\n",
      "SVM F1 score: 0.545455\n",
      "[ 0.  1.  0.  0.  1.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  1.  0.  0.  0.]\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.800000\n",
      "SVM F1 score: 0.769231\n",
      "[ 0.  0.  0.  1.  0.  1.]\n",
      "[ 0.  0.  0.  0.  0.  1.]\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.800000\n",
      "SVM F1 score: 0.769231\n",
      "[ 0.  0.  0.  1.  1.  1.]\n",
      "[ 1.  0.  0.  1.  0.  1.]\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.785714\n",
      "SVM F1 score: 0.769231\n",
      "[ 0.  1.  1.  0.]\n",
      "[ 0.  0.  0.  0.]\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.785714\n",
      "SVM F1 score: 0.666667\n",
      "[ 0.  1.  0.  0.  1.  0.]\n",
      "[ 0.  1.  1.  0.  1.  1.]\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.538462\n",
      "SVM F1 score: 0.571429\n",
      "[ 1.  1.  1.  1.  1.  1.  0.]\n",
      "[ 0.  1.  0.  1.  0.  0.  1.]\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.692308\n",
      "SVM F1 score: 0.666667\n",
      "[ 0.  1.  1.]\n",
      "[ 1.  0.  1.]\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.769231\n",
      "SVM F1 score: 0.666667\n",
      "[ 0.  0.  1.  0.  1.  0.]\n",
      "[ 0.  1.  0.  0.  1.  1.]\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.615385\n",
      "SVM F1 score: 0.444444\n",
      "[ 1.  1.  0.  0.]\n",
      "[ 1.  0.  0.  1.]\n",
      "the mean accr_CV is\n",
      "0.712014652015\n",
      "the mean f1s_CV is\n",
      "0.641447441447\n",
      "the accr_MCI_CV is\n",
      "0.588235294118\n",
      "the f1_score_MCI is\n",
      "0.511627906977\n",
      "\n",
      " RUN: 4 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.600000\n",
      "SVM F1 score: 0.400000\n",
      "[ 1.  0.  1.  0.  1.  0.]\n",
      "[ 0.  0.  1.  1.  0.  1.]\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.733333\n",
      "SVM F1 score: 0.600000\n",
      "[ 0.  0.  0.  0.  1.  1.]\n",
      "[ 1.  1.  1.  0.  1.  0.]\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.733333\n",
      "SVM F1 score: 0.600000\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  0.  0.  1.  1.  1.]\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.733333\n",
      "SVM F1 score: 0.600000\n",
      "[ 0.  1.  1.  0.  0.  0.]\n",
      "[ 0.  1.  1.  0.  1.  0.]\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.857143\n",
      "SVM F1 score: 0.800000\n",
      "[ 0.  0.  0.  1.  1.]\n",
      "[ 1.  0.  0.  1.  1.]\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.785714\n",
      "SVM F1 score: 0.769231\n",
      "[ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.]\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.692308\n",
      "SVM F1 score: 0.600000\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  0.]\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.846154\n",
      "SVM F1 score: 0.750000\n",
      "[ 1.  0.  1.]\n",
      "[ 1.  0.  1.]\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.923077\n",
      "SVM F1 score: 0.888889\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.692308\n",
      "SVM F1 score: 0.600000\n",
      "[ 0.  1.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.  0.]\n",
      "the mean accr_CV is\n",
      "0.75967032967\n",
      "the mean f1s_CV is\n",
      "0.660811965812\n",
      "the accr_MCI_CV is\n",
      "0.705882352941\n",
      "the f1_score_MCI is\n",
      "0.594594594595\n",
      "\n",
      " RUN: 5 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.666667\n",
      "SVM F1 score: 0.615385\n",
      "[ 0.  1.  0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.  1.  1.]\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.666667\n",
      "SVM F1 score: 0.444444\n",
      "[ 0.  1.  0.  1.  0.  0.]\n",
      "[ 1.  1.  0.  0.  1.  0.]\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.800000\n",
      "SVM F1 score: 0.727273\n",
      "[ 0.  0.  0.  1.  0.  0.  1.  0.]\n",
      "[ 1.  0.  0.  0.  1.  0.  1.  0.]\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.666667\n",
      "SVM F1 score: 0.615385\n",
      "[ 1.  0.  0.  1.  1.]\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.785714\n",
      "SVM F1 score: 0.727273\n",
      "[ 0.  0.  1.  0.]\n",
      "[ 0.  1.  1.  1.]\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.857143\n",
      "SVM F1 score: 0.800000\n",
      "[ 0.  0.  1.  1.  0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  1.  1.  1.  0.  0.  0.  1.]\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.692308\n",
      "SVM F1 score: 0.500000\n",
      "[ 0.  1.]\n",
      "[ 0.  0.]\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.692308\n",
      "SVM F1 score: 0.666667\n",
      "[ 1.  1.]\n",
      "[ 1.  0.]\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.846154\n",
      "SVM F1 score: 0.800000\n",
      "[ 0.  0.  1.  0.  1.  0.]\n",
      "[ 0.  0.  0.  0.  1.  0.]\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.769231\n",
      "SVM F1 score: 0.727273\n",
      "[ 1.  1.  0.]\n",
      "[ 0.  0.  1.]\n",
      "the mean accr_CV is\n",
      "0.744285714286\n",
      "the mean f1s_CV is\n",
      "0.66236985237\n",
      "the accr_MCI_CV is\n",
      "0.607843137255\n",
      "the f1_score_MCI is\n",
      "0.5\n",
      "\n",
      " RUN: 6 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.666667\n",
      "SVM F1 score: 0.444444\n",
      "[ 0.  0.  0.  0.  0.]\n",
      "[ 1.  0.  1.  0.  0.]\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.800000\n",
      "SVM F1 score: 0.727273\n",
      "[ 1.  0.  0.  0.  1.]\n",
      "[ 1.  0.  1.  0.  0.]\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.866667\n",
      "SVM F1 score: 0.800000\n",
      "[ 0.  1.  0.  0.  1.  1.]\n",
      "[ 1.  1.  1.  0.  1.  1.]\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.800000\n",
      "SVM F1 score: 0.769231\n",
      "[ 0.  1.  0.  1.  0.  1.]\n",
      "[ 0.  1.  0.  0.  0.  1.]\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.714286\n",
      "SVM F1 score: 0.666667\n",
      "[ 0.  0.  1.  1.  1.]\n",
      "[ 0.  0.  1.  0.  0.]\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.785714\n",
      "SVM F1 score: 0.769231\n",
      "[ 1.  0.  0.  1.  1.  1.  0.  0.]\n",
      "[ 0.  0.  0.  0.  1.  1.  1.  0.]\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.615385\n",
      "SVM F1 score: 0.444444\n",
      "[ 0.  0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  1.  0.]\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.846154\n",
      "SVM F1 score: 0.800000\n",
      "[ 1.]\n",
      "[ 0.]\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.769231\n",
      "SVM F1 score: 0.727273\n",
      "[ 1.  0.  1.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.  0.  1.]\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.769231\n",
      "SVM F1 score: 0.571429\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  1.  1.]\n",
      "the mean accr_CV is\n",
      "0.763333333333\n",
      "the mean f1s_CV is\n",
      "0.671999111999\n",
      "the accr_MCI_CV is\n",
      "0.627450980392\n",
      "the f1_score_MCI is\n",
      "0.536585365854\n",
      "\n",
      " RUN: 7 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.666667\n",
      "SVM F1 score: 0.615385\n",
      "[ 0.  0.  1.  1.  0.  1.  1.  0.]\n",
      "[ 1.  0.  0.  1.  0.  1.  0.  0.]\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.666667\n",
      "SVM F1 score: 0.545455\n",
      "[ 0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.]\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.800000\n",
      "SVM F1 score: 0.769231\n",
      "[ 1.  1.  0.]\n",
      "[ 1.  0.  1.]\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.733333\n",
      "SVM F1 score: 0.714286\n",
      "[ 0.  1.  1.  0.  0.  1.  1.  0.  1.]\n",
      "[ 0.  0.  0.  0.  0.  1.  1.  0.  1.]\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.642857\n",
      "SVM F1 score: 0.545455\n",
      "[ 0.  1.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.  0.]\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.785714\n",
      "SVM F1 score: 0.727273\n",
      "[ 0.  1.  0.  1.]\n",
      "[ 1.  0.  1.  1.]\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.769231\n",
      "SVM F1 score: 0.571429\n",
      "[ 0.  0.]\n",
      "[ 1.  0.]\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.769231\n",
      "SVM F1 score: 0.666667\n",
      "[ 0.  1.  0.  1.]\n",
      "[ 0.  0.  0.  1.]\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.692308\n",
      "SVM F1 score: 0.600000\n",
      "[ 0.  1.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.  1.  0.]\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.923077\n",
      "SVM F1 score: 0.909091\n",
      "[ 1.  1.  1.  1.  0.]\n",
      "[ 1.  1.  1.  0.  0.]\n",
      "the mean accr_CV is\n",
      "0.744908424908\n",
      "the mean f1s_CV is\n",
      "0.666426906427\n",
      "the accr_MCI_CV is\n",
      "0.647058823529\n",
      "the f1_score_MCI is\n",
      "0.571428571429\n",
      "\n",
      " RUN: 8 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.866667\n",
      "SVM F1 score: 0.857143\n",
      "[ 1.  0.  1.  0.  1.]\n",
      "[ 0.  0.  1.  0.  0.]\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.466667\n",
      "SVM F1 score: 0.428571\n",
      "[ 1.  0.  0.  0.  0.  1.  0.  1.  1.  1.]\n",
      "[ 0.  0.  0.  1.  1.  0.  1.  0.  0.  1.]\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.600000\n",
      "SVM F1 score: 0.500000\n",
      "[ 0.  1.  0.  0.]\n",
      "[ 0.  1.  1.  0.]\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.866667\n",
      "SVM F1 score: 0.833333\n",
      "[ 0.  1.  0.  0.  1.  1.  0.]\n",
      "[ 0.  1.  0.  0.  0.  1.  0.]\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.714286\n",
      "SVM F1 score: 0.600000\n",
      "[ 0.  0.  0.]\n",
      "[ 0.  1.  0.]\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.928571\n",
      "SVM F1 score: 0.909091\n",
      "[ 1.  0.  0.  0.]\n",
      "[ 1.  0.  0.  0.]\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.769231\n",
      "SVM F1 score: 0.666667\n",
      "[ 1.  0.  1.  0.]\n",
      "[ 1.  0.  0.  1.]\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.769231\n",
      "SVM F1 score: 0.571429\n",
      "[ 0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.]\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.846154\n",
      "SVM F1 score: 0.833333\n",
      "[ 0.  1.  1.  1.]\n",
      "[ 0.  1.  1.  1.]\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.846154\n",
      "SVM F1 score: 0.800000\n",
      "[ 1.  0.  1.  0.  0.  0.]\n",
      "[ 1.  0.  1.  0.  0.  1.]\n",
      "the mean accr_CV is\n",
      "0.767362637363\n",
      "the mean f1s_CV is\n",
      "0.699956709957\n",
      "the accr_MCI_CV is\n",
      "0.686274509804\n",
      "the f1_score_MCI is\n",
      "0.6\n",
      "\n",
      " RUN: 9 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.600000\n",
      "SVM F1 score: 0.000000\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 1.  1.  0.  1.  0.  0.  1.  0.  0.]\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.733333\n",
      "SVM F1 score: 0.714286\n",
      "[ 0.  0.  1.  1.  1.  1.  1.  1.]\n",
      "[ 0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.733333\n",
      "SVM F1 score: 0.600000\n",
      "[ 0.  0.  1.  0.]\n",
      "[ 0.  0.  1.  0.]\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.800000\n",
      "SVM F1 score: 0.769231\n",
      "[ 0.  0.  1.]\n",
      "[ 1.  0.  1.]\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.714286\n",
      "SVM F1 score: 0.666667\n",
      "[ 1.  1.  0.  0.  1.]\n",
      "[ 0.  0.  1.  0.  1.]\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.928571\n",
      "SVM F1 score: 0.923077\n",
      "[ 0.  1.  0.  1.]\n",
      "[ 0.  1.  0.  1.]\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.692308\n",
      "SVM F1 score: 0.600000\n",
      "[ 0.  0.  0.]\n",
      "[ 0.  0.  0.]\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.692308\n",
      "SVM F1 score: 0.333333\n",
      "[ 0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  1.  0.]\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.846154\n",
      "SVM F1 score: 0.833333\n",
      "[ 1.  1.  1.]\n",
      "[ 0.  1.  1.]\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "SVM Accuracy: 0.846154\n",
      "SVM F1 score: 0.800000\n",
      "[ 0.  1.  1.  0.  1.  0.]\n",
      "[ 0.  1.  1.  0.  0.  0.]\n",
      "the mean accr_CV is\n",
      "0.758644688645\n",
      "the mean f1s_CV is\n",
      "0.623992673993\n",
      "the accr_MCI_CV is\n",
      "0.705882352941\n",
      "the f1_score_MCI is\n",
      "0.615384615385\n",
      "Runs Avg Accuracies: 0.7499743589743589\n",
      "Standard Deviation: 0.016047443463282716\n",
      "Runs Avg F1: 0.6640754245754245\n",
      "Standard Deviation: 0.019873118933685163\n",
      "Runs Avg Accuracies_MCI: 0.6490196078431373\n",
      "Standard Deviation: 0.043359498799011735\n",
      "Runs Avg Accuracies_MCI: 0.551242942652024\n",
      "Standard Deviation: 0.05336590399604527\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sep1 = '*' * 100\n",
    "sep2 = '*' * 50\n",
    "sep3 = '*' * 30\n",
    "\n",
    "print(\"beginning selection best number of features\")\n",
    "n_features = [10,30,50,70,80,100,1000,2000]\n",
    "\n",
    "#this is the optimal feature\n",
    "n_features = [30]\n",
    "\n",
    "\n",
    "\n",
    "rbf = svm.SVC(C=0.1,kernel='linear')\n",
    "\n",
    "for i in n_features:\n",
    "    print(\"\\n\\n Number of Feature: {} {} \\n\".format(i, sep1))\n",
    "      \n",
    "    accr_run  = []\n",
    "    f1s_run = []\n",
    "    accr_MCI_run= []\n",
    "    f1s_MCI_run = []    \n",
    "    \n",
    "    base_labels=[]\n",
    "    \n",
    "    for runs in range(10):\n",
    "        counter=0\n",
    "        print(\"\\n RUN: {} {} \\n\".format(runs, sep3))\n",
    "        \n",
    "        accr_CV = []\n",
    "        f1s_CV=[] \n",
    "        strat_labels = []\n",
    "        \n",
    "        test_labels_MCI_CV = []\n",
    "        y_pred_MCI_CV = []\n",
    "        \n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=int(runs))\n",
    "        for train_index, test_index in skf.split(X, y):       \n",
    "            print(\"\\n Fold: {} {} \\n\".format(counter, sep2))        \n",
    "            counter=counter+1\n",
    "                        \n",
    "            train_data_origin, test_data_origin=X[train_index], X[test_index]\n",
    "            train_labels, test_labels = y[train_index], y[test_index]\n",
    "            \n",
    "            strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    " #           print(\"Random forest for feature selection\")\n",
    "            clf = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "            clf = clf.fit(train_data_origin, train_labels)\n",
    "            importances = clf.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]        \n",
    "            \n",
    "            index=indices[0:i]\n",
    "            train_data=train_data_origin[:, index]\n",
    "            test_data=test_data_origin[:, index]\n",
    "            \n",
    "            test_index_MCI = [test_index[i] for i in range(0, len(test_index)) if test_index[i] in MCI_index]\n",
    "                                    \n",
    "        #SVM\n",
    "            rbf = rbf.fit(train_data, train_labels)\n",
    "            acc = rbf.score(test_data, test_labels)\n",
    "                \n",
    "            #f1 calculation\n",
    "            y_pred = rbf.predict(test_data)\n",
    "            f1 = f1_score(test_labels, y_pred)\n",
    "                                             \n",
    "            print('SVM Accuracy: %f' % acc)\n",
    "            print('SVM F1 score: %f' % f1)\n",
    "                    \n",
    "            accr_CV = np.append(accr_CV, acc)\n",
    "            f1s_CV=np.append(f1s_CV, f1)             \n",
    "            \n",
    "\n",
    "        #MCI_case            \n",
    "            if (len(test_index_MCI)==0):\n",
    "                print(\"There is no MCI in this shuffling test set, so we skip it\")\n",
    "            else:\n",
    "                test_data_MCI_origin = X[test_index_MCI]\n",
    "                test_data_MCI = test_data_MCI_origin[:, index]\n",
    "                test_labels_MCI = y[test_index_MCI]\n",
    "            \n",
    "                y_pred_MCI = rbf.predict(test_data_MCI)\n",
    "                \n",
    "                print(y_pred_MCI)\n",
    "                print(test_labels_MCI)\n",
    "                                    \n",
    "                y_pred_MCI_CV = np.append(y_pred_MCI_CV, y_pred_MCI)\n",
    "                test_labels_MCI_CV = np.append(test_labels_MCI_CV, test_labels_MCI)\n",
    "                                                        \n",
    "        base_labels=np.append(base_labels, strat_labels)  \n",
    "        \n",
    "        print(\"the mean accr_CV is\")\n",
    "        print(np.mean(accr_CV))\n",
    "        print(\"the mean f1s_CV is\")\n",
    "        print(np.mean(f1s_CV))\n",
    "        print(\"the accr_MCI_CV is\")\n",
    "        print(np.sum(test_labels_MCI_CV==y_pred_MCI_CV)/len(test_labels_MCI_CV))\n",
    "        print(\"the f1_score_MCI is\")\n",
    "        print(f1_score(test_labels_MCI_CV, y_pred_MCI_CV))\n",
    "        \n",
    "        accr_run = np.append(accr_run, np.mean(accr_CV))\n",
    "        f1s_run = np.append(f1s_run, np.mean(f1s_CV))\n",
    "        accr_MCI_run = np.append(accr_MCI_run, np.sum(test_labels_MCI_CV==y_pred_MCI_CV)/len(test_labels_MCI_CV))\n",
    "        f1s_MCI_run = np.append(f1s_MCI_run, f1_score(test_labels_MCI_CV, y_pred_MCI_CV))\n",
    "            \n",
    "    print(\"Runs Avg Accuracies: {}\".format(np.mean(accr_run)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(accr_run)))\n",
    "    print(\"Runs Avg F1: {}\".format(np.mean(f1s_run)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(f1s_run)))\n",
    "    print(\"Runs Avg Accuracies_MCI: {}\".format(np.mean(accr_MCI_run)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(accr_MCI_run)))    \n",
    "    print(\"Runs Avg Accuracies_MCI: {}\".format(np.mean(f1s_MCI_run)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(f1s_MCI_run)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68627451  0.58823529  0.64705882  0.58823529  0.70588235  0.60784314\n",
      "  0.62745098  0.64705882  0.68627451  0.70588235]\n"
     ]
    }
   ],
   "source": [
    "print(accr_MCI_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sep1 = '*' * 100\n",
    "sep2 = '*' * 50\n",
    "sep3 = '*' * 30\n",
    "\n",
    "print(\"beginning selection best number of features\")\n",
    "n_features = [10,30,50,70,80,100,1000,2000]\n",
    "\n",
    "#this is the optimal feature\n",
    "n_features = [10]\n",
    "\n",
    "logistic = linear_model.LogisticRegression(C=10)\n",
    "\n",
    "for i in n_features:\n",
    "    print(\"\\n\\n Number of Feature: {} {} \\n\".format(i, sep1))\n",
    "      \n",
    "    accr_run  = []\n",
    "    f1s_run = []\n",
    "    accr_MCI_run= []\n",
    "    f1s_MCI_run = []    \n",
    "    \n",
    "    base_labels=[]\n",
    "    \n",
    "    for runs in range(10):\n",
    "        counter=0\n",
    "        print(\"\\n RUN: {} {} \\n\".format(runs, sep3))\n",
    "        \n",
    "        accr_CV = []\n",
    "        f1s_CV=[] \n",
    "        strat_labels = []\n",
    "        \n",
    "        test_labels_MCI_CV = []\n",
    "        y_pred_MCI_CV = []\n",
    "        \n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=int(runs))\n",
    "        for train_index, test_index in skf.split(X, y):       \n",
    "            print(\"\\n Fold: {} {} \\n\".format(counter, sep2))        \n",
    "            counter=counter+1\n",
    "                        \n",
    "            train_data_origin, test_data_origin=X[train_index], X[test_index]\n",
    "            train_labels, test_labels = y[train_index], y[test_index]\n",
    "            \n",
    "            strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    " #           print(\"Random forest for feature selection\")\n",
    "            clf = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "            clf = clf.fit(train_data_origin, train_labels)\n",
    "            importances = clf.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]        \n",
    "            \n",
    "            index=indices[0:i]\n",
    "            train_data=train_data_origin[:, index]\n",
    "            test_data=test_data_origin[:, index]\n",
    "            \n",
    "            test_index_MCI = [test_index[i] for i in range(0, len(test_index)) if test_index[i] in MCI_index]\n",
    "                                    \n",
    "        #LR\n",
    "            \n",
    "            log = logistic.fit(train_data, train_labels)\n",
    "            acc = log.score(test_data, test_labels)            \n",
    "                \n",
    "            #f1 calculation\n",
    "            y_pred = logistic.predict(test_data)\n",
    "            f1 = f1_score(test_labels, y_pred)\n",
    "                                             \n",
    "            print('Accuracy: %f' % acc)\n",
    "            print('F1 score: %f' % f1)\n",
    "                    \n",
    "            accr_CV = np.append(accr_CV, acc)\n",
    "            f1s_CV=np.append(f1s_CV, f1)             \n",
    "            \n",
    "\n",
    "        #MCI_case            \n",
    "            if (len(test_index_MCI)==0):\n",
    "                print(\"There is no MCI in this shuffling test set, so we skip it\")\n",
    "            else:\n",
    "                test_data_MCI_origin = X[test_index_MCI]\n",
    "                test_data_MCI = test_data_MCI_origin[:, index]\n",
    "                test_labels_MCI = y[test_index_MCI]\n",
    "            \n",
    "                y_pred_MCI = logistic.predict(test_data_MCI)\n",
    "                \n",
    "                print(y_pred_MCI)\n",
    "                print(test_labels_MCI)\n",
    "                                    \n",
    "                y_pred_MCI_CV = np.append(y_pred_MCI_CV, y_pred_MCI)\n",
    "                test_labels_MCI_CV = np.append(test_labels_MCI_CV, test_labels_MCI)\n",
    "                                                        \n",
    "        base_labels=np.append(base_labels, strat_labels)  \n",
    "        \n",
    "        print(\"the mean accr_CV is\")\n",
    "        print(np.mean(accr_CV))\n",
    "        print(\"the mean f1s_CV is\")\n",
    "        print(np.mean(f1s_CV))\n",
    "        print(\"the accr_MCI_CV is\")\n",
    "        print(np.sum(test_labels_MCI_CV==y_pred_MCI_CV)/len(test_labels_MCI_CV))\n",
    "        print(\"the f1_score_MCI is\")\n",
    "        print(f1_score(test_labels_MCI_CV, y_pred_MCI_CV))\n",
    "        \n",
    "        accr_run = np.append(accr_run, np.mean(accr_CV))\n",
    "        f1s_run = np.append(f1s_run, np.mean(f1s_CV))\n",
    "        accr_MCI_run = np.append(accr_MCI_run, np.sum(test_labels_MCI_CV==y_pred_MCI_CV)/len(test_labels_MCI_CV))\n",
    "        f1s_MCI_run = np.append(f1s_MCI_run, f1_score(test_labels_MCI_CV, y_pred_MCI_CV))\n",
    "            \n",
    "    print(\"Runs Avg Accuracies: {}\".format(np.mean(accr_run)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(accr_run)))\n",
    "    print(\"Runs Avg F1: {}\".format(np.mean(f1s_run)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(f1s_run)))\n",
    "    print(\"Runs Avg Accuracies_MCI: {}\".format(np.mean(accr_MCI_run)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(accr_MCI_run)))    \n",
    "    print(\"Runs Avg Accuracies_MCI: {}\".format(np.mean(f1s_MCI_run)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(f1s_MCI_run)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning selection best number of features\n",
      "\n",
      "\n",
      " Number of Feature: 10 **************************************************************************************************** \n",
      "\n",
      "\n",
      " RUN: 0 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.800000\n",
      "Logistic Regression F1 score: 0.800000\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.800000\n",
      "Logistic Regression F1 score: 0.769231\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.733333\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.866667\n",
      "Logistic Regression F1 score: 0.833333\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.857143\n",
      "Logistic Regression F1 score: 0.800000\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.714286\n",
      "Logistic Regression F1 score: 0.600000\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.846154\n",
      "Logistic Regression F1 score: 0.800000\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.846154\n",
      "Logistic Regression F1 score: 0.750000\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.692308\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.692308\n",
      "Logistic Regression F1 score: 0.500000\n",
      "\n",
      " RUN: 1 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.733333\n",
      "Logistic Regression F1 score: 0.714286\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.866667\n",
      "Logistic Regression F1 score: 0.833333\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.666667\n",
      "Logistic Regression F1 score: 0.545455\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.800000\n",
      "Logistic Regression F1 score: 0.769231\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.785714\n",
      "Logistic Regression F1 score: 0.727273\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.714286\n",
      "Logistic Regression F1 score: 0.714286\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.846154\n",
      "Logistic Regression F1 score: 0.750000\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.538462\n",
      "Logistic Regression F1 score: 0.250000\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.846154\n",
      "Logistic Regression F1 score: 0.833333\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.769231\n",
      "Logistic Regression F1 score: 0.769231\n",
      "\n",
      " RUN: 2 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.933333\n",
      "Logistic Regression F1 score: 0.909091\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.800000\n",
      "Logistic Regression F1 score: 0.727273\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.600000\n",
      "Logistic Regression F1 score: 0.400000\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.733333\n",
      "Logistic Regression F1 score: 0.600000\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.714286\n",
      "Logistic Regression F1 score: 0.714286\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.714286\n",
      "Logistic Regression F1 score: 0.714286\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.846154\n",
      "Logistic Regression F1 score: 0.833333\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.769231\n",
      "Logistic Regression F1 score: 0.769231\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.692308\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.692308\n",
      "Logistic Regression F1 score: 0.714286\n",
      "\n",
      " RUN: 3 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.933333\n",
      "Logistic Regression F1 score: 0.909091\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.600000\n",
      "Logistic Regression F1 score: 0.500000\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.800000\n",
      "Logistic Regression F1 score: 0.769231\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.800000\n",
      "Logistic Regression F1 score: 0.769231\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.785714\n",
      "Logistic Regression F1 score: 0.769231\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.714286\n",
      "Logistic Regression F1 score: 0.600000\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.615385\n",
      "Logistic Regression F1 score: 0.615385\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.692308\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.769231\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.769231\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " RUN: 4 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.533333\n",
      "Logistic Regression F1 score: 0.222222\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.666667\n",
      "Logistic Regression F1 score: 0.545455\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.800000\n",
      "Logistic Regression F1 score: 0.727273\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.800000\n",
      "Logistic Regression F1 score: 0.727273\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.785714\n",
      "Logistic Regression F1 score: 0.727273\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.642857\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.769231\n",
      "Logistic Regression F1 score: 0.727273\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.923077\n",
      "Logistic Regression F1 score: 0.888889\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 1.000000\n",
      "Logistic Regression F1 score: 1.000000\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.615385\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " RUN: 5 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.800000\n",
      "Logistic Regression F1 score: 0.727273\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "Logistic Regression F1 score: 0.000000\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.866667\n",
      "Logistic Regression F1 score: 0.833333\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.800000\n",
      "Logistic Regression F1 score: 0.769231\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.857143\n",
      "Logistic Regression F1 score: 0.833333\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.857143\n",
      "Logistic Regression F1 score: 0.833333\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.769231\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.769231\n",
      "Logistic Regression F1 score: 0.727273\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.846154\n",
      "Logistic Regression F1 score: 0.833333\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.923077\n",
      "Logistic Regression F1 score: 0.909091\n",
      "\n",
      " RUN: 6 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.733333\n",
      "Logistic Regression F1 score: 0.600000\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.866667\n",
      "Logistic Regression F1 score: 0.833333\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.800000\n",
      "Logistic Regression F1 score: 0.769231\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.933333\n",
      "Logistic Regression F1 score: 0.923077\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.642857\n",
      "Logistic Regression F1 score: 0.615385\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.785714\n",
      "Logistic Regression F1 score: 0.769231\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.692308\n",
      "Logistic Regression F1 score: 0.500000\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.846154\n",
      "Logistic Regression F1 score: 0.800000\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.769231\n",
      "Logistic Regression F1 score: 0.727273\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.769231\n",
      "Logistic Regression F1 score: 0.571429\n",
      "\n",
      " RUN: 7 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.666667\n",
      "Logistic Regression F1 score: 0.545455\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.666667\n",
      "Logistic Regression F1 score: 0.615385\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.733333\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.733333\n",
      "Logistic Regression F1 score: 0.714286\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.857143\n",
      "Logistic Regression F1 score: 0.833333\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.714286\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.769231\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.769231\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.692308\n",
      "Logistic Regression F1 score: 0.600000\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.923077\n",
      "Logistic Regression F1 score: 0.909091\n",
      "\n",
      " RUN: 8 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.733333\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.466667\n",
      "Logistic Regression F1 score: 0.500000\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.733333\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.866667\n",
      "Logistic Regression F1 score: 0.833333\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.857143\n",
      "Logistic Regression F1 score: 0.833333\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.928571\n",
      "Logistic Regression F1 score: 0.909091\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.769231\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.769231\n",
      "Logistic Regression F1 score: 0.571429\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.692308\n",
      "Logistic Regression F1 score: 0.714286\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.846154\n",
      "Logistic Regression F1 score: 0.800000\n",
      "\n",
      " RUN: 9 ****************************** \n",
      "\n",
      "\n",
      " Fold: 0 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.733333\n",
      "Logistic Regression F1 score: 0.500000\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.733333\n",
      "Logistic Regression F1 score: 0.750000\n",
      "\n",
      " Fold: 2 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.733333\n",
      "Logistic Regression F1 score: 0.600000\n",
      "\n",
      " Fold: 3 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.866667\n",
      "Logistic Regression F1 score: 0.833333\n",
      "\n",
      " Fold: 4 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.714286\n",
      "Logistic Regression F1 score: 0.666667\n",
      "\n",
      " Fold: 5 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.928571\n",
      "Logistic Regression F1 score: 0.923077\n",
      "\n",
      " Fold: 6 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.846154\n",
      "Logistic Regression F1 score: 0.800000\n",
      "\n",
      " Fold: 7 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.692308\n",
      "Logistic Regression F1 score: 0.500000\n",
      "\n",
      " Fold: 8 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.769231\n",
      "Logistic Regression F1 score: 0.769231\n",
      "\n",
      " Fold: 9 ************************************************** \n",
      "\n",
      "Logistic Regression Accuracy: 0.692308\n",
      "Logistic Regression F1 score: 0.600000\n",
      "LR###############################################################\n",
      "Runs Avg Accuracies: 0.7709523809523808\n",
      "Standard Deviation: 0.07712968068386021\n",
      "Runs Avg F1: 0.6942307692307692\n",
      "Standard Deviation: 0.13623959104091365\n"
     ]
    }
   ],
   "source": [
    "sep1 = '*' * 100\n",
    "sep2 = '*' * 50\n",
    "sep3 = '*' * 30\n",
    "\n",
    "print(\"beginning selection best number of features\")\n",
    "#n_features = [10,30,50,70,80,100,1000,2000]\n",
    "\n",
    "\n",
    "#this is the optimal feature\n",
    "n_features = [10]\n",
    "\n",
    "logistic = linear_model.LogisticRegression(C=10)\n",
    "\n",
    "for i in n_features:\n",
    "    print(\"\\n\\n Number of Feature: {} {} \\n\".format(i, sep1))\n",
    "      \n",
    "    LR_all_accs_one_feature  = []\n",
    "    LR_all_f1s_one_feature = []\n",
    "\n",
    "\n",
    "    base_labels=[]\n",
    "    \n",
    "    for runs in range(10):\n",
    "        counter=0\n",
    "        print(\"\\n RUN: {} {} \\n\".format(runs, sep3))\n",
    "        \n",
    "        LR_accuracies = []\n",
    "        LR_f1s=[]    \n",
    "    \n",
    "\n",
    "        strat_labels = []\n",
    "        \n",
    "        logistic = linear_model.LogisticRegression(C=0.01)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=int(runs))\n",
    "        for train_index, test_index in skf.split(X, y):       \n",
    "            print(\"\\n Fold: {} {} \\n\".format(counter, sep2))        \n",
    "            counter=counter+1\n",
    "                        \n",
    "            train_data_origin, test_data_origin=X[train_index], X[test_index]\n",
    "            train_labels, test_labels = y[train_index], y[test_index]\n",
    "            strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    " #           print(\"Random forest for feature selection\")\n",
    "            clf = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "            clf = clf.fit(train_data_origin, train_labels)\n",
    "            importances = clf.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]        \n",
    "            \n",
    "            index=indices[0:i]\n",
    "            train_data=train_data_origin[:, index]\n",
    "            test_data=test_data_origin[:, index]\n",
    "                             \n",
    "            #Logistic Regression\n",
    "            log = logistic.fit(train_data, train_labels)\n",
    "            log_acc = log.score(test_data, test_labels)\n",
    "\n",
    "            #f1 calculation            \n",
    "            y_pred = logistic.predict(test_data)            \n",
    "            log_f1 = f1_score(test_labels, y_pred)\n",
    "\n",
    "            print('Logistic Regression Accuracy: %f' % log_acc)\n",
    "            print('Logistic Regression F1 score: %f' % log_f1)\n",
    "                            \n",
    "            LR_accuracies = np.append(LR_accuracies, log_acc)\n",
    "            LR_f1s=np.append(LR_f1s, log_f1)        \n",
    "            \n",
    "            \n",
    "        #MCI_case            \n",
    "            if (len(test_index_MCI)==0):\n",
    "                print(\"There is no MCI in this shuffling test set, so we skip it\")\n",
    "            else:\n",
    "                test_data_MCI_origin = X[test_index_MCI]\n",
    "                test_data_MCI = test_data_MCI_origin[:, index]\n",
    "                test_labels_MCI = y[test_index_MCI]\n",
    "            \n",
    "                y_pred_MCI = rbf.predict(test_data_MCI)\n",
    "                \n",
    "                print(y_pred_MCI)\n",
    "                print(test_labels_MCI)\n",
    "                                    \n",
    "                y_pred_MCI_CV = np.append(y_pred_MCI_CV, y_pred_MCI)\n",
    "                test_labels_MCI_CV = np.append(test_labels_MCI_CV, test_labels_MCI)            \n",
    "            \n",
    "                             \n",
    "        base_labels=np.append(base_labels, strat_labels)        \n",
    "        LR_all_accs_one_feature=np.append(LR_all_accs_one_feature, np.mean(LR_accuracies))\n",
    "        LR_all_f1s_one_feature =np.append(LR_all_f1s_one_feature, np.mean(LR_f1s))    \n",
    "    \n",
    "\n",
    "\n",
    "    print(\"LR###############################################################\")\n",
    "    print(\"Runs Avg Accuracies: {}\".format(np.mean(LR_accuracies)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(LR_accuracies)))\n",
    "    print(\"Runs Avg F1: {}\".format(np.mean(LR_f1s)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(LR_f1s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

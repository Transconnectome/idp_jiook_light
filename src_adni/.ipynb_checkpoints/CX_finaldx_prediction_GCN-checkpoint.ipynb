{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished this block\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn import linear_model, svm\n",
    "import re\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#s = \"../braindata/data_1_mor_select_100.csv\"\n",
    "import os          \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import sys, os\n",
    "sys.path.insert(0, '..')\n",
    "from lib import models, graph, coarsening, utils\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print('finished this block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished this block\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir('../data/adni')\n",
    "print('finished this block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the original training data dimension is\n",
      "(179, 34733)\n"
     ]
    }
   ],
   "source": [
    "dd =pd.read_csv(\"combine_new_biomarker_correct.csv\",header=0)\n",
    "print('the original training data dimension is')\n",
    "print(dd.shape)\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after the precoessing, the X.shape is \n",
      "(140, 34717)\n",
      "the y.shape is\n",
      "(140,)\n",
      "the number of MCI case is\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:2248: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    }
   ],
   "source": [
    "with open('combine_new_biomarker_correct.csv', 'r') as f:\n",
    "    d_reader = csv.DictReader(f)\n",
    "    #get fieldnames from DictReader object and store in list\n",
    "    headers = d_reader.fieldnames\n",
    "    \n",
    "data=np.array(dd)\n",
    "idx_IN_columns = np.append(np.array(range(1,6)),np.array([14,22]))\n",
    "idx_IN_columns = np.append(idx_IN_columns,np.array(range(23,data.shape[1])))\n",
    "\n",
    "X=data[:,idx_IN_columns]\n",
    "X_biomarker=X[:,0:5]\n",
    "\n",
    "y=data[:,9]  \n",
    "y_dxbl=data[:,10]\n",
    "\n",
    "ind_num_matrix=np.isnan(X_biomarker)\n",
    "ind_num_vector=np.any(ind_num_matrix,axis=1)\n",
    "\n",
    "X_no_nan=X[~ind_num_vector,:]\n",
    "y_no_nan=y[~ind_num_vector]\n",
    "y_dxbl_no_nan = y_dxbl[~ind_num_vector]\n",
    "\n",
    "X=X_no_nan\n",
    "y=y_no_nan\n",
    "y_dxbl=y_dxbl_no_nan\n",
    "\n",
    "MCI = (y_dxbl==2)\n",
    "MCI_index =[ i for i in range(0, MCI.shape[0]) if MCI[i]]\n",
    "\n",
    "X = stats.zscore(X)\n",
    "\n",
    "base_labels= []\n",
    "\n",
    "\n",
    "np.isnan(X).any()\n",
    "X[np.isnan(X)] = np.median(X[~np.isnan(X)])\n",
    "\n",
    "print(\"after the precoessing, the X.shape is \")\n",
    "print(X.shape)\n",
    "print(\"the y.shape is\")\n",
    "print(y.shape)\n",
    "print(\"the number of MCI case is\")\n",
    "print(len(MCI_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('../../Chenxiao_Results_Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish this block\n"
     ]
    }
   ],
   "source": [
    "test_number=1\n",
    "\n",
    "C = max(y) + 1  # number of classes    \n",
    "\n",
    "common = {}\n",
    "common['dir_name']       = 'CX_GCN'\n",
    "common['num_epochs']     = 35\n",
    "common['batch_size']     = 5\n",
    "common['eval_frequency'] = common['num_epochs']\n",
    "common['brelu']          = 'b1relu'\n",
    "common['pool']           = 'mpool1'\n",
    "common['filter']         = 'chebyshev5'\n",
    "# Architecture.\n",
    "common['F']              = [64, 32]  # Number of graph convolutional filters.\n",
    "common['K']              = [10, 10]  # Polynomial orders.\n",
    "common['p']              = [4, 4]    # Pooling sizes.\n",
    "common['M']              = [256, 512, 128, C]  # Output dimensionality of fully connected layers.s\n",
    "# Optimization.\n",
    "common['regularization'] = 1e-4\n",
    "common['dropout']        = 0.5\n",
    "common['learning_rate']  = 5e-4\n",
    "common['decay_rate']     = 0.95\n",
    "common['momentum']       = 0.9\n",
    "\n",
    "model_perf = utils.model_perf()    \n",
    "\n",
    "number_of_features = 100\n",
    "Metric = 'euclidean'\n",
    "K=10\n",
    "\n",
    "\n",
    "textfile_name=common['dir_name']+str(test_number)+'.txt'\n",
    "f = open(textfile_name,'w')\n",
    "f.write('This is the Result Output for the %d th testing. \\n' % test_number )\n",
    "f.write('The following tis the super-parameter setting:\\n')\n",
    "f.write('num_epochs: %d \\n' % common['num_epochs'])\n",
    "f.write('batch_size: %d \\n' % common['batch_size'])\n",
    "f.write('regularization: %f  \\n' % common['regularization'])\n",
    "f.write('dropout: %f  \\n' % common['dropout'])\n",
    "f.write('learning_rate: %f  \\n' % common['learning_rate'])\n",
    "f.write('decay_rate: %f  \\n' % common['decay_rate'])\n",
    "f.write('number_of_features: %d: \\n' % number_of_features)\n",
    "f.write('Metric: %s \\n' % Metric )\n",
    "f.write('K: %d \\n' % K )\n",
    "\n",
    "\n",
    "f.close()\n",
    "print('finish this block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RUN: 0 ****************************** \n",
      "\n",
      "\n",
      " Fold: 1 ************************************************** \n",
      "\n",
      "d = |V| = 100, k|V| < |E| = 1454\n",
      "Layer 0: M_0 = |V| = 128 nodes (28 added),|E| = 727 edges\n",
      "Layer 1: M_1 = |V| = 64 nodes (12 added),|E| = 363 edges\n",
      "Layer 2: M_2 = |V| = 32 nodes (5 added),|E| = 165 edges\n",
      "Layer 3: M_3 = |V| = 16 nodes (2 added),|E| = 68 edges\n",
      "Layer 4: M_4 = |V| = 8 nodes (1 added),|E| = 21 edges\n",
      "Layer 5: M_5 = |V| = 4 nodes (0 added),|E| = 6 edges\n",
      "Layer 6: M_6 = |V| = 2 nodes (0 added),|E| = 1 edges\n",
      "begin working!!!!!!!!\n",
      "validation accuracy: peak = 73.33, mean = 70.40\n",
      "INFO:tensorflow:Restoring parameters from /Users/ChenxiaoXu/Dropbox/repos/project1/idp_jiook_15_01_18/idp_jiook_light/lib/../checkpoints/CX_GCN15.txtrun0counter1/model-875\n",
      "train accuracy: 99.20 (124 / 125), f1 : 98.99, loss: 3.40e-01\n",
      "time: 2s (wall 1s)\n",
      "INFO:tensorflow:Restoring parameters from /Users/ChenxiaoXu/Dropbox/repos/project1/idp_jiook_15_01_18/idp_jiook_light/lib/../checkpoints/CX_GCN15.txtrun0counter1/model-875\n",
      "test  accuracy: 73.33 (11 / 15), f1 : 71.43, loss: 1.04e+00\n",
      "time: 1s (wall 1s)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'CGCNN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-53f47699cad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mmodel_perf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModels1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_perf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m#        Models1.fit(train_data, train_labels, test_data, test_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/repos/project1/idp_jiook_15_01_18/idp_jiook_light/lib/utils.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(s, fontsize)\u001b[0m\n\u001b[1;32m    334\u001b[0m         '''\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CGCNN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_f1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CGCNN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mroc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CGCNN'"
     ]
    }
   ],
   "source": [
    "sep1 = '*' * 100\n",
    "sep2 = '*' * 50\n",
    "sep3 = '*' * 30\n",
    "\n",
    "accr_run = []\n",
    "f1s_run = []\n",
    "accr_MCI_run = []\n",
    "f1s_MCI_run = []\n",
    "\n",
    "base_labels= []\n",
    "\n",
    "for runs in range(10):        \n",
    "    counter=0\n",
    "    print(\"\\n RUN: {} {} \\n\".format(runs, sep3))\n",
    "\n",
    "    f = open(textfile_name,'a')\n",
    "    f.write(\"\\n RUN: {} {} \\n\".format(runs, sep3))\n",
    "    f.close()\n",
    "    \n",
    "    strat_labels = []\n",
    "    accr_CV = []\n",
    "    f1s_CV = []\n",
    "    \n",
    "    test_labels_MCI_CV = []\n",
    "    y_pred_MCI_CV = []\n",
    "        \n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=int(runs))\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        counter = counter+1\n",
    "        print(\"\\n Fold: {} {} \\n\".format(counter, sep2))\n",
    "\n",
    "        f = open(textfile_name,'a')\n",
    "        f.write(\"\\n Fold: {} {} \\n\".format(counter, sep2))\n",
    "        f.close()\n",
    "\n",
    "        train_data_origin, test_data_origin = X[train_index], X[test_index]\n",
    "        train_labels, test_labels = y[train_index], y[test_index]\n",
    "\n",
    "        strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    "        clf = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "        clf = clf.fit(train_data_origin, train_labels)\n",
    "        importances = clf.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]        \n",
    "            \n",
    "        index=indices[0:number_of_features]\n",
    "        train_data=train_data_origin[:, index]\n",
    "        test_data=test_data_origin[:, index]                          \n",
    "                               \n",
    "        test_index_MCI = [test_index[i] for i in range(0, len(test_index)) if test_index[i] in MCI_index]\n",
    "                                            \n",
    "###################################################\n",
    "#Chenxiao: generating permuational matrix\n",
    "        dist, idx = graph.distance_scipy_spatial(train_data.transpose(), k=10, metric= Metric)\n",
    "        A = graph.adjacency(dist, idx).astype(np.float32)\n",
    "        assert A.shape == (train_data.shape[1], train_data.shape[1])\n",
    "        print('d = |V| = {}, k|V| < |E| = {}'.format(train_data.shape[1], A.nnz))\n",
    "        plt.spy(A, markersize=2, color='black')     \n",
    "        graphs, perm = coarsening.coarsen(A, levels=6, self_connections=False)\n",
    "        \n",
    "        train_data = coarsening.perm_data(train_data, perm)\n",
    " #       val_data = coarsening.perm_data(test_data, perm)\n",
    "        test_data = coarsening.perm_data(test_data, perm)\n",
    "\n",
    "        L = [graph.laplacian(A, normalized=True) for A in graphs]\n",
    " #       graph.plot_spectrum(L)    \n",
    " ###################################################        \n",
    "    \n",
    "        name1 = 'CGCNN'\n",
    "        params = common.copy()\n",
    "        params['dir_name'] = textfile_name + 'run' +str(runs) + 'counter' + str(counter)\n",
    "        params['decay_steps'] = len(train_labels) / common['batch_size']\n",
    "        \n",
    "        print('begin working!!!!!!!!')\n",
    "        f = open(textfile_name, 'a')\n",
    "        f.write(\"begin working!!!!!!!!\\n\")\n",
    "        f.close()\n",
    "                          \n",
    "                          \n",
    "        Models1=models.cgcnn(L, **params)\n",
    "                \n",
    "        model_perf.test(Models1, name1, params, train_data, train_labels, test_data, test_labels, test_data, test_labels, test_index)\n",
    "        scores, f1, y_labels, test_accuracy, y_pred = model_perf.show()   \n",
    "\n",
    "#        Models1.fit(train_data, train_labels, test_data, test_labels)                  \n",
    "#        y_pred = Models1.predict(test_data)\n",
    "        acc = np.sum(y_pred == test_labels) / test_labels.shape[0]                    \n",
    "        f1 = f1_score(test_labels, y_pred)\n",
    "                          \n",
    "                          \n",
    "        print('Accuracy: %f' % acc)\n",
    "        print('F1 score: %f' % f1)                          \n",
    "            \n",
    "        accr_CV = np.append(accr_CV, acc)\n",
    "        f1s_CV=np.append(f1s_CV, f1)    \n",
    "                          \n",
    "                          \n",
    "        strat_labels=np.append(strat_labels, test_labels)    \n",
    "                          \n",
    "        #MCI_case            \n",
    "        if (len(test_index_MCI)==0):\n",
    "            print(\"There is no MCI in this shuffling test set, so we skip it\")\n",
    "        else:\n",
    "            test_data_MCI_origin = X[test_index_MCI]\n",
    "            test_data_MCI = test_data_MCI_origin[:, index]\n",
    "            test_labels_MCI = y[test_index_MCI]\n",
    "                    \n",
    "            test_data_MCI = coarsening.perm_data(test_data_MCI, perm)\n",
    "\n",
    "            Models2=models.cgcnn(L, **params)\n",
    "            \n",
    "            name2 = 'CGCNN2'\n",
    "            \n",
    "            model_perf.test(Models2, name1, params, train_data, train_labels, test_data_MCI, test_labels_MCI, test_data_MCI, test_labels_MCI, test_index)\n",
    "            scores, f1, y_labels, test_accuracy, y_pred_MCI = model_perf.show()              \n",
    "            \n",
    "            \n",
    "                          \n",
    "#            Models2.fit(train_data, train_labels, test_data_MCI, test_labels_MCI)                  \n",
    "#            y_predict_MCI = Models2.predict(test_data_MCI)                \n",
    "            \n",
    "            print(y_pred_MCI)\n",
    "            print(test_labels_MCI)\n",
    "                                    \n",
    "            y_pred_MCI_CV = np.append(y_pred_MCI_CV, y_pred_MCI)\n",
    "            test_labels_MCI_CV = np.append(test_labels_MCI_CV, test_labels_MCI)\n",
    "        \n",
    "####################################################  \n",
    "                          \n",
    "    base_labels=np.append(base_labels, strat_labels)  \n",
    "#    print(\"the mean accr_CV is\")\n",
    "#    print(np.mean(accr_CV))\n",
    "#    print(\"the mean f1s_CV is\")\n",
    "#    print(np.mean(f1s_CV))\n",
    "    print(\"the total number_MCI_CV is\")\n",
    "    print(np.sum(number_MCI_CV))\n",
    "    print(\"the accr_MCI_CV is\")\n",
    "    print(np.sum(test_labels_MCI_CV==y_pred_MCI_CV)/len(test_labels_MCI_CV))\n",
    "    print(\"the f1_score_MCI is\")\n",
    "    print(f1_score(test_labels_MCI_CV, y_pred_MCI_CV))\n",
    "                          \n",
    "#    accr_run = np.append(accr_run, np.mean(accr_CV))\n",
    "#    f1s_run = np.append(f1s_run, np.mean(f1s_CV))\n",
    "    accr_MCI_run = np.append(accr_MCI_run, np.sum(test_labels_MCI_CV==y_pred_MCI_CV)/len(test_labels_MCI_CV))\n",
    "    f1s_MCI_run = np.append(f1s_MCI_run, f1_score(test_labels_MCI_CV, y_pred_MCI_CV))                          \n",
    "\n",
    "            \n",
    "#print(\"Runs Avg Accuracies: {}\".format(np.mean(accr_run)))\n",
    "#print(\"Standard Deviation: {}\".format(np.std(accr_run)))\n",
    "#print(\"Runs Avg F1: {}\".format(np.mean(f1s_run)))\n",
    "#print(\"Standard Deviation: {}\".format(np.std(f1s_run)))\n",
    "print(\"Runs Avg Accuracies_MCI: {}\".format(np.mean(accr_MCI_run)))\n",
    "print(\"Standard Deviation: {}\".format(np.std(accr_MCI_run)))    \n",
    "print(\"Runs Avg Accuracies_MCI: {}\".format(np.mean(f1s_MCI_run)))\n",
    "print(\"Standard Deviation: {}\".format(np.std(f1s_MCI_run)))     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

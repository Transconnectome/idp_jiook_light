{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished this block\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn import linear_model, svm\n",
    "import re\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#s = \"../braindata/data_1_mor_select_100.csv\"\n",
    "import os          \n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "print('finished this block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished this block\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir('../data/adni')\n",
    "print('finished this block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the original training data dimension is\n",
      "(179, 34733)\n"
     ]
    }
   ],
   "source": [
    "dd =pd.read_csv(\"combine_new_biomarker_correct.csv\",header=0)\n",
    "print('the original training data dimension is')\n",
    "print(dd.shape)\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "names=list(dd)\n",
    "start_index_conn=names.index('T1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after the precoessing, the X.shape is \n",
      "(179, 34709)\n",
      "the y.shape is\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "with open('combine_new_biomarker.csv', 'r') as f:\n",
    "    d_reader = csv.DictReader(f)\n",
    "    #get fieldnames from DictReader object and store in list\n",
    "    headers = d_reader.fieldnames\n",
    "    \n",
    "data=np.array(dd)\n",
    "#idx_IN_columns = np.append(np.array([9,10]),np.array(range(start_index_conn,data.shape[1])))\n",
    "\n",
    "#print(idx_IN_columns)\n",
    "\n",
    "X_conn=data[:,start_index_conn:]  #Connectome features\n",
    "X_biomarker=data[:,1:6] # Biomarker features\n",
    "y_baseline=data[:,9]  #baseline 1 is normal  2 MCI  3 is AD\n",
    "y_final=data[:,10]   #Finaldx # 0 is normal 1 is AD \n",
    "\n",
    "\n",
    "#print(y_final)\n",
    "#print(y_baseline)\n",
    "\n",
    "\n",
    "y=np.zeros(y_baseline.shape)\n",
    "#print(len(y))\n",
    "\n",
    "for i in range(0,len(y)):\n",
    "    if y_baseline[i]==1:\n",
    "        if y_final[i]==1:\n",
    "            y[i]=2\n",
    "        else:\n",
    "            y[i]=0\n",
    "    elif y_baseline[i]==2:\n",
    "        if y_final[i]==0:\n",
    "            y[i]=1\n",
    "        else:\n",
    "            y[i]=2\n",
    "    else: \n",
    "        y[i]=3\n",
    "\n",
    "        \n",
    "        \n",
    "# X_marker=X[:,2:]\n",
    "\n",
    "ind_num_matrix=np.isnan(X_conn)\n",
    "ind_num_vector=np.any(ind_num_matrix,axis=1)\n",
    "\n",
    "X_no_nan=X_conn[~ind_num_vector,:]\n",
    "y_no_nan=y[~ind_num_vector]\n",
    "\n",
    "X_conn_final=X_no_nan\n",
    "y=y_no_nan        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "feature_num_all=[]\n",
    "\n",
    "lr_all_feature=[]\n",
    "svm_all_feature=[]\n",
    "XGreg_all_feature=[]\n",
    "\n",
    "\n",
    "lr_fls_feature=[]\n",
    "svm_fls_feature=[]\n",
    "XGB_f1s_feature=[]\n",
    "\n",
    "base_labels= []\n",
    "# np.isnan(X).any()\n",
    "\n",
    "# np.isnan(X).any()\n",
    "#X[np.isnan(X_)] = np.median(X[~np.isnan(X)])\n",
    "\n",
    "print(\"after the precoessing, the X.shape is \")\n",
    "print(X_conn_final.shape)\n",
    "print(\"the y.shape is\")\n",
    "print(y.shape)\n",
    "\n",
    "X=X_conn_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 3\n",
    "\n",
    "all_TP = []\n",
    "all_TN = []\n",
    "all_FP = []\n",
    "all_FN = []\n",
    "\n",
    "all_acc = []\n",
    "all_sen = []\n",
    "all_spec = []\n",
    "all_auc = []\n",
    "\n",
    "all_roc_label = []\n",
    "all_roc_pred = []\n",
    "all_roc_prob = []\n",
    "\n",
    "rs_list=[33994,31358,27381,8642,7012,42023,44642,44002,30706,12571]\n",
    "for rs in rs_list:\n",
    "        print('********random seed:{}'.format(rs))\n",
    "\n",
    "        inner_cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=rs)\n",
    "        outer_cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=rs)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        #scaler = RobustScaler()\n",
    "        scaler.fit(X)\n",
    "        X = scaler.transform(X)\n",
    "\n",
    "        avg_acc = []\n",
    "        avg_TP = []\n",
    "        avg_TN = []\n",
    "        avg_FP = []\n",
    "        avg_FN = []\n",
    "        avg_sen = []\n",
    "        avg_spec = []\n",
    "        avg_auc = []\n",
    "\n",
    "\n",
    "        roc_label = []\n",
    "        roc_pred = []\n",
    "        roc_prob = []\n",
    "        \n",
    "        for train_index, test_index in outer_cv.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            # 'featureExtract__n_estimators': np.arange(10, 100, 10),\n",
    "            \n",
    "            #grid1######################################\n",
    "            #params = {'randomforest__min_samples_leaf': np.arange(1, 51, 5),\n",
    "            #          'randomforest__n_estimators': np.arange(10, 100, 10)}\n",
    "            \n",
    "            #grid2######################################\n",
    "            #params = {'randomforest__min_samples_leaf': np.arange(1, 51, 1),\n",
    "            #          'randomforest__n_estimators': np.arange(10, 500, 10)}\n",
    "            \n",
    "            #grid3######################################\n",
    "            params = {'randomforest__min_samples_leaf': np.arange(1, 51, 5),\n",
    "                      'randomforest__n_estimators': np.arange(10, 500, 10)}\n",
    "            \n",
    "            params_svm = [\n",
    "                    {'randomforest__min_samples_leaf': np.arange(1, 51, 5),\n",
    "                      'randomforest__n_estimators': np.arange(10, 100, 10)},\n",
    "                    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}                \n",
    "            ]\n",
    "            \n",
    "            #pipe = Pipeline([\n",
    "            #    ('featureExtract', SelectFromModel(ExtraTreesClassifier())),\n",
    "            #    ('randomforest', RandomForestClassifier())\n",
    "            #])\n",
    "            \n",
    "            pipe_rf = Pipeline([\n",
    "                ('featureExtract', SelectFromModel(ExtraTreesClassifier())),\n",
    "                ('randomforest', RandomForestClassifier())\n",
    "            ])\n",
    "\n",
    "            \n",
    "            \n",
    "            #clf = GridSearchCV(estimator=pipe, param_grid=params, cv=inner_cv, scoring='accuracy',n_jobs=8)\n",
    "            clf = GridSearchCV(estimator=pipe_rf, param_grid=params, cv=inner_cv,scoring='accuracy', n_jobs=-1)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            fs = clf.best_estimator_.named_steps['featureExtract']\n",
    "            mask = fs.get_support()\n",
    "            y_pred = clf.predict(X_test)\n",
    "            y_prob = clf.predict_proba(X_test)\n",
    "          #  roc_pred = clf.predict_proba(X_test)\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_prob[:, 1])\n",
    "\n",
    "            roc_label = np.append(roc_label, y_test)\n",
    "            roc_pred = np.append(roc_pred, y_pred)\n",
    "            roc_prob = np.append(roc_prob, y_prob[:, 1])\n",
    "            \n",
    "            #confusion mat\n",
    "\n",
    "            conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "            TP = conf_mat[0][0]\n",
    "            FP = conf_mat[0][1]\n",
    "            FN = conf_mat[1][0]\n",
    "            TN = conf_mat[1][1]\n",
    "            \n",
    "            print(TP, FP, FN, TN)\n",
    "            sen = TP / (TP + FN)\n",
    "            spec = TN / (TN + FP)\n",
    "                \n",
    "            # avg meausres\n",
    "            avg_TP = np.append(avg_TP, TP)\n",
    "            avg_TN = np.append(avg_TN, TN)\n",
    "            avg_FP = np.append(avg_FP, FP)\n",
    "            avg_FN = np.append(avg_FN, FN)\n",
    "\n",
    "            avg_acc = np.append(avg_acc, acc)\n",
    "            avg_sen = np.append(avg_sen, sen)\n",
    "            avg_spec = np.append(avg_spec, spec)\n",
    "            avg_auc = np.append(avg_auc, auc)\n",
    "        \n",
    "            print('Accuracy:{},AUC:{}'.format(acc, auc))\n",
    "            print('Sensitivity:{},Specificity:{}'.format(sen, spec))\n",
    "    \n",
    "        # all measures\n",
    "        all_TP = np.append(all_TP, avg_TP)\n",
    "        all_TN = np.append(all_TN, avg_TN)\n",
    "        all_FP = np.append(all_FP, avg_FP)\n",
    "        all_FN = np.append(all_FN, avg_FN)\n",
    "\n",
    "        all_acc = np.append(all_acc, avg_acc)\n",
    "        all_sen = np.append(all_sen, avg_sen)\n",
    "        all_spec = np.append(all_spec, avg_spec)\n",
    "        all_auc = np.append(all_auc, avg_auc)\n",
    "    \n",
    "        all_roc_label = np.append(all_roc_label, roc_label)\n",
    "        all_roc_pred = np.append(all_roc_pred, roc_pred)\n",
    "        all_roc_prob = np.append(all_roc_prob, roc_prob)\n",
    "\n",
    "\n",
    "print(all_sen)\n",
    "import numpy as np, scipy.stats as st\n",
    "\n",
    "#all_acc \n",
    "#all_sen \n",
    "#all_spec \n",
    "\n",
    "\n",
    "\n",
    "acc_CI=st.t.interval(0.95, len(all_acc)-1, loc=np.mean(all_acc), scale=st.sem(all_acc))\n",
    "sen_CI=st.t.interval(0.95, len(all_sen)-1, loc=np.mean(all_sen), scale=st.sem(all_sen))\n",
    "spec_CI=st.t.interval(0.95, len(all_spec)-1, loc=np.mean(all_spec), scale=st.sem(all_spec))\n",
    "auc_CI=st.t.interval(0.95, len(all_auc)-1, loc=np.mean(all_auc), scale=st.sem(all_auc))\n",
    "\n",
    "txt_name='../imgs2/' + name + '_' + data_name + '.txt'\n",
    "print(\"RF_ACC={a}, 95%CI={l}-{u}\".format(a=np.mean(all_acc), l=acc_CI[0],u=acc_CI[1]),file=open(txt_name, \"a\"))\n",
    "print(\"RF_AUC={a}, 95%CI={l}-{u}\".format(a=np.mean(all_auc), l=auc_CI[0],u=auc_CI[1]),file=open(txt_name, \"a\"))\n",
    "print(\"RF_SENSITIVITY={a}, 95%CI={l}-{u}\".format(a=np.mean(all_sen), l=sen_CI[0],u=sen_CI[1]),file=open(txt_name, \"a\"))\n",
    "print(\"RF_SPECIFICITY={a}, 95%CI={l}-{u}\".format(a=np.mean(all_spec), l=spec_CI[0],u=spec_CI[1]),file=open(txt_name, \"a\"))\n",
    "\n",
    "#print(\"Total score for {n} is {s}\".format(n=name, s=score))\n",
    "\n",
    "\n",
    "#print(\"RF_SENSITIVITY={}\".format(np.mean(all_sen)),file=open(txt_name, \"a\"))\n",
    "#print(\"RF_SENSITIVITY95%CI={}\".format(sen_CI),file=open(txt_name, \"a\"))\n",
    "\n",
    "#print(\"RF_SPECIFICITY={}\".format(np.mean(all_spec)),file=open(txt_name, \"a\"))\n",
    "#print(\"RF_SPECIFICITY95%CI={}\".format(spec_CI),file=open(txt_name, \"a\"))\n",
    "\n",
    "\n",
    "    # ROC curve\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(all_roc_label, all_roc_prob)\n",
    "#auc = roc_auc_score(all_roc_label, all_roc_prob)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(fpr, tpr, lw=2, label='random forest (AUC = %0.2f)' % np.mean(all_auc))\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('roc')\n",
    "plt.legend(loc=\"lower right\") \n",
    "#plt.savefig('10x_Combined_ROC.eps')\n",
    "roc_name='../imgs2/' + name + '_' + data_name + '.pdf'\n",
    "plt.savefig(roc_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin SVM\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sep1 = '*' * 100\n",
    "sep2 = '*' * 50\n",
    "sep3 = '*' * 30\n",
    "\n",
    "print(\"beginning selection best number of features\")\n",
    "n_features = [10,30,50,70,80,100,1000,2000]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rbf = svm.SVC(C=10,kernel='rbf',gamma=0.01)\n",
    "\n",
    "for i in n_features:\n",
    "    print(\"\\n\\n Number of Feature: {} {} \\n\".format(i, sep1))\n",
    "      \n",
    "    SVM_all_accs_one_feature  = []\n",
    "    SVM_all_f1s_one_feature = []\n",
    "    base_labels=[]\n",
    "    \n",
    "    for runs in range(1):\n",
    "        counter=0\n",
    "        print(\"\\n RUN: {} {} \\n\".format(runs, sep3))\n",
    "        \n",
    "        SVM_accuracies = []\n",
    "        SVM_f1s=[] \n",
    "        strat_labels = []\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=int(runs))\n",
    "        for train_index, test_index in skf.split(X, y):       \n",
    "            print(\"\\n Fold: {} {} \\n\".format(counter, sep2))        \n",
    "            counter=counter+1\n",
    "                        \n",
    "            train_data_origin, test_data_origin=X[train_index], X[test_index]\n",
    "            train_labels, test_labels = y[train_index], y[test_index]\n",
    "            strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    " #           print(\"Random forest for feature selection\")\n",
    "            clf = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "            clf = clf.fit(train_data_origin, train_labels)\n",
    "            importances = clf.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]        \n",
    "            \n",
    "            index=indices[0:i]\n",
    "            train_data=train_data_origin[:, index]\n",
    "            test_data=test_data_origin[:, index]\n",
    "                                     \n",
    "        #SVM\n",
    "            rbf = rbf.fit(train_data, train_labels)\n",
    "            svm_acc = rbf.score(test_data, test_labels)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #f1 calculation\n",
    "            y_pred = rbf.predict(test_data)\n",
    "            \n",
    "            print(y_pred)\n",
    "            print(test_labels)\n",
    "            \n",
    "            svm_f1 = f1_score(test_labels, y_pred, average='macro')\n",
    "            \n",
    "                \n",
    "            print('SVM Accuracy: %f' % svm_acc)\n",
    "            print('SVM F1 score: %f' % svm_f1)\n",
    "                    \n",
    "            SVM_accuracies = np.append(SVM_accuracies, svm_acc)\n",
    "            SVM_f1s=np.append(SVM_f1s, svm_f1)             \n",
    "                            \n",
    "        base_labels=np.append(base_labels, strat_labels)        \n",
    "        SVM_all_accs_one_feature=np.append(SVM_all_accs_one_feature, np.mean(SVM_accuracies))\n",
    "        #SVM_all_f1s_one_feature =np.append(SVM_all_f1s_one_feature, np.mean(SVM_f1s)) \n",
    "\n",
    "    print(\"SVM###############################################################\")\n",
    "    print(\"Runs Avg Accuracies: {}\".format(np.mean(SVM_accuracies)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(SVM_accuracies)))\n",
    "    #print(\"Runs Avg F1: {}\".format(np.mean(SVM_f1s)))\n",
    "    #print(\"Standard Deviation: {}\".format(np.std(SVM_f1s)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('begin logistic regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sep1 = '*' * 100\n",
    "sep2 = '*' * 50\n",
    "sep3 = '*' * 30\n",
    "\n",
    "print(\"beginning selection best number of features\")\n",
    "n_features = [10,30,50,70,80,100,1000,2000]\n",
    "\n",
    "logistic = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "for i in n_features:\n",
    "    print(\"\\n\\n Number of Feature: {} {} \\n\".format(i, sep1))\n",
    "      \n",
    "    LR_all_accs_one_feature  = []\n",
    "    LR_all_f1s_one_feature = []\n",
    "\n",
    "\n",
    "    base_labels=[]\n",
    "    \n",
    "    for runs in range(1):\n",
    "        counter=0\n",
    "        print(\"\\n RUN: {} {} \\n\".format(runs, sep3))\n",
    "        \n",
    "        LR_accuracies = []\n",
    "        LR_f1s=[]    \n",
    "    \n",
    "\n",
    "        strat_labels = []\n",
    "        \n",
    "        logistic = linear_model.LogisticRegression(C=1e4)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=int(runs))\n",
    "        for train_index, test_index in skf.split(X, y):       \n",
    "            print(\"\\n Fold: {} {} \\n\".format(counter, sep2))        \n",
    "            counter=counter+1\n",
    "                        \n",
    "            train_data_origin, test_data_origin=X[train_index], X[test_index]\n",
    "            train_labels, test_labels = y[train_index], y[test_index]\n",
    "            strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    " #           print(\"Random forest for feature selection\")\n",
    "            clf = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "            clf = clf.fit(train_data_origin, train_labels)\n",
    "            importances = clf.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]        \n",
    "            \n",
    "            index=indices[0:i]\n",
    "            train_data=train_data_origin[:, index]\n",
    "            test_data=test_data_origin[:, index]\n",
    "                             \n",
    "            #Logistic Regression\n",
    "            log = logistic.fit(train_data, train_labels)\n",
    "            log_acc = log.score(test_data, test_labels)\n",
    "\n",
    "            #f1 calculation            \n",
    "            y_pred = logistic.predict(test_data)            \n",
    "            log_f1 = f1_score(test_labels, y_pred, average='macro')\n",
    "\n",
    "            print('Logistic Regression Accuracy: %f' % log_acc)\n",
    "            print('Logistic Regression F1 score: %f' % log_f1)\n",
    "                            \n",
    "            LR_accuracies = np.append(LR_accuracies, log_acc)\n",
    "            LR_f1s=np.append(LR_f1s, log_f1)        \n",
    "                      \n",
    "        base_labels=np.append(base_labels, strat_labels)        \n",
    "        LR_all_accs_one_feature=np.append(LR_all_accs_one_feature, np.mean(LR_accuracies))\n",
    "        LR_all_f1s_one_feature =np.append(LR_all_f1s_one_feature, np.mean(LR_f1s))    \n",
    "    \n",
    "\n",
    "\n",
    "    print(\"LR###############################################################\")\n",
    "    print(\"Runs Avg Accuracies: {}\".format(np.mean(LR_accuracies)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(LR_accuracies)))\n",
    "    print(\"Runs Avg F1: {}\".format(np.mean(LR_f1s)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(LR_f1s)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('begin XGboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sep1 = '*' * 100\n",
    "sep2 = '*' * 50\n",
    "sep3 = '*' * 30\n",
    "\n",
    "print(\"beginning selection best number of features\")\n",
    "n_features = [10,30,50,70,80,100,1000,2000]\n",
    "\n",
    "\n",
    "param={}\n",
    "param['objective'] = 'multi:softmax'\n",
    "\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['num_class'] = 6\n",
    "\n",
    "for i in n_features:\n",
    "    print(\"\\n\\n Number of Feature: {} {} \\n\".format(i, sep1))\n",
    "      \n",
    "    XGB_all_accs_one_feature  = []\n",
    "    XGB_all_f1s_one_feature = []\n",
    "\n",
    "\n",
    "    base_labels=[]\n",
    "    \n",
    "    for runs in range(10):\n",
    "        counter=0\n",
    "        print(\"\\n RUN: {} {} \\n\".format(runs, sep3))\n",
    "        \n",
    "        XGB_accuracies = []\n",
    "        XGB_f1s=[]    \n",
    "    \n",
    "\n",
    "        strat_labels = []\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=int(runs))\n",
    "        for train_index, test_index in skf.split(X, y):       \n",
    "            print(\"\\n Fold: {} {} \\n\".format(counter, sep2))        \n",
    "            counter=counter+1\n",
    "                        \n",
    "            train_data_origin, test_data_origin=X[train_index], X[test_index]\n",
    "            train_labels, test_labels = y[train_index], y[test_index]\n",
    "            strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    " #           print(\"Random forest for feature selection\")\n",
    "            clf = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "            clf = clf.fit(train_data_origin, train_labels)\n",
    "            importances = clf.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]        \n",
    "            \n",
    "            index=indices[0:i]\n",
    "            train_data=train_data_origin[:, index]\n",
    "            test_data=test_data_origin[:, index]\n",
    "            \n",
    "            xgb_train_data=xgb.DMatrix(train_data, label=train_labels)\n",
    "            xgb_test_data=xgb.DMatrix(test_data, label=test_labels)\n",
    "            \n",
    "                             \n",
    "            #Logistic Regression\n",
    "            watchlist=[(xgb_train_data, 'train'), (xgb_test_data, 'test')]\n",
    "            num_round=5\n",
    "            bst = xgb.train(param, xgb_train_data, num_round, watchlist)\n",
    "            y_pred = bst.predict(xgb_test_data)\n",
    "\n",
    "            print(y_pred)\n",
    "            \n",
    "            print(test_labels)\n",
    "            \n",
    "            print(np.sum(y_pred == test_labels))\n",
    "            \n",
    "            print(test_labels[0])\n",
    "            \n",
    "            xgb_acc = np.sum(y_pred == test_labels) / test_labels.shape[0]           \n",
    "\n",
    "            #f1 calculation\n",
    "            xgb_f1 = f1_score(test_labels, y_pred, average='macro')\n",
    "\n",
    "            print('XGB Regression Accuracy: %f' % xgb_acc)\n",
    "            print('XGB Regression F1 score: %f' % xgb_f1)\n",
    "                            \n",
    "            XGB_accuracies = np.append(LR_accuracies, log_acc)\n",
    "            XGB_f1s=np.append(LR_f1s, log_f1)        \n",
    "               \n",
    "        base_labels=np.append(base_labels, strat_labels)        \n",
    "        XGB_all_accs_one_feature=np.append(LR_all_accs_one_feature, np.mean(LR_accuracies))\n",
    "        XG_all_f1s_one_feature =np.append(LR_all_f1s_one_feature, np.mean(LR_f1s))    \n",
    "\n",
    "    #print(\"LR###############################################################\")\n",
    "    #print(\"Runs Avg Accuracies: {}\".format(np.mean(LR_accuracies)))\n",
    "    #print(\"Standard Deviation: {}\".format(np.std(LR_accuracies)))\n",
    "    #print(\"Runs Avg F1: {}\".format(np.mean(LR_f1s)))\n",
    "    #print(\"Standard Deviation: {}\".format(np.std(LR_f1s)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn import linear_model, svm\n",
    "import re\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#s = \"../braindata/data_1_mor_select_100.csv\"\n",
    "import os          \n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/idp_jiook/data/adni')\n",
    "dd =pd.read_csv(\"combine_new.csv\",header=0)\n",
    "print(dd.shape)\n",
    "import csv\n",
    "\n",
    "with open('combine_new.csv', 'r') as f:\n",
    "    d_reader = csv.DictReader(f)\n",
    "\n",
    "    #get fieldnames from DictReader object and store in list\n",
    "    headers = d_reader.fieldnames\n",
    "data=np.array(dd)\n",
    "#print(data.shape)\n",
    "idx_IN_columns = np.append(np.array([9,17]),np.array(range(18,data.shape[1])))\n",
    "print(idx_IN_columns)\n",
    "X=data[:,idx_IN_columns]\n",
    "#features=data[:,11:data.shape[1]]\n",
    "#features = features.transpose()\n",
    "X = stats.zscore(X)\n",
    "#print(features.shape)\n",
    "y=data[:,8]\n",
    "#/ 6:AD-normal / 7:AD-MCI / 8:MCI-normal \n",
    "\n",
    "ind_num=np.isnan(y)\n",
    "# print(ind_num.shape)\n",
    "\n",
    "\n",
    "y_no_nan = y[~ind_num]\n",
    "\n",
    "X_no_nan = X[~ind_num,:]\n",
    "\n",
    "       # print(y.shape)\n",
    "\n",
    "y=y_no_nan\n",
    "X=X_no_nan\n",
    "feature_num_all=[]\n",
    "lr_all_feature=[]\n",
    "svm_all_feature=[]\n",
    "lr_fls_feature=[]\n",
    "svm_fls_feature=[]\n",
    "base_labels= []\n",
    "\n",
    "#X=X.reshape(X.size,1)\n",
    "#X=X.astype(np.float64,copy=False)\n",
    "np.isnan(X).any()\n",
    "#feature_num=features.shape[1]\n",
    "\n",
    "X[np.isnan(X)] = np.median(X[~np.isnan(X)])\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "clf = clf.fit(X, y)\n",
    "importances = clf.feature_importances_\n",
    "importances\n",
    "indices = np.argsort(importances)[::-1]\n",
    "#print(\"Feature ranking:\")\n",
    "\n",
    "#for f in range(X.shape[1]):\n",
    "#    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "n_features = [10,30,50,70,80,100,1000,2000,13000,18000,10000,20000,3000,30000,4000,500,5000,6000,7000,8000,9000,15000,25000]\n",
    "#n_features = [1000]\n",
    "n_features.sort()\n",
    "\n",
    "for i in n_features:\n",
    "#     #print(i)\n",
    "    \n",
    "#     #lsvc = LinearSVC(C=J[i],penalty=\"l1\", dual=True).fit(X, y)\n",
    "#     #model = SelectFromModel(lsvc, prefit=True)\n",
    "#     #features = model.transform(X)\n",
    "#     clf = ExtraTreesClassifier(n_estimators=250,\n",
    "#                               random_state=0)\n",
    "#     clf = clf.fit(X, y)\n",
    "#     importances = forest.feature_importances_\n",
    "       \n",
    "    index=indices[0:i]\n",
    "    print(index.shape)\n",
    "    features=X[:,index]\n",
    "#     clf.feature_importances_ \n",
    "\n",
    "#     model = SelectFromModel(clf, threshold=0.6,prefit=True)\n",
    "#     features = model.transform(X)\n",
    "#     features.shape               \n",
    "#     #features=features.reshape(features.size,1)\n",
    "#     #features=features.astype(np.float64,copy=false)\n",
    "#     np.isnan(features).any()\n",
    "    feature_num=features.shape[1]\n",
    "    print(feature_num)\n",
    "    \n",
    "  \n",
    "    lr_all_accs = []\n",
    "    lr_all_scores = []\n",
    "    lr_f1s = []\n",
    "    svm_all_accs = []\n",
    "    svm_all_scores = []\n",
    "    svm_f1s = []\n",
    "    #base_labels = []\n",
    "    for runs in range(1):\n",
    "        lr_accuracies = []\n",
    "        lr_scores = []\n",
    "        svm_accuracies = []\n",
    "        svm_scores = []\n",
    "        strat_labels = []\n",
    "        \n",
    "        logistic = linear_model.LogisticRegression(C=1e5)\n",
    "        rbf = svm.SVC(C=10,kernel='linear',gamma=0.01)\n",
    "\n",
    "        skf=RepeatedStratifiedKFold(n_splits=10, n_repeats=2)\n",
    "        for train_index, test_index in skf.split(features, y):\n",
    "                    train_data, test_data = features[train_index], features[test_index]\n",
    "                    train_labels, test_labels = y[train_index], y[test_index]\n",
    "\n",
    "                    strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    "                    log = logistic.fit(train_data, train_labels)\n",
    "                    log_prob = log.decision_function(test_data)\n",
    "                    log_acc = log.score(test_data, test_labels)\n",
    "\n",
    "                    #f1 calculation\n",
    "                    y_pred = logistic.predict(test_data)\n",
    "                    log_f1 = f1_score(test_labels, y_pred)\n",
    "\n",
    "                    lr_accuracies = np.append(lr_accuracies, log_acc)\n",
    "                    lr_scores = np.append(lr_scores, log_prob)\n",
    "                    lr_f1s = np.append(lr_f1s, log_f1)\n",
    "                    #print('Logistic Regression Accuracy: %f' % log_acc)\n",
    "\n",
    "                    rbf = rbf.fit(train_data, train_labels)\n",
    "                    svm_acc = rbf.score(test_data, test_labels)\n",
    "                    svm_prob = rbf.decision_function(test_data)\n",
    "\n",
    "                    #f1 calculation\n",
    "                    y_pred = rbf.predict(test_data)\n",
    "                    svm_f1 = f1_score(test_labels, y_pred)\n",
    "                    #print('SVM Accuracy: %f' % svm_acc)\n",
    "                    svm_accuracies = np.append(svm_accuracies, svm_acc)\n",
    "                    svm_scores = np.append(svm_scores, svm_prob)\n",
    "                    svm_f1s = np.append(svm_f1s, svm_f1)\n",
    "                    #print('SVM f1: %f' % svm_f1)\n",
    "\n",
    "\n",
    "                    lr_all_scores = np.append(lr_all_scores, lr_scores)\n",
    "                    lr_fold_avg = np.mean(lr_accuracies)\n",
    "                    lr_all_accs = np.append(lr_all_accs, lr_fold_avg)\n",
    "                    svm_all_scores = np.append(svm_all_scores, svm_scores)\n",
    "                    svm_fold_avg = np.mean(svm_accuracies)\n",
    "                    svm_all_accs = np.append(svm_all_accs, svm_fold_avg)\n",
    "                    #print('Logistic Regression Accuracy: %f' % log_acc_avg)\n",
    "                            #print('SVM Regression Accuracy: %f' % svm_acc_avg)\n",
    "        feature_num_all=np.append(feature_num_all,feature_num)\n",
    "# print(np.mean(lr_all_accs))\n",
    "# print(np.mean(svm_all_accs))      \n",
    "        lr_all_feature=np.append(lr_all_feature,np.mean(lr_all_accs))\n",
    "        svm_all_feature=np.append(svm_all_feature,np.mean(svm_all_accs))\n",
    "        lr_fls_feature=np.append(lr_fls_feature,np.mean(lr_f1s))\n",
    "        svm_fls_feature=np.append(svm_fls_feature,np.mean(svm_f1s))\n",
    "        #base_labels_all = np.append(base_labels_all,strat)\n",
    "        base_labels = np.append(base_labels, np.mean(strat_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81421372568118833"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n",
    "np.max(lr_all_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niARCCUVERAKhhCIiIoH4//hkV714K6GsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1106994e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot( (feature_num_all), lr_all_feature*100, lw=5, label='Logistic Regression')\n",
    "plt.plot( (feature_num_all), svm_all_feature*100, lw=5, label='SVM')\n",
    "plt.xlim([50, 30000])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('MCIvsSMI')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/idp_jiook/data/MCIvsSMI_combine.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy: 0.9473684210526315\n",
      "svm f1: 0.8695652173913044\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"svm accuracy: {}\".format(np.mean(svm_acc)))\n",
    "print(\"svm f1: {}\".format(np.mean(svm_f1s)))\n",
    "print(svm_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-da8518b9331f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# print(\"SVM f1s Avg : {}\".format(np.mean( svm_fls_feature )),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# print(\"SVM f1s Standard Deviation: {}\".format(np.std(svm_fls_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlrindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_all_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# print(\"LR Maximum feature number is: {}\".format(feature_num_all[lrindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msvmindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_all_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#print(svm_f1s)\n",
    "\n",
    "# print(\"LR accuracy Avg: {}\".format(np.mean(lr_all_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"LR accuracy Standard Deviation: {}\".format(np.std(lr_all_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "# print(\"LR f1s Avg : {}\".format(np.mean( lr_fls_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"LR f1s Standard Deviation: {}\".format(np.std(lr_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "# print(\"SVM Avg: {}\".format(np.mean(svm_all_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"SVM Standard Deviation: {}\".format(np.std(svm_all_accs)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "# print(\"SVM f1s Avg : {}\".format(np.mean( svm_fls_feature )),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "# print(\"SVM f1s Standard Deviation: {}\".format(np.std(svm_fls_feature)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "lrindex=np.argmax(lr_all_feature)\n",
    "# print(\"LR Maximum feature number is: {}\".format(feature_num_all[lrindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "svmindex=np.argmax(svm_all_feature)\n",
    "# print(\"SVM Maximum feature is number : {}\".format(feature_num_all[svmindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "\n",
    "# clf = ExtraTreesClassifier(n_estimators=250,\n",
    "#                               random_state=0)\n",
    "# clf = clf.fit(X, y)\n",
    "# importances = clf.feature_importances_\n",
    "# #importances\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(100):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f],headers[indices[f]],importances[indices[f]]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMI_rank.txt\", \"a\"))\n",
    "\n",
    "    \n",
    "#################################################################################################################    \n",
    "from sklearn import metrics\n",
    "\n",
    "max_features = feature_num_all[svmindex]\n",
    "print(max_features)\n",
    "lr_all_accs = []\n",
    "lr_all_scores = []\n",
    "lr_f1s = []\n",
    "svm_all_accs = []\n",
    "svm_all_scores = []\n",
    "svm_f1s = []\n",
    "base_labels = []\n",
    "lr_sensitivity= []\n",
    "svm_sensitivity=[]\n",
    "lr_specificity=[]\n",
    "svm_specificity=[]\n",
    "\n",
    "index=indices[0:int(max_features)]\n",
    "features=X[:,index]\n",
    "feature_num=features.shape[1]\n",
    "for runs in range(1):\n",
    "    lr_accuracies = []\n",
    "    lr_scores = []\n",
    "    svm_accuracies = []\n",
    "    svm_scores = []\n",
    "    strat_labels = []\n",
    "\n",
    "    logistic = linear_model.LogisticRegression(C=1e5)\n",
    "    rbf = svm.SVC(C=10,kernel='linear',gamma=0.01)\n",
    "    \n",
    "    skf=RepeatedStratifiedKFold(n_splits=10, n_repeats=10)\n",
    "    for train_index, test_index in skf.split(features, y):\n",
    "                train_data, test_data = features[train_index], features[test_index]\n",
    "                train_labels, test_labels = y[train_index], y[test_index]\n",
    "                #print(train_data.shape)\n",
    "                strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    "                log = logistic.fit(train_data, train_labels)\n",
    "                log_prob = log.decision_function(test_data)\n",
    "                log_acc = log.score(test_data, test_labels)\n",
    "\n",
    "                #f1 calculation\n",
    "                y_pred = logistic.predict(test_data)\n",
    "                log_f1 = f1_score(test_labels, y_pred)\n",
    "                log_confuse= metrics.confusion_matrix(test_labels, y_pred)\n",
    "                TP = log_confuse[1, 1]\n",
    "                TN = log_confuse[0, 0]\n",
    "                FP = log_confuse[0, 1]\n",
    "                FN = log_confuse[1, 0]\n",
    "                log_sen=metrics.recall_score(test_labels, y_pred)\n",
    "    #             print(TN)\n",
    "    #             print(FP)\n",
    "                log_spec=TN / (TN + FP)\n",
    "    #             print(log_confuse)\n",
    "    #             print(log_sen)\n",
    "    #             print(log_spec)\n",
    "\n",
    "                lr_accuracies = np.append(lr_accuracies, log_acc)\n",
    "                lr_sensitivity=np.append(lr_sensitivity, log_sen)\n",
    "                lr_specificity=np.append(lr_specificity, log_spec)\n",
    "\n",
    "                lr_scores = np.append(lr_scores, log_prob)\n",
    "                lr_f1s = np.append(lr_f1s, log_f1)\n",
    "\n",
    "                #print('Logistic Regression Accuracy: %f' % log_acc)\n",
    "\n",
    "                rbf = rbf.fit(train_data, train_labels)\n",
    "                svm_acc = rbf.score(test_data, test_labels)\n",
    "                svm_prob = rbf.decision_function(test_data)\n",
    "\n",
    "                #f1 calculation\n",
    "                y_pred = rbf.predict(test_data)\n",
    "                svm_f1 = f1_score(test_labels, y_pred)\n",
    "                svm_confuse= metrics.confusion_matrix(test_labels, y_pred)\n",
    "                TP = log_confuse[1, 1]\n",
    "                TN = log_confuse[0, 0]\n",
    "                FP = log_confuse[0, 1]\n",
    "                FN = log_confuse[1, 0]\n",
    "                svm_sen=metrics.recall_score(test_labels, y_pred)\n",
    "                svm_spec=TN / (TN + FP)\n",
    "\n",
    "\n",
    "\n",
    "                svm_accuracies = np.append(svm_accuracies, log_acc)\n",
    "                svm_sensitivity=np.append(svm_sensitivity, log_sen)\n",
    "                svm_specificity=np.append(svm_specificity, log_spec)\n",
    "\n",
    "                #print('SVM Accuracy: %f' % svm_acc)\n",
    "                svm_accuracies = np.append(svm_accuracies, svm_acc)\n",
    "                svm_scores = np.append(svm_scores, svm_prob)\n",
    "                svm_f1s = np.append(svm_f1s, svm_f1)\n",
    "\n",
    "    base_labels = np.append(base_labels, strat_labels)\n",
    "    lr_all_scores = np.append(lr_all_scores, lr_scores)\n",
    "    lr_fold_avg = np.mean(lr_accuracies)\n",
    "    lr_all_accs = np.append(lr_all_accs, lr_fold_avg)\n",
    "    svm_all_scores = np.append(svm_all_scores, svm_scores)\n",
    "    svm_fold_avg = np.mean(svm_accuracies)\n",
    "    svm_all_accs = np.append(svm_all_accs, svm_fold_avg)\n",
    "\n",
    "# feature_num_all=np.append(feature_num_all,feature_num)\n",
    "# # print(np.mean(lr_all_accs))\n",
    "print(np.mean(svm_all_accs))      \n",
    "# lr_all_feature=np.append(lr_all_feature,np.mean(lr_all_accs))\n",
    "# print(lr_all_feature)\n",
    "# svm_all_feature=np.append(svm_all_feature,np.mean(svm_all_accs))\n",
    "# print(np.mean(svm_accuracies))\n",
    "# lr_fls_feature=np.append(lr_fls_feature,np.mean(lr_f1s))\n",
    "# svm_fls_feature=np.append(svm_fls_feature,np.mean(svm_f1s))\n",
    "#base_labels_all = np.append(base_labels_all,strat)\n",
    "#base_labels = np.append(base_labels, np.mean(strat_labels))\n",
    "\n",
    "print(\"LR accuracy Avg: {}\".format(np.mean(lr_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR accuracy Standard Deviation: {}\".format(np.std(lr_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR sensitivity Avg: {}\".format(np.mean(lr_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR sensitivity Standard Deviation: {}\".format(np.std(lr_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR specificity Avg: {}\".format(np.mean(lr_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR specificity Standard Deviation: {}\".format(np.std(lr_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR f1s Avg : {}\".format(np.mean(lr_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"LR f1s Standard Deviation: {}\".format(np.std(lr_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "print(\"SVM Avg: {}\".format(np.mean(svm_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM Standard Deviation: {}\".format(np.std(svm_accuracies)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM sensitivity Avg: {}\".format(np.mean(svm_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM sensitivity Standard Deviation: {}\".format(np.std(svm_sensitivity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM specificity Avg: {}\".format(np.mean(svm_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM specificity Standard Deviation: {}\".format(np.std(svm_specificity)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM f1s Avg : {}\".format(np.mean(svm_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "print(\"SVM f1s Standard Deviation: {}\".format(np.std(svm_f1s)),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "#lrindex=np.argmax(lr_all_feature)\n",
    "print(\"LR Maximum feature number is: {}\".format(feature_num_all[lrindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "#svmindex=np.argmax(svm_all_feature)\n",
    "print(\"SVM Maximum feature is number : {}\".format(feature_num_all[svmindex]),file=open(\"/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/MCIvsSMIaccuracy.txt\", \"a\"))\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "fpr['lr'], tpr['lr'], _ = roc_curve(base_labels, lr_all_scores)\n",
    "roc_auc['lr'] = auc(fpr['lr'], tpr['lr'])\n",
    "#f1['lr']=f1_score(fpr['lr'], tpr['lr'])\n",
    "fpr['svm'], tpr['svm'], _ = roc_curve(base_labels, svm_all_scores)\n",
    "roc_auc['svm'] = auc(fpr['svm'], tpr['svm'])\n",
    "#f1['svm']=f1_score(fpr['svm'], tpr['svm'])\n",
    "#fpr['gcn'], tpr['gcn'], _ = roc_curve(all_labels, all_scores)\n",
    "#roc_auc['gcn'] = auc(fpr['gcn'], tpr['gcn'])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr['lr'], tpr['lr'], lw=5, label='Logistic Regression (area = %0.2f)' % roc_auc['lr'] )\n",
    "#plt.plot(fpr['lr'], tpr['lr'], lw=3, label='Logistic Regression (f1 = %0.2f)' % f1['lr'] )\n",
    "plt.plot(fpr['svm'], tpr['svm'], lw=5, label='SVM (area = %0.2f)' % roc_auc['svm'] )\n",
    "#plt.plot(fpr['svm'], tpr['svm'f], lw=3, label='SVM (f1 = %0.2f)' % f1['svm'] )\n",
    "#plt.plot(fpr['gcn'], tpr['gcn'], lw=3, label='GCN (area = %0.2f)' % roc_auc['gcn'])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=5, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('MCIvsSMI')\n",
    "plt.legend(loc=\"lower right\") \n",
    "#plt.savefig('10x_Combined_ROC.eps')\n",
    "#plt.savefig('ROC_MCIVsNormal_connectome.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig('/Users/yunwang/Dropbox (NYSPI)/00 AD ML/0papers/0Neuroimage-Clinical/Figures/ROC_MCIvsSMI_connectome.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

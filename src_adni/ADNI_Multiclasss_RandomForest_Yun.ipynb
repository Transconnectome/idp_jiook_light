{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished this block\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn import linear_model, svm\n",
    "import re\n",
    "from sklearn.metrics import roc_curve, auc,f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#s = \"../braindata/data_1_mor_select_100.csv\"\n",
    "import os          \n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "\n",
    "import pandas as pd\n",
    "from numpy import *\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score,cross_val_predict,StratifiedKFold,KFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix, mean_squared_error,precision_score,recall_score,f1_score,hamming_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('finished this block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished this block\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir('../data/adni')\n",
    "print('finished this block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the original training data dimension is\n",
      "(179, 34733)\n"
     ]
    }
   ],
   "source": [
    "dd =pd.read_csv(\"combine_new_biomarker_correct.csv\",header=0)\n",
    "print('the original training data dimension is')\n",
    "print(dd.shape)\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=list(dd)\n",
    "start_index_conn=names.index('T1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after the precoessing, the X.shape is \n",
      "(179, 34709)\n",
      "the y.shape is\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "with open('combine_new_biomarker.csv', 'r') as f:\n",
    "    d_reader = csv.DictReader(f)\n",
    "    #get fieldnames from DictReader object and store in list\n",
    "    headers = d_reader.fieldnames\n",
    "    \n",
    "data=np.array(dd)\n",
    "#idx_IN_columns = np.append(np.array([9,10]),np.array(range(start_index_conn,data.shape[1])))\n",
    "\n",
    "#print(idx_IN_columns)\n",
    "\n",
    "X_conn=data[:,start_index_conn:]  #Connectome features\n",
    "X_biomarker=data[:,1:6] # Biomarker features\n",
    "y_baseline=data[:,10]  #baseline 1 is normal  2 MCI  3 is AD\n",
    "y_final=data[:,9]   #Finaldx # 0 is Not-AD  1 is AD \n",
    "\n",
    "\n",
    "#print(y_final)\n",
    "#print(y_baseline)\n",
    "\n",
    "\n",
    "y=np.zeros(y_baseline.shape)\n",
    "#print(len(y))\n",
    "\n",
    "for i in range(0,len(y)):\n",
    "    if y_baseline[i]==1:\n",
    "#         if y_final[i]==1:\n",
    "#             y[i]=0\n",
    "#         else:\n",
    "            y[i]=0\n",
    "    elif y_baseline[i]==2:\n",
    "        if y_final[i]==0:\n",
    "            y[i]=1 #stable MCI\n",
    "        else:\n",
    "            y[i]=2 # Converted MCI \n",
    "    else: \n",
    "        y[i]=3 \n",
    "\n",
    "        \n",
    "# X_marker=X[:,2:]\n",
    "\n",
    "ind_num_matrix=np.isnan(X_conn)\n",
    "ind_num_vector=np.any(ind_num_matrix,axis=1)\n",
    "\n",
    "X_no_nan=X_conn[~ind_num_vector,:]\n",
    "y_no_nan=y[~ind_num_vector]\n",
    "\n",
    "X_conn_final=X_no_nan\n",
    "y=y_no_nan        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "feature_num_all=[]\n",
    "\n",
    "lr_all_feature=[]\n",
    "svm_all_feature=[]\n",
    "XGreg_all_feature=[]\n",
    "\n",
    "\n",
    "lr_fls_feature=[]\n",
    "svm_fls_feature=[]\n",
    "XGB_f1s_feature=[]\n",
    "\n",
    "base_labels= []\n",
    "# np.isnan(X).any()\n",
    "\n",
    "# np.isnan(X).any()\n",
    "#X[np.isnan(X_)] = np.median(X[~np.isnan(X)])\n",
    "\n",
    "print(\"after the precoessing, the X.shape is \")\n",
    "print(X_conn_final.shape)\n",
    "print(\"the y.shape is\")\n",
    "print(y.shape)\n",
    "\n",
    "X=X_biomarker\n",
    "X[np.isnan(X)] = np.median(X[~np.isnan(X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X_scaler=scaler.fit_transform(X.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "rs=33994\n",
    "outer_cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=rs)\n",
    "for train_index, test_index in outer_cv.split(X_scaler, y):\n",
    "    X_train, X_test = X_scaler[train_index], X_scaler[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    ovo_clf=OneVsOneClassifier(SGDClassifier(random_state=42))\n",
    "    ovo_clf.fit(X_train,y_train)\n",
    "    ovo_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.36585366, 0.34146341, 0.30769231])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score( ovo_clf,X_train,y_train,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=cross_val_predict(ovo_clf,X_train,y_train,cv=10)\n",
    "conf_mx=confusion_matrix(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row_sums=conf_mx.sum(axis=1,keepdims=True)\n",
    "norm_conf_mx=conf_mx/row_sums\n",
    "np.fill_diagonal(norm_conf_mx,0)\n",
    "plt.matshow(norm_conf_mx,cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.35416667, 0.02083333, 0.14583333],\n",
       "       [0.5       , 0.        , 0.07692308, 0.15384615],\n",
       "       [0.06666667, 0.13333333, 0.        , 0.73333333],\n",
       "       [0.34375   , 0.0625    , 0.09375   , 0.        ]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_conf_mx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 3\n",
    "\n",
    "all_TP = []\n",
    "all_TN = []\n",
    "all_FP = []\n",
    "all_FN = []\n",
    "\n",
    "all_acc = []\n",
    "all_sen = []\n",
    "all_spec = []\n",
    "all_auc = []\n",
    "\n",
    "all_roc_label = []\n",
    "all_roc_pred = []\n",
    "all_roc_prob = []\n",
    "\n",
    "#rs_list=[33994,31358,27381,8642,7012,42023,44642,44002,30706,12571]\n",
    "rs_list=[33994]\n",
    "for rs in rs_list:\n",
    "        print('********random seed:{}'.format(rs))\n",
    "\n",
    "        inner_cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=rs)\n",
    "        outer_cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=rs)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        #scaler = RobustScaler()\n",
    "        scaler.fit(X)\n",
    "        X = scaler.transform(X)\n",
    "\n",
    "        avg_acc = []\n",
    "        avg_TP = []\n",
    "        avg_TN = []\n",
    "        avg_FP = []\n",
    "        avg_FN = []\n",
    "        avg_sen = []\n",
    "        avg_spec = []\n",
    "        avg_auc = []\n",
    "\n",
    "\n",
    "        roc_label = []\n",
    "        roc_pred = []\n",
    "        roc_prob = []\n",
    "        \n",
    "        for train_index, test_index in outer_cv.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            # 'featureExtract__n_estimators': np.arange(10, 100, 10),\n",
    "            \n",
    "            #grid1######################################\n",
    "            #params = {'randomforest__min_samples_leaf': np.arange(1, 51, 5),\n",
    "            #          'randomforest__n_estimators': np.arange(10, 100, 10)}\n",
    "            \n",
    "            #grid2######################################\n",
    "            #params = {'randomforest__min_samples_leaf': np.arange(1, 51, 1),\n",
    "            #          'randomforest__n_estimators': np.arange(10, 500, 10)}\n",
    "            \n",
    "            #grid3######################################\n",
    "            params = {'randomforest__min_samples_leaf': np.arange(1, 51, 5),\n",
    "                      'randomforest__n_estimators': np.arange(10, 500, 10)}\n",
    "            \n",
    "#             params_svm = [\n",
    "#                     {'randomforest__min_samples_leaf': np.arange(1, 51, 5),\n",
    "#                       'randomforest__n_estimators': np.arange(10, 100, 10)},\n",
    "#                     {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}                \n",
    "#             ]\n",
    "            \n",
    "            #pipe = Pipeline([\n",
    "            #    ('featureExtract', SelectFromModel(ExtraTreesClassifier())),\n",
    "            #    ('randomforest', RandomForestClassifier())\n",
    "            #])\n",
    "            \n",
    "            pipe_rf = Pipeline([\n",
    "                ('featureExtract', SelectFromModel(ExtraTreesClassifier())),\n",
    "                ('randomforest', RandomForestClassifier())\n",
    "            ])\n",
    "\n",
    "            \n",
    "            \n",
    "            #clf = GridSearchCV(estimator=pipe, param_grid=params, cv=inner_cv, scoring='accuracy',n_jobs=8)\n",
    "            clf = GridSearchCV(estimator=pipe_rf, param_grid=params, cv=inner_cv,scoring='accuracy', n_jobs=-1)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Begin SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sep1 = '*' * 100\n",
    "sep2 = '*' * 50\n",
    "sep3 = '*' * 30\n",
    "\n",
    "print(\"beginning selection best number of features\")\n",
    "n_features = [10,30,50,70,80,100,1000,2000]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rbf = svm.SVC(C=10,kernel='rbf',gamma=0.01)\n",
    "\n",
    "for i in n_features:\n",
    "    print(\"\\n\\n Number of Feature: {} {} \\n\".format(i, sep1))\n",
    "      \n",
    "    SVM_all_accs_one_feature  = []\n",
    "    SVM_all_f1s_one_feature = []\n",
    "    base_labels=[]\n",
    "    \n",
    "    for runs in range(1):\n",
    "        counter=0\n",
    "        print(\"\\n RUN: {} {} \\n\".format(runs, sep3))\n",
    "        \n",
    "        SVM_accuracies = []\n",
    "        SVM_f1s=[] \n",
    "        strat_labels = []\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=int(runs))\n",
    "        for train_index, test_index in skf.split(X, y):       \n",
    "            print(\"\\n Fold: {} {} \\n\".format(counter, sep2))        \n",
    "            counter=counter+1\n",
    "                        \n",
    "            train_data_origin, test_data_origin=X[train_index], X[test_index]\n",
    "            train_labels, test_labels = y[train_index], y[test_index]\n",
    "            strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    " #           print(\"Random forest for feature selection\")\n",
    "            clf = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "            clf = clf.fit(train_data_origin, train_labels)\n",
    "            importances = clf.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]        \n",
    "            \n",
    "            index=indices[0:i]\n",
    "            train_data=train_data_origin[:, index]\n",
    "            test_data=test_data_origin[:, index]\n",
    "                                     \n",
    "        #SVM\n",
    "            rbf = rbf.fit(train_data, train_labels)\n",
    "            svm_acc = rbf.score(test_data, test_labels)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #f1 calculation\n",
    "            y_pred = rbf.predict(test_data)\n",
    "            \n",
    "            print(y_pred)\n",
    "            print(test_labels)\n",
    "            \n",
    "            svm_f1 = f1_score(test_labels, y_pred, average='macro')\n",
    "            \n",
    "                \n",
    "            print('SVM Accuracy: %f' % svm_acc)\n",
    "            print('SVM F1 score: %f' % svm_f1)\n",
    "                    \n",
    "            SVM_accuracies = np.append(SVM_accuracies, svm_acc)\n",
    "            SVM_f1s=np.append(SVM_f1s, svm_f1)             \n",
    "                            \n",
    "        base_labels=np.append(base_labels, strat_labels)        \n",
    "        SVM_all_accs_one_feature=np.append(SVM_all_accs_one_feature, np.mean(SVM_accuracies))\n",
    "        #SVM_all_f1s_one_feature =np.append(SVM_all_f1s_one_feature, np.mean(SVM_f1s)) \n",
    "\n",
    "    print(\"SVM###############################################################\")\n",
    "    print(\"Runs Avg Accuracies: {}\".format(np.mean(SVM_accuracies)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(SVM_accuracies)))\n",
    "    #print(\"Runs Avg F1: {}\".format(np.mean(SVM_f1s)))\n",
    "    #print(\"Standard Deviation: {}\".format(np.std(SVM_f1s)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('begin logistic regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep1 = '*' * 100\n",
    "sep2 = '*' * 50\n",
    "sep3 = '*' * 30\n",
    "\n",
    "print(\"beginning selection best number of features\")\n",
    "n_features = [10,30,50,70,80,100,1000,2000]\n",
    "\n",
    "logistic = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "for i in n_features:\n",
    "    print(\"\\n\\n Number of Feature: {} {} \\n\".format(i, sep1))\n",
    "      \n",
    "    LR_all_accs_one_feature  = []\n",
    "    LR_all_f1s_one_feature = []\n",
    "\n",
    "\n",
    "    base_labels=[]\n",
    "    \n",
    "    for runs in range(1):\n",
    "        counter=0\n",
    "        print(\"\\n RUN: {} {} \\n\".format(runs, sep3))\n",
    "        \n",
    "        LR_accuracies = []\n",
    "        LR_f1s=[]    \n",
    "    \n",
    "\n",
    "        strat_labels = []\n",
    "        \n",
    "        logistic = linear_model.LogisticRegression(C=1e4)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=int(runs))\n",
    "        for train_index, test_index in skf.split(X, y):       \n",
    "            print(\"\\n Fold: {} {} \\n\".format(counter, sep2))        \n",
    "            counter=counter+1\n",
    "                        \n",
    "            train_data_origin, test_data_origin=X[train_index], X[test_index]\n",
    "            train_labels, test_labels = y[train_index], y[test_index]\n",
    "            strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    " #           print(\"Random forest for feature selection\")\n",
    "            clf = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "            clf = clf.fit(train_data_origin, train_labels)\n",
    "            importances = clf.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]        \n",
    "            \n",
    "            index=indices[0:i]\n",
    "            train_data=train_data_origin[:, index]\n",
    "            test_data=test_data_origin[:, index]\n",
    "                             \n",
    "            #Logistic Regression\n",
    "            log = logistic.fit(train_data, train_labels)\n",
    "            log_acc = log.score(test_data, test_labels)\n",
    "\n",
    "            #f1 calculation            \n",
    "            y_pred = logistic.predict(test_data)            \n",
    "            log_f1 = f1_score(test_labels, y_pred, average='macro')\n",
    "\n",
    "            print('Logistic Regression Accuracy: %f' % log_acc)\n",
    "            print('Logistic Regression F1 score: %f' % log_f1)\n",
    "                            \n",
    "            LR_accuracies = np.append(LR_accuracies, log_acc)\n",
    "            LR_f1s=np.append(LR_f1s, log_f1)        \n",
    "                      \n",
    "        base_labels=np.append(base_labels, strat_labels)        \n",
    "        LR_all_accs_one_feature=np.append(LR_all_accs_one_feature, np.mean(LR_accuracies))\n",
    "        LR_all_f1s_one_feature =np.append(LR_all_f1s_one_feature, np.mean(LR_f1s))    \n",
    "    \n",
    "\n",
    "\n",
    "    print(\"LR###############################################################\")\n",
    "    print(\"Runs Avg Accuracies: {}\".format(np.mean(LR_accuracies)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(LR_accuracies)))\n",
    "    print(\"Runs Avg F1: {}\".format(np.mean(LR_f1s)))\n",
    "    print(\"Standard Deviation: {}\".format(np.std(LR_f1s)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('begin XGboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep1 = '*' * 100\n",
    "sep2 = '*' * 50\n",
    "sep3 = '*' * 30\n",
    "\n",
    "print(\"beginning selection best number of features\")\n",
    "n_features = [10,30,50,70,80,100,1000,2000]\n",
    "\n",
    "\n",
    "param={}\n",
    "param['objective'] = 'multi:softmax'\n",
    "\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['num_class'] = 6\n",
    "\n",
    "for i in n_features:\n",
    "    print(\"\\n\\n Number of Feature: {} {} \\n\".format(i, sep1))\n",
    "      \n",
    "    XGB_all_accs_one_feature  = []\n",
    "    XGB_all_f1s_one_feature = []\n",
    "\n",
    "\n",
    "    base_labels=[]\n",
    "    \n",
    "    for runs in range(10):\n",
    "        counter=0\n",
    "        print(\"\\n RUN: {} {} \\n\".format(runs, sep3))\n",
    "        \n",
    "        XGB_accuracies = []\n",
    "        XGB_f1s=[]    \n",
    "    \n",
    "\n",
    "        strat_labels = []\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=int(runs))\n",
    "        for train_index, test_index in skf.split(X, y):       \n",
    "            print(\"\\n Fold: {} {} \\n\".format(counter, sep2))        \n",
    "            counter=counter+1\n",
    "                        \n",
    "            train_data_origin, test_data_origin=X[train_index], X[test_index]\n",
    "            train_labels, test_labels = y[train_index], y[test_index]\n",
    "            strat_labels = np.append(strat_labels, test_labels)\n",
    "\n",
    " #           print(\"Random forest for feature selection\")\n",
    "            clf = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "            clf = clf.fit(train_data_origin, train_labels)\n",
    "            importances = clf.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]        \n",
    "            \n",
    "            index=indices[0:i]\n",
    "            train_data=train_data_origin[:, index]\n",
    "            test_data=test_data_origin[:, index]\n",
    "            \n",
    "            xgb_train_data=xgb.DMatrix(train_data, label=train_labels)\n",
    "            xgb_test_data=xgb.DMatrix(test_data, label=test_labels)\n",
    "            \n",
    "                             \n",
    "            #Logistic Regression\n",
    "            watchlist=[(xgb_train_data, 'train'), (xgb_test_data, 'test')]\n",
    "            num_round=5\n",
    "            bst = xgb.train(param, xgb_train_data, num_round, watchlist)\n",
    "            y_pred = bst.predict(xgb_test_data)\n",
    "\n",
    "            print(y_pred)\n",
    "            \n",
    "            print(test_labels)\n",
    "            \n",
    "            print(np.sum(y_pred == test_labels))\n",
    "            \n",
    "            print(test_labels[0])\n",
    "            \n",
    "            xgb_acc = np.sum(y_pred == test_labels) / test_labels.shape[0]           \n",
    "\n",
    "            #f1 calculation\n",
    "            xgb_f1 = f1_score(test_labels, y_pred, average='macro')\n",
    "\n",
    "            print('XGB Regression Accuracy: %f' % xgb_acc)\n",
    "            print('XGB Regression F1 score: %f' % xgb_f1)\n",
    "                            \n",
    "            XGB_accuracies = np.append(LR_accuracies, log_acc)\n",
    "            XGB_f1s=np.append(LR_f1s, log_f1)        \n",
    "               \n",
    "        base_labels=np.append(base_labels, strat_labels)        \n",
    "        XGB_all_accs_one_feature=np.append(LR_all_accs_one_feature, np.mean(LR_accuracies))\n",
    "        XG_all_f1s_one_feature =np.append(LR_all_f1s_one_feature, np.mean(LR_f1s))    \n",
    "\n",
    "    #print(\"LR###############################################################\")\n",
    "    #print(\"Runs Avg Accuracies: {}\".format(np.mean(LR_accuracies)))\n",
    "    #print(\"Standard Deviation: {}\".format(np.std(LR_accuracies)))\n",
    "    #print(\"Runs Avg F1: {}\".format(np.mean(LR_f1s)))\n",
    "    #print(\"Standard Deviation: {}\".format(np.std(LR_f1s)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

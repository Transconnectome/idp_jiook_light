{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "cwd=os.getcwd()\n",
    "os.chdir('/Users/posnerlab/Dropbox (NYSPI)/00 AD ML/Deep Learning Project')\n",
    "# Import modules\n",
    "import os \n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "#import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 164, 164, 4)\n",
      "(211, 164, 164, 4)\n",
      "(208, 959)\n",
      "(208,)\n",
      "(211, 1)\n",
      "filtindex:(208,)\n",
      "(208, 948)\n",
      "(208,)\n",
      "notice\n",
      "(146,)\n",
      "(146, 164, 164, 4)\n",
      "(98,)\n",
      "(98, 164, 164, 4)\n",
      "(172,)\n",
      "(172, 164, 164, 4)\n",
      "(201,)\n",
      "(179, 1)\n",
      "(179, 1007)\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "test=scipy.io.loadmat('adni_connectome_aparc_length.mat')\n",
    "aparcl_adni=np.array(test['connectome_aparc0x2Baseg_length'])\n",
    "\n",
    "test=scipy.io.loadmat('adni_connectome_aparc_count.mat')\n",
    "aparcc_adni=np.array(test['connectome_aparc0x2Baseg_count'])\n",
    "\n",
    "test=scipy.io.loadmat('adni_connectome_aparc2009_length.mat')\n",
    "aparc2l_adni=np.array(test['connectome_aparc0x2Ea2009s0x2Baseg_length'])\n",
    "\n",
    "test=scipy.io.loadmat('adni_connectome_aparc2009_count.mat')\n",
    "aparc2c_adni=np.array(test['connectome_aparc0x2Ea2009s0x2Baseg_count'])\n",
    "\n",
    "test=scipy.io.loadmat('idp_connectome_aparc_length.mat')\n",
    "aparcl_idp=np.array(test['connectome_aparc_length'])\n",
    "\n",
    "test=scipy.io.loadmat('idp_connectome_aparc_count.mat')\n",
    "aparcc_idp=np.array(test['connectome_aparc_count'])\n",
    "\n",
    "test=scipy.io.loadmat('idp_connectome_aparc2009_length.mat')\n",
    "aparc2l_idp=np.array(test['connectome_aparc2009_length'])\n",
    "\n",
    "test=scipy.io.loadmat('idp_connectome_aparc2009_count.mat')\n",
    "aparc2c_idp=np.array(test['connectome_aparc2009_count'])\n",
    "\n",
    "\n",
    "\n",
    "## Zeropad smaller matrices, organized into X\n",
    "\n",
    "zeromatal=np.zeros([164,164,179])\n",
    "zeromatac=np.zeros([164,164,179])\n",
    "\n",
    "zeromatal[40:124,40:124,:]=aparcl_adni\n",
    "zeromatac[40:124,40:124,:]=aparcc_adni\n",
    "\n",
    "aparcl_adni=zeromatal\n",
    "aparcc_adni=zeromatac\n",
    "\n",
    "X1=np.zeros([164,164,179,4])\n",
    "X1[:,:,:,0]=aparcl_adni\n",
    "X1[:,:,:,1]=aparcc_adni\n",
    "X1[:,:,:,2]=aparc2l_adni\n",
    "X1[:,:,:,3]=aparc2c_adni\n",
    "\n",
    "X1=X1.transpose([2,0,1,3])\n",
    "print(X1.shape)\n",
    "\n",
    "\n",
    "\n",
    "zeromatal=np.zeros([164,164,211])\n",
    "zeromatac=np.zeros([164,164,211])\n",
    "\n",
    "zeromatal[40:124,40:124,:]=aparcl_idp\n",
    "zeromatac[40:124,40:124,:]=aparcc_idp\n",
    "\n",
    "aparcl_idp=zeromatal\n",
    "aparcc_idp=zeromatac\n",
    "\n",
    "X2=np.zeros([164,164,211,4])\n",
    "X2[:,:,:,0]=aparcl_idp\n",
    "X2[:,:,:,1]=aparcc_idp\n",
    "X2[:,:,:,2]=aparc2l_idp\n",
    "X2[:,:,:,3]=aparc2c_idp\n",
    "\n",
    "X2=X2.transpose([2,0,1,3])\n",
    "print(X2.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datasubjid=pd.read_csv('idp_data_1_mor.csv',header=0)\n",
    "datasubjid=np.array(datasubjid)\n",
    "print(datasubjid.shape)\n",
    "M2=datasubjid\n",
    "labels=datasubjid[:,1]\n",
    "\n",
    "datasubjid=datasubjid[:,0]\n",
    "\n",
    "print(datasubjid.shape)\n",
    "matsubjid=pd.read_csv('idp_connectome_subjectlist.csv',header=0)\n",
    "matsubjid=np.array(matsubjid)\n",
    "print(matsubjid.shape)\n",
    "\n",
    "filtindex=np.isin(matsubjid,datasubjid)\n",
    "filtindex=filtindex.ravel()\n",
    "filtindex2=np.isin(datasubjid,matsubjid)\n",
    "filtindex2=filtindex2.ravel()\n",
    "print(\"filtindex:{}\".format(filtindex2.shape))\n",
    "X2=X2[filtindex,:,:,:]\n",
    "M2=M2[filtindex1,11:]\n",
    "print(M2.shape)\n",
    "filtindex1=np.isin(datasubjid,matsubjid)\n",
    "filtindex1=filtindex1.ravel()\n",
    "y2=labels[filtindex1]\n",
    "print(y2.shape)\n",
    "\n",
    "print(\"notice\")\n",
    "\n",
    "\n",
    "data=pd.read_csv('idp_data_1_mor.csv',header=0)\n",
    "data=np.array(data)\n",
    "\n",
    "ad_smi=data[:,5]\n",
    "mci_smi=data[:,6]\n",
    "ad_mci=data[:,7]\n",
    "\n",
    "ind_num=np.isnan(ad_smi)\n",
    "y2_adsmi=ad_smi[~ind_num]\n",
    "X2_adsmi=X2[~ind_num,:,:,:]\n",
    "print(y2_adsmi.shape)\n",
    "print(X2_adsmi.shape)\n",
    "\n",
    "ind_num=np.isnan(mci_smi)\n",
    "y2_mcismi=mci_smi[~ind_num]\n",
    "X2_mcismi=X2[~ind_num,:,:,:]\n",
    "print(y2_mcismi.shape)\n",
    "print(X2_mcismi.shape)\n",
    "\n",
    "ind_num=np.isnan(ad_mci)\n",
    "y2_admci=ad_mci[~ind_num]\n",
    "X2_admci=X2[~ind_num,:,:,:]\n",
    "print(y2_admci.shape)\n",
    "print(X2_admci.shape)\n",
    "\n",
    "\n",
    "\n",
    "## Less matrix than subjects, grabbing respective labels into y\n",
    "\n",
    "data=pd.read_csv('adni_data_1_mor.csv',header=0)\n",
    "data=np.array(data)\n",
    "datasubjid=data[:,0]\n",
    "print(datasubjid.shape)\n",
    "matsubjid=pd.read_csv('adni_connectome_subjectlist.csv',header=0)\n",
    "matsubjid=np.array(matsubjid)\n",
    "print(matsubjid.shape)\n",
    "\n",
    "filtindex=np.isin(datasubjid,matsubjid)\n",
    "filtindex=filtindex.ravel()\n",
    "labels=data[:,13]\n",
    "\n",
    "y1=labels[filtindex]\n",
    "M1=data[filtindex,37:]\n",
    "print(M1.shape)\n",
    "\n",
    "print(y1.shape)\n",
    "\n",
    "\n",
    "#print(M2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208,)\n"
     ]
    }
   ],
   "source": [
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M1 is morphometric data from ADNI; M2 is Morphemetric data from IDP \n",
    "# X1 is Connectome data from ADNI  X2 is from IDP\n",
    "#y1 and y2 are the target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/posnerlab/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# ADNI Morphometric data dimension reduction \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "scaler=StandardScaler()\n",
    "#ADNI dataset\n",
    "scaler.fit(M1)\n",
    "M1_scale=scaler.transform(M1)\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=50)\n",
    "model.fit(M1_scale,y1)\n",
    "\n",
    "def selectKImportance(model, X, k=5):\n",
    "     return X[:,model.feature_importances_.argsort()[::-1][:k]]\n",
    "\n",
    "\n",
    "M1_new = selectKImportance(model,M1_scale,100)\n",
    "M1_new.shape\n",
    "scipy.io.savemat('/Users/posnerlab/Dropbox (NYSPI)/00 AD ML/Deep Learning Project/ADNI_morph_100.mat',mdict={'M1_new': M1_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDP Morphometric data dimension reduction \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "scaler=StandardScaler()\n",
    "imputor=Imputer(missing_values='NaN', strategy=\"mean\",axis=0)\n",
    "imputor.fit(M2)\n",
    "M2=imputor.transform(M2)\n",
    "#ADNI dataset\n",
    "scaler.fit(M2)\n",
    "M2_scale=scaler.transform(M2)\n",
    "\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=50)\n",
    "model.fit(M2_scale,y2)\n",
    "\n",
    "def selectKImportance(model, X, k=5):\n",
    "     return X[:,model.feature_importances_.argsort()[::-1][:k]]\n",
    "\n",
    "\n",
    "M2_new = selectKImportance(model,M2_scale,100)\n",
    "M2_new.shape\n",
    "scipy.io.savemat('/Users/posnerlab/Dropbox (NYSPI)/00 AD ML/Deep Learning Project/IDP_morph_100.mat',mdict={'M2_new': M2_new})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "os.chdir('/Users/posnerlab/idp_jiook_light/imgs3_idp/2018-07-02/data_3_all') #IDP project\n",
    "\n",
    "csv_dir='/Users/posnerlab/idp_jiook_light/braindata'\n",
    "dd=pd.read_csv(csv_dir+'/'+'data_3_all.csv')\n",
    "col=list(dd)\n",
    "start_index=col.index('hippo_lh_md_1')\n",
    "feature_names=col[start_index:]\n",
    "# traverse root directory, and list directories as dirs and files as files\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    #path = root.split(os.sep)\n",
    "    #print((len(path) ) * '---', os.path.basename(root))\n",
    "    print(root)\n",
    "    for file in files:\n",
    "        if file.endswith('.' + 'p') & file.startswith('features_'):\n",
    "           \n",
    "            #pathss=path[2]\n",
    "            C=pickle.load( open(root+'/'+file, \"rb\" ) )\n",
    "            name=[]\n",
    "            for i,j in enumerate(C):\n",
    "                name=np.append(name,feature_names[int(j)])\n",
    "            filenames=os.path.splitext(file)[0]\n",
    "\n",
    "#             C=C.reshape(900,-1)\n",
    "            #C=C.astype(int)\n",
    "            unique, counts = np.unique(name, return_counts=True)\n",
    "            Cdic=dict(zip(unique, counts))\n",
    "            w = csv.writer(open(root+'/'+'Rank'+filenames+'.csv', \"w\"))\n",
    "            for key, val in Cdic.items():\n",
    "                w.writerow([key, val])\n",
    "            #print(len(C))\n",
    "            if len(name)>0:\n",
    "                 print(root+'/'+file)\n",
    "                 C_reshape=np.reshape(name,(30,30))\n",
    "                \n",
    "                 \n",
    "                 df = pd.DataFrame(C_reshape)\n",
    "                 #filenames=os.path.splitext(file)[0]\n",
    "                 #print(os.path.splitext(file)[0])\n",
    "                 df.to_csv(root+'/'+filenames+'.csv')\n",
    "                \n",
    "                 #for i in range(len(C_reshape)):\n",
    "                       #print(df.iloc[:,i].value_counts())\n",
    "\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "./linear_model.LogisticRegression\n",
      "./linear_model.LogisticRegression/features_30AD vs MCI.p\n",
      "./linear_model.LogisticRegression/features_30AD vs SMC.p\n",
      "./linear_model.LogisticRegression/features_30MCI vs SMC.p\n",
      "./RandomForestClassifier\n",
      "./RandomForestClassifier/features_30AD vs MCI.p\n",
      "./RandomForestClassifier/features_30AD vs SMC.p\n",
      "./RandomForestClassifier/features_30MCI vs SMC.p\n",
      "./SVC\n",
      "./SVC/features_30AD vs MCI.p\n",
      "./SVC/features_30AD vs SMC.p\n",
      "./SVC/features_30MCI vs SMC.p\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "os.chdir('/Users/posnerlab/idp_jiook_light/imgs3_adni/2018-07-06/combine_new_3fold') # combine_new\n",
    "\n",
    "csv_dir='/Users/posnerlab/idp_jiook_light/data/adni'\n",
    "dd=pd.read_csv(csv_dir+'/'+'combine_new.csv')\n",
    "col=list(dd)\n",
    "start_index=col.index('T1')\n",
    "feature_names=col[start_index:]\n",
    "# traverse root directory, and list directories as dirs and files as files\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    #path = root.split(os.sep)\n",
    "    #print((len(path) ) * '---', os.path.basename(root))\n",
    "    print(root)\n",
    "    for file in files:\n",
    "        if file.endswith('.' + 'p') & file.startswith('features_'):\n",
    "           \n",
    "            #pathss=path[2]\n",
    "            C=pickle.load( open(root+'/'+file, \"rb\" ) )\n",
    "            name=[]\n",
    "            for i,j in enumerate(C):\n",
    "                name=np.append(name,feature_names[int(j)])\n",
    "            filenames=os.path.splitext(file)[0]\n",
    "\n",
    "#             C=C.reshape(900,-1)\n",
    "            #C=C.astype(int)\n",
    "            unique, counts = np.unique(name, return_counts=True)\n",
    "            Cdic=dict(zip(unique, counts))\n",
    "            w = csv.writer(open(root+'/'+'Rank'+filenames+'.csv', \"w\"))\n",
    "            for key, val in Cdic.items():\n",
    "                w.writerow([key, val])\n",
    "            #print(len(C))\n",
    "            if len(name)>0:\n",
    "                 print(root+'/'+file)\n",
    "                 C_reshape=np.reshape(name,(30,30))\n",
    "                \n",
    "                 \n",
    "                 df = pd.DataFrame(C_reshape)\n",
    "                 #filenames=os.path.splitext(file)[0]\n",
    "                 #print(os.path.splitext(file)[0])\n",
    "                 df.to_csv(root+'/'+filenames+'.csv')\n",
    "                \n",
    "                 #for i in range(len(C_reshape)):\n",
    "                       #print(df.iloc[:,i].value_counts())\n",
    "\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "./linear_model.LogisticRegression\n",
      "./linear_model.LogisticRegression/features_30MCI converter.p\n",
      "./RandomForestClassifier\n",
      "./RandomForestClassifier/features_30MCI converter.p\n",
      "./SVC\n",
      "./SVC/features_30MCI converter.p\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "os.chdir('/Users/posnerlab/idp_jiook_light/imgs3_adni/2018-07-06/combine_MConly_RFonly_3fold') # combine_new\n",
    "\n",
    "csv_dir='/Users/posnerlab/idp_jiook_light/data/adni'\n",
    "dd=pd.read_csv(csv_dir+'/'+'combine_MConly.csv')\n",
    "col=list(dd)\n",
    "start_index=col.index('T11')\n",
    "feature_names=col[start_index:]\n",
    "# traverse root directory, and list directories as dirs and files as files\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    #path = root.split(os.sep)\n",
    "    #print((len(path) ) * '---', os.path.basename(root))\n",
    "    print(root)\n",
    "    for file in files:\n",
    "        if file.endswith('.' + 'p') & file.startswith('features_'):\n",
    "           \n",
    "            #pathss=path[2]\n",
    "            C=pickle.load( open(root+'/'+file, \"rb\" ) )\n",
    "            name=[]\n",
    "            for i,j in enumerate(C):\n",
    "                name=np.append(name,feature_names[int(j)])\n",
    "            filenames=os.path.splitext(file)[0]\n",
    "\n",
    "#             C=C.reshape(900,-1)\n",
    "            #C=C.astype(int)\n",
    "            unique, counts = np.unique(name, return_counts=True)\n",
    "            Cdic=dict(zip(unique, counts))\n",
    "            w = csv.writer(open(root+'/'+'Rank'+filenames+'.csv', \"w\"))\n",
    "            for key, val in Cdic.items():\n",
    "                w.writerow([key, val])\n",
    "            #print(len(C))\n",
    "            if len(name)>0:\n",
    "                 print(root+'/'+file)\n",
    "                 C_reshape=np.reshape(name,(30,30))\n",
    "                \n",
    "                 \n",
    "                 df = pd.DataFrame(C_reshape)\n",
    "                 #filenames=os.path.splitext(file)[0]\n",
    "                 #print(os.path.splitext(file)[0])\n",
    "                 df.to_csv(root+'/'+filenames+'.csv')\n",
    "                \n",
    "                 #for i in range(len(C_reshape)):\n",
    "                       #print(df.iloc[:,i].value_counts())\n",
    "\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
